<!DOCTYPE html>
<html lang="en" data-bs-theme="light">
  <head>
    <meta charset="utf-8">

    <!-- Viewport -->
    <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1, maximum-scale=1, viewport-fit=cover">
    
    <!-- SEO meta tags -->
    <title>Building a Property Insurance Claims Data Lakehouse with Airflow and Databricks</title>
    <meta name="description" content="Automate email attachment capture with Apache Airflow on Docker. Learn how to automatically fetch Gmail attachments, save files to shared folders, maintain audit trails, and integrate with BI tools - all with just a few lines of Python.">
    <meta name="keywords" content="apache airflow, email automation, gmail attachments, docker, python, data pipeline, ETL, workflow automation, IMAP, email processing, data engineering, scheduler, attachment retrieval, automation">
    <meta name="author" content="Darren Clark">


    <!-- Facebook and Twitter integration -->
    <meta property="og:title" content="Building a Property Insurance Claims Data Lakehouse with Airflow and Databricks"/>
    <meta property="og:image" content="https://pattersonconsultingtn.com/assets/img/dbx_claims_data_lakehouse_header_0.jpg"/>
    <meta property="og:url" content="https://pattersonconsultingtn.com/blog/building_databricks_insurance_claims_lakehouse.html"/>
    <meta property="og:site_name" content="Patterson Consulting"/>
    <meta property="og:description" content="After reading this guide, you'll be able to: 
    Automatically fetch all new attachments from your Gmail account on a schedule,
    Save every file into a shared downloads folder ready for any analytics tool,
    Maintain a precise audit trail of which attachments were retrieved and when,
    Seamlessly integrate incoming files into your BI or data pipeline with just a few lines of Python, 
    Streamline your workflow so your first task each day is insight, not inbox maintenance."/>


    <meta name="twitter:title" content="Building a Property Insurance Claims Data Lakehouse with Airflow and Databricks" />
    <meta name="twitter:image" content="https://pattersonconsultingtn.com/assets/img/dbx_claims_data_lakehouse_header_0.jpg" />
    <meta name="twitter:url" content="https://pattersonconsultingtn.com/blog/building_databricks_insurance_claims_lakehouse.html" />
    <meta name="twitter:card" content="summary_large_image" />


    <!-- Webmanifest + Favicon / App icons -->
    <link rel="manifest" href="/alpha_manifest.json">
    <link rel="icon" type="image/png" href="../assets/app-icons/icon-32x32.png" sizes="32x32">
    <link rel="apple-touch-icon" href="../assets/app-icons/icon-180x180.png">
        
    
    <!-- Theme switcher (color modes) -->
    <script src="../assets/js/theme-switcher.js"></script>

    
    <!-- Import Google font (Inter) -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&amp;display=swap" rel="stylesheet" id="google-font">


    <!-- Vendor styles -->
    <link rel="stylesheet" media="screen" href="../assets/vendor/swiper/swiper-bundle.min.css">
    <link rel="stylesheet" media="screen" href="../assets/vendor/lightgallery/css/lightgallery-bundle.min.css">

    <link rel="stylesheet" media="screen" href="../assets/vendor/aos/dist/aos.css">

    <!-- Font icons -->
    <link rel="stylesheet" href="../assets/icons/around-icons.min.css">

    <!-- Theme styles + Bootstrap -->
    <link rel="stylesheet" media="screen" href="../assets/css/theme.pct.v2.css">

    <!-- Page loading styles -->
    <style>
      .page-loading {
        position: fixed;
        top: 0;
        right: 0;
        bottom: 0;
        left: 0;
        width: 100%;
        height: 100%;
        -webkit-transition: all .4s .2s ease-in-out;
        transition: all .4s .2s ease-in-out;
        background-color: #fff;
        opacity: 0;
        visibility: hidden;
        z-index: 9999;
      }
      [data-bs-theme="dark"] .page-loading {
        background-color: #121519;
      }
      .page-loading.active {
        opacity: 1;
        visibility: visible;
      }
      .page-loading-inner {
        position: absolute;
        top: 50%;
        left: 0;
        width: 100%;
        text-align: center;
        -webkit-transform: translateY(-50%);
        transform: translateY(-50%);
        -webkit-transition: opacity .2s ease-in-out;
        transition: opacity .2s ease-in-out;
        opacity: 0;
      }
      .page-loading.active > .page-loading-inner {
        opacity: 1;
      }
      .page-loading-inner > span {
        display: block;
        font-family: "Inter", sans-serif;
        font-size: 1rem;
        font-weight: normal;
        color: #6f788b;
      }
      [data-bs-theme="dark"] .page-loading-inner > span {
        color: #fff;
        opacity: .6;
      }
      .page-spinner {
        display: inline-block;
        width: 2.75rem;
        height: 2.75rem;
        margin-bottom: .75rem;
        vertical-align: text-bottom;
        background-color: #d7dde2; 
        border-radius: 50%;
        opacity: 0;
        -webkit-animation: spinner .75s linear infinite;
        animation: spinner .75s linear infinite;
      }
      [data-bs-theme="dark"] .page-spinner {
        background-color: rgba(255,255,255,.25);
      }
      @-webkit-keyframes spinner {
        0% {
          -webkit-transform: scale(0);
          transform: scale(0);
        }
        50% {
          opacity: 1;
          -webkit-transform: none;
          transform: none;
        }
      }
      @keyframes spinner {
        0% {
          -webkit-transform: scale(0);
          transform: scale(0);
        }
        50% {
          opacity: 1;
          -webkit-transform: none;
          transform: none;
        }
      }

      .todo_edit { 
        color: #ff0000;
       }
    </style>

    <!-- Page loading scripts -->
    <script>
      (function () {
        window.onload = function () {
          const preloader = document.querySelector('.page-loading')
          preloader.classList.remove('active')
          setTimeout(function () {
            preloader.remove()
          }, 1500)

          const theme = 'light'
          document.documentElement.setAttribute('data-bs-theme', theme)
          

        }
      })()
    </script>

    <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-N6H6PTM9');</script>
    <!-- End Google Tag Manager -->


  </head>


  <!-- Body -->
  <body>


    <!-- Page loading spinner -->
    <div class="page-loading active">
      <div class="page-loading-inner">
        <div class="page-spinner"></div>
        <span>Loading...</span>
      </div>
    </div>


    <!-- Page wrapper -->
    <main class="page-wrapper">

      <header data-bs-theme="light">
        <!-- Navbar. Remove 'fixed-top' class to make the navigation bar scrollable with the page -->
        <div class="navbar navbar-expand-lg fixed-top bg-light">
          <div class="container">

            <!-- Navbar brand (Logo) -->
            <a class="navbar-brand pe-sm-3" href="../../index.html">
              <span class="text-primary flex-shrink-0 me-2">
                <svg width="35" height="32" viewBox="0 0 36 33" xmlns="http://www.w3.org/2000/svg">
                  <!--
                  <path fill="currentColor" d="M35.6,29c-1.1,3.4-5.4,4.4-7.9,1.9c-2.3-2.2-6.1-3.7-9.4-3.7c-3.1,0-7.5,1.8-10,4.1c-2.2,2-5.8,1.5-7.3-1.1c-1-1.8-1.2-4.1,0-6.2l0.6-1.1l0,0c0.6-0.7,4.4-5.2,12.5-5.7c0.5,1.8,2,3.1,3.9,3.1c2.2,0,4.1-1.9,4.1-4.2s-1.8-4.2-4.1-4.2c-2,0-3.6,1.4-4,3.3H7.7c-0.8,0-1.3-0.9-0.9-1.6l5.6-9.8c2.5-4.5,8.8-4.5,11.3,0L35.1,24C36,25.7,36.1,27.5,35.6,29z"></path>
                -->




<g transform="matrix(0.004459, 0, 0, -0.00433, -8154.369629, -2022.807495)" fill="#000000" stroke="none" style="transform-origin: 8189.37px 2055.78px;">
  <path d="M340 9410 l0 -260 1348 0 c807 0 1370 -4 1403 -9 30 -6 101 -15 159
-21 177 -19 447 -88 605 -155 242 -103 389 -186 553 -310 124 -94 287 -257
390 -390 26 -34 100 -148 140 -215 214 -362 327 -901 282 -1345 -11 -115 -47
-341 -58 -362 -5 -10 -14 -45 -21 -78 -7 -33 -16 -64 -20 -70 -4 -5 -13 -30
-20 -55 -7 -25 -19 -58 -26 -75 -70 -160 -92 -205 -132 -277 -45 -80 -161
-257 -189 -288 -8 -8 -33 -37 -56 -65 -60 -71 -200 -208 -277 -270 -88 -70
-241 -175 -258 -175 -7 0 -13 -3 -13 -8 0 -11 -304 -162 -326 -162 -3 0 -20
-7 -37 -14 -45 -21 -210 -74 -254 -82 -21 -4 -45 -10 -55 -15 -9 -5 -72 -18
-140 -30 -67 -12 -145 -26 -173 -31 -29 -6 -359 -12 -782 -15 l-733 -4 0
-1175 0 -1174 3270 0 3270 0 0 3695 0 3695 -3925 0 -3925 0 0 -260z" style="fill: rgb(255, 149, 0);"></path>
  <path d="M1650 6884 l0 -1096 648 4 647 4 120 28 c66 16 125 32 130 36 6 4 28
13 50 20 53 17 129 56 179 92 23 16 52 36 66 46 86 60 201 201 261 322 84 168
109 281 116 525 7 251 -18 402 -97 580 -56 126 -184 280 -295 355 -27 18 -62
42 -77 52 -15 10 -29 18 -32 18 -3 0 -30 11 -60 25 -30 14 -61 25 -68 25 -7 1
-31 8 -53 16 -101 37 -228 44 -892 44 l-643 0 0 -1096z" style="fill: rgb(255, 149, 0);"></path>
</g>



                </svg>
              </span>
              Patterson Consulting
            </a>


            <a class="btn btn-primary btn-sm fs-sm order-lg-3 d-none d-sm-inline-flex" href="../../contact_us.html" target="_blank" rel="noopener">
              <i class="fs-xl me-2 ms-n1"></i>
              Contact Us
            </a>

            <!-- Mobile menu toggler (Hamburger) -->
            <button class="navbar-toggler ms-sm-3" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-label="Toggle navigation">
              <span class="navbar-toggler-icon"></span>
            </button>

            <!-- Navbar collapse (Main navigation) -->
            <nav class="collapse navbar-collapse" id="navbarNav">
              <ul class="navbar-nav navbar-nav-scroll me-auto" style="--ar-scroll-height: 520px;">


                <li class="nav-item dropdown">
                  <a class="nav-link dropdown-toggle" href="#" data-bs-toggle="dropdown" aria-expanded="false">Industries</a>
                  <ul class="dropdown-menu">
                    <li><a class="dropdown-item" href="../../insurance_industry.html">Insurance</a></li>
                  </ul>
                </li>


                <li class="nav-item dropdown">
                  <a class="nav-link dropdown-toggle" href="#" data-bs-toggle="dropdown" data-bs-auto-close="outside" aria-expanded="false">Engineering Services</a>
                  <ul class="dropdown-menu">
                    <li><a class="dropdown-item" href="../platform_engineering.html">Platform Engineering</a></li>
                    <li><a class="dropdown-item" href="../data_engineering.html">Data Engineering</a></li>
                    <li><a class="dropdown-item" href="../generative_ai.html">GenAI Services</a></li>
                    <!--
                    <li><a class="dropdown-item" href="../../data_strategy.html">Data Strategy</a></li>
                  -->
                    
                    
                  </ul>

                </li>

                <li class="nav-item dropdown">
                  <a class="nav-link dropdown-toggle" href="#" data-bs-toggle="dropdown" data-bs-auto-close="outside" aria-expanded="false">Resources</a>
                  <ul class="dropdown-menu">
                    <li><a class="dropdown-item" href="../blog/blog_index.html">Blog</a></li>
                    <li><a class="dropdown-item" href="../publications.html">Team Publications</a></li>
                    <li><a class="dropdown-item" href="../index.html#case_studies">Case Studies</a></li>
                    <li><a class="dropdown-item" href="https://www.youtube.com/channel/UCmaki2Xq1AeFL8XbWGIWyQg">Videos</a></li>
                  </ul>

                </li>

                <li class="nav-item">
                  <a class="nav-link" href="../about.html">About</a>
                </li>
              </ul>
            </nav>

          </div>
        </div>
      </header>


      <!-- Page header -->
      <section class="container py-5 mt-5 mb-md-2 mb-lg-3 mb-xl-4">

        <!-- Breadcrumb -->
        <nav aria-label="breadcrumb">
          
          <ol class="pt-lg-3 pb-lg-4 pb-2 breadcrumb">
            <li class="breadcrumb-item"><a href="">Home</a></li>
            <li class="breadcrumb-item"><a href="../">Blog Index</a></li>
            <li class="breadcrumb-item active" aria-current="page">Building a Property Insurance Claims Data Lakehouse with Airflow and Databricks</li>
          </ol>
          
        </nav>

        <!-- Post title + post meta -->
        <h1 class="display-4 text-left pb-2 pb-lg-3">Building a Property Insurance Claims Data Lakehouse with Airflow and Databricks</h1>

        <!--
        <div class="d-flex flex-wrap align-items-center justify-content-center mt-n2">
          <span class="text-body-secondary fs-sm fw-normal p-0 mt-2 me-3">
            12
            <i class="ai-share fs-lg ms-1"></i>
          </span>
          <a class="nav-link position-relative text-body-secondary fs-sm fw-normal d-flex align-items-end p-0 mt-2" href="#comments" data-scroll data-scroll-offset="60">
            <span class="position-absolute w-100 h-100 top-0 start-0" data-bs-toggle="collapse" data-bs-target="#commentsCollapse"></span>
            4
            <i class="ai-message fs-lg ms-1"></i>
          </a>
          <span class="fs-xs opacity-20 mt-2 mx-3">|</span>
          <span class="fs-sm text-body-secondary mt-2">16 hours ago</span>
          <span class="fs-xs opacity-20 mt-2 mx-3">|</span>
          <a class="badge text-nav fs-xs border mt-2" href="#">Inspiration</a>
        </div>
        -->

            <div class="d-flex flex-wrap align-items-center justify-content-between border-bottom mb-4">
              <div class="d-flex align-items-center mb-4 me-4">
                <span class="fs-sm me-2">By:</span>
                <a class="nav-link position-relative fw-semibold p-0" href="#author" data-scroll data-scroll-offset="80">
                  Darren Clark
                  <span class="d-block position-absolute start-0 bottom-0 w-100" style="background-color: currentColor; height: 1px;"></span>
                </a>
              </div>

            </div>

      </section>


      <!-- Post cover image (parallax) -->
      <section class="jarallax" data-jarallax data-speed=".65">
        <div class="jarallax-img bg-position-center-y" style="background-image: url(../assets/img/dbx_claims_data_lakehouse_header_0.jpg);"></div>
        <div class="d-none d-xxl-block" style="height: 600px;"></div>
        <div class="d-none d-xl-block d-xxl-none" style="height: 650px;"></div>
        <div class="d-none d-lg-block d-xl-none" style="height: 500px;"></div>
        <div class="d-none d-md-block d-lg-none" style="height: 400px;"></div>
        <div class="d-md-none" style="height: 300px;"></div>
      </section>


      <!-- Post content -->
      <section class="container pt-5 mt-md-2 mt-lg-3 mt-xl-4">
        <div class="row justify-content-center pt-xxl-2">
          <div class="col-lg-9 col-xl-8">



           <p class="fs-lg">

            In this branch of our series on building property insurance claims data platforms we're going to use the Databricks platform for our storage system. We need to process the incoming TPA bordereaux data each day, and we'll use Airflow pipelines to orchestrate python code to get the data into data lakehouse.

            

            

          </p>

          <p class="fs-lg">


            Since we're focused on managing a budget and accurately forecasting costs in property insurance, we want to get our claims data updates at least daily so that our chief claims officer can make the best quality decisions possible. To do that we're going to have to integrate bordereaux data with different schemas in our automated pipeline. Let's start out by setting up a data lakehouse to store the incoming data once we have it converted and merged each day.

          </p>

            







           <h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">Building a Claims Delta Lake Table in Databricks</h2>

           <p class="fs-lg">

            

A Databricks Table is a structured dataset stored as files in cloud object storage and tracked through a catalog and metastore. 
<!--
Built on the Delta Lake format, it supports ACID transactions, scalable metadata, versioned data (time travel), and both batch and streaming workloads. 
-->
Databricks offers two types: <b>managed tables</b>, which it controls fully within its storage environment, and <b>unmanaged (external) tables</b>, where storage and governance remain with the user. 

          </p>
            

           <p class="fs-lg">

            Building your data platform around managed data tables has the following key advantages of unmanaged blob storage.

            

            

            </p>
<ul>
  <li>
    <strong>Reliable Data with ACID Transactions</strong>
    <ul>
      <li>Prevents data corruption from concurrent writes.</li>
      <li>Supports safe, multi-user ETL operations.</li>
    </ul>
  </li>
  <li>
    <strong>Time Travel for Easy Recovery</strong>
    <ul>
      <li>Access past versions of data anytime.</li>
      <li>Helps with audits, debugging, and rollbacks.</li>
    </ul>
  </li>
  <li>
    <strong>Faster Queries and Lower Costs</strong>
    <ul>
      <li>Built-in optimizations like file compaction and indexing.</li>
      <li>Speeds up analytics and reduces compute/storage usage.</li>
    </ul>
  </li>
</ul>

           <p class="fs-lg">

This flexibility allows insurance data teams to balance control with performance, optimizing for both compliance and scale.

           </p>         



           <p class="fs-lg">

To begin building a modern data lakehouse on Databricks, you’ll need to create a Databricks account and provision a workspace. Current Databricks workspaces are designed to leverage Unity Catalog for centralized governance and support Serverless SQL for scalable, on-demand compute.
            </p>         




           <p class="fs-lg">

Within the workspace, set up a catalog and a namespace (schema) to logically organize your claims data. For structuring tables and data pipelines, the Medallion Architecture offers a useful framework—dividing data into Bronze (raw), Silver (cleaned), and Gold (aggregated) layers—to support scalable, modular claims processing and analytics.

            

            </p>         

           <h2 class="h3 mb-lg-4 pt-3 pt-md-4 pt-xl-5">Building a Data Table for Bordereaux Claims Data</h2>            






           <p class="fs-lg">

            The SQL create table statement to setup our data lakehouse managed data table is shown below.

            

            

          </p>         



<pre class="line-numbers">
  <code class="lang-html">
CREATE TABLE claims_workspace.bronze.bordereaux_data (
    policy_number        STRING,
    months_insured       INT,
    has_claims           BOOLEAN,
    items_insured        INT,
    claim_reference      STRING,
    insured_name         STRING,
    policy_start_date    TIMESTAMP,
    date_of_loss         TIMESTAMP,
    date_reported        TIMESTAMP,
    claim_status         STRING,
    loss_type            STRING,
    paid_amount          DOUBLE,
    reserve_amount       DOUBLE,
    total_incurred       DOUBLE,
    claim_propensity     DOUBLE
);
  </code>
</pre>



           <p class="fs-lg mt-5 mb-5">

            

            In the code listing below, I show a JSON-format sample of a row of bordereaux data so you can get a feel for the type of data that we'll be working with.

          </p>

<pre class="line-numbers">
  <code class="lang-html">
{
  "policy_number": "POL1038",
  "months_insured": 113,
  "has_claims": true,
  "items_insured": 4,
  "claim_reference": "CLM1071",
  "insured_name": "Company 1038",
  "policy_start_date": "2023-10-02",
  "date_of_loss": "2024-01-16",
  "date_reported": "2024-02-15",
  "claim_status": "Open",
  "loss_type": "Property Damage",
  "paid_amount": 11463.65,
  "reserve_amount": 11962.45,
  "total_incurred": 23426.10,
  "claim_propensity": 0.5
}
  </code>
</pre>


           <p class="fs-lg mt-5">

            

            The challenge with this data is, however, that each partner TPA has their own column schema for the bordereaux data they'll send over, so we'll need to do some translation work in our ingest pipeline.

          </p>

           <h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">Airflow Pipeline to Process Incoming Bordereaux Files</h2>

           <p class="fs-lg">
            We need a way to run a data pipeline each day and pickup all of the files sent in via email from our partner TPAs. In the <a href="capturing_email_attachments_with_airflow.html">last article in this series, we showed how to use Airflow to watch an email address to pickup bordereaux files</a> as they come in and save them to S3 for processing later.

           </p>


           <p class="fs-lg">

            

            Apache Airflow is an open-source workflow orchestration tool designed to programmatically author, schedule, and monitor data pipelines. For data platforms, Airflow provides a scalable and reliable way to manage complex dependencies across ETL jobs, analytics workflows, and machine learning pipelines. Its modular architecture and support for DAG-based task scheduling make it a critical component in ensuring data quality, operational consistency, and timely data delivery across the enterprise.


          </p>




           <p class="fs-lg">

            

            So we have a subdirectory per company in S3 for incoming daily bordereaux files that need to be converted before they can be written to our data lakehouse data table. The first stage in this Airflow work does just this and then writes the merged data back to S3 for further processing.


          </p>



           <h2 class="h3 mb-lg-4 pt-3 pt-md-4 pt-xl-5">DAG Step 1: Merging Multiple TPA Schemas Together</h2>

           <p class="fs-lg">

            

            The first stage of our Airflow job uses a per-company schema configuration file to analyze each incoming file and then convert it to a normalized schema that is compatible with our data table.

          </p>


<pre class="line-numbers">
  <code class="lang-html">

...

def merge_incoming_s3_tpa_schemas():

    schema_conf_file_string = load_s3_file_as_text(bucket, subdirectory + schema_conf_file)

    data_company_schemas = json.loads( schema_conf_file_string )


    subdirs, subdirs_full = list_subdirectories(bucket, subdirectory)

    tpa_converted_df_list = []

    print("Processing Subdirectories:")

    for subdir, full_subdir in zip(subdirs, subdirs_full):

        print(full_subdir)

        file_list_subdir = list_files(bucket, full_subdir)


        for filename in file_list_subdir:

            print("\t" + filename)

            df_tmp = load_s3_file_to_dataframe(bucket, full_subdir + filename)

            print("Convert schema to standard internal schema: " + filename)

            df_new_claims_cols = df_tmp.rename(columns=data_company_schemas[subdir]["schema"])

            df_new_claims_cols['policy_start_date'] = pd.to_datetime(df_new_claims_cols['policy_start_date'], format=data_company_schemas[subdir]["date_format"])
            df_new_claims_cols['date_of_loss'] = pd.to_datetime(df_new_claims_cols['date_of_loss'], format=data_company_schemas[subdir]["date_format"])
            df_new_claims_cols['date_reported'] = pd.to_datetime(df_new_claims_cols['date_reported'], format=data_company_schemas[subdir]["date_format"])


            tpa_converted_df_list.append( df_new_claims_cols )

    df_all_bordereaux = pd.concat(tpa_converted_df_list)

    s3_key_write_merged_data = 'test-bordereaux-data/daily_bordereaux_merged_data/20250422_daily_merged.csv'
    write_df_to_s3_csv(df_all_bordereaux, bucket, s3_key_write_merged_data)



with DAG(
    'dbx_merge_incoming_tpa_schemas',
    default_args={
        "depends_on_past": False,
        "retries": 1,
        "retry_delay": timedelta(minutes=5),

    },
    description="Takes the incoming bordereaux data in different schemas in S3 and converts them to a single schema. Also merges them into a single csv.",
    schedule=timedelta(days=1),
    start_date=datetime(2021, 1, 1),
    catchup=False,
    tags=["s3", "bordereaux", "bronze"],

) as dag:
    task_read_file = PythonOperator(
        task_id='merge_tpa_schemas_python_task',
        python_callable=merge_incoming_s3_tpa_schemas
    )

  </code>
</pre>

           <p class="fs-lg mt-5">

            

            The above code does some Pandas dataframe magic to process each incoming company's specific schema (defined in the json file) and then merges all the converted dataframes together, before writing it back to S3. In the next step, we take this result and load it into our lakehouse table.

          </p>


           <h2 class="h3 mb-lg-4 pt-3 pt-md-4 pt-xl-5">DAG Step 2: Loading New Data Into Delta Lake Table</h2>

           <p class="fs-lg mb-5">

            

            Once our pipeline has merged the converted bordereaux data, it now needs to load this data into our data lakehouse data table. In the Airflow code below we can see the DAG task that uses the <code>DatabricksSqlOperator</code> to execute our saved <code>load_s3_bordereaux_into_dbx_airflow.sql</code> statement that will load the data from S3 into the data table.

          </p>


<pre class="line-numbers">
  <code class="lang-html">
...

with DAG(
    'dbx_load_data_into_dbx_lakehouse',
    default_args={
        "depends_on_past": False,
        "retries": 1,
        "retry_delay": timedelta(minutes=5),

    },
    description="Loads data into Databricks Delta Lake Table from S3",
    schedule=timedelta(days=1),
    start_date=datetime(2021, 1, 1),
    catchup=False,
    tags=["s3", "bordereaux", "silver"],

) as dag:
    test_dbx_data_task = DatabricksSqlOperator(
        task_id="dbx_sql_data_insert_task",
        databricks_conn_id="databricks_connection",
        http_path=sql_endpoint_name,
        sql="load_s3_bordereaux_into_dbx_airflow.sql"

    )

  </code>
</pre>

           <p class="fs-lg mt-5 mb-5">

            

            The above Airflow operator executes the Databricks SQL below inside the Databricks platform on the SQL Server-less data warehouse.

          </p>
 



<pre class="line-numbers">
  <code class="lang-html">

copy into  claims_workspace.bronze.bordereaux_data 
from 
    (
        SELECT 
        policy_number,
        CAST(months_insured as BIGINT) as months_insured,
        has_claims,
        CAST(items_insured as BIGINT) as items_insured,
        claim_reference,
        insured_name,
        CAST(policy_start_date as DATE) as policy_start_date,
        CAST(date_of_loss as DATE) as date_of_loss,
        CAST(date_reported as DATE) as date_reported,
        claim_status,
        loss_type,
        paid_amount,
        reserve_amount,
        total_incurred,
        claim_propensity
        

        FROM 's3://property-insurance-examples/test-bordereaux-data/daily_bordereaux_merged_data/'
    )
FILEFORMAT = CSV FORMAT_OPTIONS('sep' = ',', 'header' = 'true', 'inferSchema' = 'true')
COPY_OPTIONS ('force' = 'true', 'mergeSchema' = 'true')

  </code>
</pre>

           <p class="fs-lg mt-5 mb-5">

            

            The SQL statement will pull data from S3 where our Airflow DAG wrote the converted and merged bordereaux data and write it into the Delta lake table we previously created.

          </p>
 


            <div class="card bg-primary bg-opacity-10 border-0 overflow-hidden pt-3 pt-xl-4 px-lg-3 px-xl-4 mt-5">
              <div class="card-body position-relative z-2 pb-0">
                <h3 class="h4 card-title text-primary">But the Pipeline Doesn't Do X...</h3>

                <p class="pb-sm3 pb-md-4 mb-2">

                  The challenge of platform architecture examples is that its impossible to cover every variation that you may want to try. In this example we're skipping a few things like "pipeline flexibiltiy" and also merging row updates as part of the data table update process. If we're missing a key feature you want to talk about, 
                  <a  href="../contact_us.html">reach out and let's talk</a> and we'll see how we can help.




                </p>



              </div>
            </div>

            

           <h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">From Data Tables to Data Models</h2>

           <p class="fs-lg">

            

            Our data lake tables are a great starting point, but we want to standardize the knowledge work formulas over our data lakehouse in a way that is easily accessible to the claims team. To do that, we'll use the Cube.dev semantic layer to integrate with our Databricks claims data lakehouse and build standardized claims data models. This allows us to further refine the data in a data table into standardized claims information (in our knowledge work architecture "information layer") that is useful to the claims team.

          </p>

           <p class="fs-lg">
            
Data models in a semantic layer add critical business context and structure on top of raw data tables in a lakehouse, enabling more consistent, governed, and user-friendly access to information. Unlike raw tables, semantic models define metrics, dimensions, and relationships in business terms, allowing teams to self-serve insights without needing to understand complex SQL or data schemas. This abstraction enhances data trust, accelerates decision-making, and ensures alignment across analytics, reporting, and AI applications.

          </p>


           <p class="fs-lg">

            

            In the next post we connect our Databricks data platform to the Cube.dev semantic layer and construct our claims data models for use in the claims team's knowledge work tools.

          </p>

          </div>
        </div>
      </section>



      <!-- Post content -->
      
      <section class="container pt-5 mt-md-2 mt-lg-3 mt-xl-4">


            
            <div class="d-flex flex-wrap pb-5 pt-3 pt-md-4 pt-xl-5 mt-xl-n2 pl-3">
              <h3 class="h3 py-1 mb-0 me-4">Next in Series</h3>
            </div>



                  <div class="card overflow-hidden mb-4">
                    <div class="row g-0">
                      <div class="col-sm-4 bg-repeat-0 bg-size-cover" style="background-image: url(../assets/img/claims_data_model_cube_dbx_header_0.jpg); min-height: 14rem;"></div>
                      <div class="col-sm-8">
                        <div class="card-body">
                          <h4 class="card-title">Building a Standard Claims Data Model With the Cube Semantic Layer and Databricks</h4>
                          <p class="card-text">Creating standard claims data models for claims knowledge work in property insurance companies.</p>
                          
                <a class="btn btn-lg btn-link px-0" href="./building_standard_claims_data_model_cube_dbx_lakehouse.html">
                  Read next article in series
                  <i class="ai-arrow-right ms-2"></i>
                </a>

                        </div>
                      </div>
                    </div>
                  </div>

      </section>
   




    </main>

    

  <footer class="footer py-5 bg-dark" data-bs-theme="dark">
      <div class="container pt-md-2 pt-lg-3 pt-xl-4">
        <div class="row pb-5 pt-sm-2 mb-lg-2">
          <div class="col-md-4 col-lg-3 pb-2 pb-md-0 mb-4 mb-md-0">


            <a class="navbar-brand pe-sm-3" href="/index.html">
              <span class="text-primary flex-shrink-0 me-2">
                <svg width="35" height="32" viewBox="0 0 36 33" xmlns="http://www.w3.org/2000/svg">

                  <g transform="matrix(0.004459, 0, 0, -0.00433, -8154.369629, -2022.807495)" fill="#000000" stroke="none" style="transform-origin: 8189.37px 2055.78px;">
                    <path d="M340 9410 l0 -260 1348 0 c807 0 1370 -4 1403 -9 30 -6 101 -15 159
                  -21 177 -19 447 -88 605 -155 242 -103 389 -186 553 -310 124 -94 287 -257
                  390 -390 26 -34 100 -148 140 -215 214 -362 327 -901 282 -1345 -11 -115 -47
                  -341 -58 -362 -5 -10 -14 -45 -21 -78 -7 -33 -16 -64 -20 -70 -4 -5 -13 -30
                  -20 -55 -7 -25 -19 -58 -26 -75 -70 -160 -92 -205 -132 -277 -45 -80 -161
                  -257 -189 -288 -8 -8 -33 -37 -56 -65 -60 -71 -200 -208 -277 -270 -88 -70
                  -241 -175 -258 -175 -7 0 -13 -3 -13 -8 0 -11 -304 -162 -326 -162 -3 0 -20
                  -7 -37 -14 -45 -21 -210 -74 -254 -82 -21 -4 -45 -10 -55 -15 -9 -5 -72 -18
                  -140 -30 -67 -12 -145 -26 -173 -31 -29 -6 -359 -12 -782 -15 l-733 -4 0
                  -1175 0 -1174 3270 0 3270 0 0 3695 0 3695 -3925 0 -3925 0 0 -260z" style="fill: rgb(255, 149, 0);"></path>
                    <path d="M1650 6884 l0 -1096 648 4 647 4 120 28 c66 16 125 32 130 36 6 4 28
                  13 50 20 53 17 129 56 179 92 23 16 52 36 66 46 86 60 201 201 261 322 84 168
                  109 281 116 525 7 251 -18 402 -97 580 -56 126 -184 280 -295 355 -27 18 -62
                  42 -77 52 -15 10 -29 18 -32 18 -3 0 -30 11 -60 25 -30 14 -61 25 -68 25 -7 1
                  -31 8 -53 16 -101 37 -228 44 -892 44 l-643 0 0 -1096z" style="fill: rgb(255, 149, 0);"></path>
                  </g>

                </svg>
              </span>
              <span class="text-light">
              Patterson Consulting
              </span>
            </a>    

            <p class="fs-sm pb-2 pb-md-3 mb-3 text-light">Delivering data pipelines, analytics, and large language model applications.</p>
            <div class="d-flex gap-3">
              <!--
              <a class="btn btn-icon btn-sm btn-secondary btn-facebook rounded-circle" href="#" aria-label="Facebook">
                <i class="ai-facebook"></i>
              </a>
            -->
              <!--
              <a class="btn btn-icon btn-sm btn-secondary btn-instagram rounded-circle" href="#" aria-label="Instagram">
                <i class="ai-instagram"></i>
              </a>
            -->
              <a class="btn btn-icon btn-sm btn-secondary btn-linkedin rounded-circle" href="https://www.linkedin.com/company/patterson-consulting-tn/" aria-label="LinkedIn">
                <i class="ai-linkedin"></i>
              </a>
            </div>
          </div>
          <div class="col-md-8 col-lg-7 col-xl-6 offset-lg-2 offset-xl-3">
            <div class="row row-cols-1 row-cols-sm-3">
              <div class="col mb-4 mb-md-0">
              </div>
              <div class="col mb-4 mb-md-0">

              </div>
              <div class="col mb-4 mb-md-0">
                <h4 class="h6 fw-bold pb-lg-1">Company</h4>
                <ul class="nav flex-column">
                  <li><a class="nav-link fw-normal py-1 px-0" href="../contact_us.html">Contact Us</a></li>
                  <li><a class="nav-link fw-normal py-1 px-0" href="../blog/blog_index.html">Blog</a></li>
                  <li><a class="nav-link fw-normal py-1 px-0" href="../index.html#case_studies">Case Studies</a></li>
                  <li><a class="nav-link fw-normal py-1 px-0" href="../publications.html">eBooks</a></li>
                  <li><a class="nav-link fw-normal py-1 px-0" href="https://www.youtube.com/channel/UCmaki2Xq1AeFL8XbWGIWyQg">Videos</a></li>
                  <li><a class="nav-link fw-normal py-1 px-0" href="../about.html">About</a></li>
                </ul>
              </div>
            </div>
          </div>
        </div>
        <p class="nav fs-sm mb-0">
          <span class="text-body-secondary">© All rights reserved. Made by</span>
          <a class="nav-link fw-normal p-0 ms-1" href="https://www.pattersonconsultingtn.com/" target="_blank" rel="noopener">Patterson Consulting</a>
        </p>
      </div>
    </footer>    


    <!-- Back to top button -->
    <a class="btn-scroll-top" href="#top" data-scroll aria-label="Scroll back to top">
      <svg viewBox="0 0 40 40" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
        <circle cx="20" cy="20" r="19" fill="none" stroke="currentColor" stroke-width="1.5" stroke-miterlimit="10"></circle>
      </svg>
      <i class="ai-arrow-up"></i>
    </a>


    <!-- Vendor scripts: JS libraries and plugins -->
    
    <script src="../assets/vendor/jarallax/dist/jarallax.min.js"></script>
    <script src="../assets/vendor/swiper/swiper-bundle.min.js"></script>
    


    <script src="../assets/vendor/swiper/swiper-bundle.min.js"></script>
    <script src="../assets/vendor/lightgallery/lightgallery.min.js"></script>


    <script src="../assets/vendor/lightgallery/plugins/fullscreen/lg-fullscreen.min.js"></script>
    <script src="../assets/vendor/lightgallery/plugins/zoom/lg-zoom.min.js"></script>
    <script src="../assets/vendor/lightgallery/plugins/video/lg-video.min.js"></script>
    <script src="../assets/vendor/lightgallery/plugins/thumbnail/lg-thumbnail.min.js"></script>



    <!-- Bootstrap + Theme scripts -->
    <script src="../assets/js/theme.min.js"></script>
  </body>
</html>
