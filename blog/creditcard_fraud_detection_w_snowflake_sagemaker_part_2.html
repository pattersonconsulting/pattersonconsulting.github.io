
<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
	<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-119541534-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-119541534-1');
</script>

	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Detecting Credit Card Fraud with Snowflake, Snowpark, and SageMaker Studio - Part 2 of 5: Scalable Feature Engineering with Snowpark</title>
	<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="description" content="In this blog post series we will demonstrate how to build a credit card fraud detection system on realistic data and deploying it to the cloud with streamlit" />
	<meta name="keywords" content="snowflake, predictive maintenance, exploratory data analysis, machine learning, data science, snowpark" />
	<meta name="author" content="Patterson Consulting" />

  	<!-- Facebook and Twitter integration -->
	<meta property="og:title" content="Detecting Credit Card Fraud with Snowflake, Snowpark, and SageMaker Studio - Part 2 of 5: Scalable Feature Engineering with Snowpark"/>
	<meta property="og:image" content="http://www.pattersonconsultingtn.com/blog/images/meta_og_images/pct_ccfd_p2_og_card.png"/>
	<meta property="og:url" content="http://www.pattersonconsultingtn.com/blog/creditcard_fraud_detection_w_snowflake_sagemaker_part_2.html"/>
	<meta property="og:site_name" content=""/>
	<meta property="og:description" content="In this blog post series we will demonstrate how to build a credit card fraud detection system on realistic data and deploying it to the cloud with streamlit"/>
	

	<meta name="twitter:title" content="Detecting Credit Card Fraud with Snowflake, Snowpark, and SageMaker Studio - Part 2 of 5: Scalable Feature Engineering with Snowpark" />
	<meta data-rh="true" property="twitter:description" content="In this blog post series we will demonstrate how to build a credit card fraud detection system on realistic data and deploying it to the cloud with streamlit"/>

	<meta name="twitter:image" content="http://www.pattersonconsultingtn.com/blog/images/meta_og_images/pct_ccfd_p2_og_card.png" />
	<meta name="twitter:url" content="http://www.pattersonconsultingtn.com/blog/creditcard_fraud_detection_w_snowflake_sagemaker_part_2.html" />
	<meta name="twitter:card" content="summary_large_image" />


	<!-- Place favicon.ico and apple-touch-icon.png in the root directory -->
	<!-- <link rel="shortcut icon" href="favicon.ico"> -->
	
	<link rel="stylesheet" href="../css/animate.css">
	<link rel="stylesheet" href="../css/bootstrap.css">
	<link rel="stylesheet" href="../css/icomoon.css">

	<link rel="stylesheet" href="../css/owl.carousel.min.css">
	<link rel="stylesheet" href="../css/owl.theme.default.min.css">

	<link rel="stylesheet" href="../css/style.css">

	<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">

	<link rel="shortcut icon" href="http://www.pattersonconsultingtn.com/pct.ico" type="image/x-icon" />

	<style>
		a { 
			color: #FF0000; 
			text-decoration: underline;
		}

		span.quote_to_rewrite {
			color: #FF0000;
			font-style: italic;
		}

table {
  font-family: arial, sans-serif;
  border-collapse: collapse;
  width: 100%;
}

td, th {
  border: 1px solid #dddddd;
  text-align: left;
  padding: 8px;
}

tr:nth-child(even) {
  background-color: #dddddd;
}

h2 {
	color: #555555;
}

pre {
    background: #f4f4f4;
    border: 1px solid #ddd;
    border-left: 3px solid #f36d33;
    color: #666;
    page-break-inside: avoid;
    font-family: monospace;
    font-size: 15px;
    line-height: 1.6;
    margin-bottom: 1.6em;
    max-width: 100%;
    overflow: auto;
    padding: 1em 1.5em;
    display: block;
    word-wrap: break-word;
}

.news_item_row {
	border: 0px solid #999999; 
	padding: 0px; 
	padding-top: 20px; 
	padding-bottom: 24px; 
	margin: 0px; 
	margin-bottom: 6px; 
	background-color: #ffffff;

}

.news_item_label {
	border: 1px solid #cccccc; 
	border-bottom: 0px; 
	width: 50%; 
	padding: 12px; 
	padding-top: 18px; 
	margin: 0px; 
	margin-left: 0px; 
	background-color: #dddddd;
}


.news_item_body {
	border: 2px solid #cccccc; 
	padding: 12px; 
	padding-top: 18px; 
	margin: 20px; 
	margin-left: 0px; 
	margin-top: 0px; 
	background-color: #ffffff;

}

blockquote.rewrite {

	color:  red;
}

</style>	

	<script src="../js/modernizr-2.6.2.min.js"></script>
	<!--[if lt IE 9]>
	<script src="js/respond.min.js"></script>
	<![endif]-->

	</head>
	<body class="boxed">
	<!-- Loader -->
	<div class="fh5co-loader"></div>

	<div id="wrap">

	<div id="fh5co-page">
		<header id="fh5co-header" role="banner">
			<div class="container">
				<a href="#" class="js-fh5co-nav-toggle fh5co-nav-toggle dark"><i></i></a>
				<div id="fh5co-logo"><a href="index.html"><img src="../images/website_header_top_march2018_v0.png" ></a></div>
				<nav id="fh5co-main-nav" role="navigation">
		          <ul>
		            
		            <li class="has-sub">
		              <div class="drop-down-menu">
		                <a href="#">Services</a>
		                <div class="dropdown-menu-wrap">
		                  <ul>
		                    
		                    <li><a href="../offerings/snowflake_services.html">Snowflake</a></li>
		                    <li><a href="../offerings/data_engineering.html">Data Engineering</a></li>
		                    <li><a href="../offerings/data_science.html">Data Science</a></li>

		                    <li><a href="../offerings/cloud_operations.html">Cloud Operations and Engineering</a></li>
		                    
		                    <li><a href="../offerings/managed_kubeflow.html">Managed Kubeflow</a></li>

		                    <li><a href="../offerings/managed_kafka.html">Managed Kafka</a></li>

		                    <li><a href="../offerings/research_partnerships.html">Research Partnerships</a></li>
		                    
		                  </ul>
		                </div>
		              </div>
		            </li>
		            
		            <li><a href="../partners.html">Partners</a></li>

		            <li><a href="../blog/blog_index.html">Blog</a></li>
		          
		            <li class="cta"><a href="../contact.html">Contact</a></li>
		          </ul>
		        </nav>
			</div>
		</header>
		<!-- Header -->

		
		<div id="fh5co-intro" class="fh5co-section">
			<div class="container">


		
				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">
						<h1>Detecting Credit Card Fraud with Snowflake, Snowpark, and SageMaker Studio</h1>
						<p>
							<h3>Part 2 of 5: Scalable Feature Engineering with Snowpark</h3>


						</p>
						<p>
							Author: Josh Patterson<br/>
							Date: zzzzzzz xxth, 2022
						</p>
						

						<p>
							Other entries in this series:

							<ul>

								<li>Part 1: <a href="creditcard_fraud_detection_w_snowflake_sagemaker_part_1.html">Loading the Credit Card Transaction Data Into Snowflake</a></li>
								<li>Part 2: <a href="creditcard_fraud_detection_w_snowflake_sagemaker_part_2.html">Scalable Feature Engineering with Snowpark</a></li>
								<li>Part 3: <a href="creditcard_fraud_detection_w_snowflake_sagemaker_part_3.html">Connecting AWS Sagemaker Studio Lab to Snowflake</a></li>
								<li>Part 4: <a href="creditcard_fraud_detection_w_snowflake_sagemaker_part_4.html">Grid Search Model Selection with AWS Sagemaker Studio Lab and Shap Hypertune</a></li>
								<li>Part 5: <a href="creditcard_fraud_detection_w_snowflake_sagemaker_part_5.html">Deploying the Model as a Streamlit Application</a></li>
							</ul>

						</p>

						For more use cases like these, check out our <a href="http://www.pattersonconsultingtn.com/use_case_repository/finserv_vertical.html">Financial Services vertical</a> in our <a href="http://www.pattersonconsultingtn.com/use_case_repository/intro.html">Use Case Repository</a>.




					</div>

				</div>




				<!-- Section 1 of 5: Intro, PM in Cloud -->

				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">

						<h1>Introduction</h1>

						<img src="./images/snowflake_logo_wide_sept_2021.png" width="400px;" style="float: right;"/>


						<p>
							In our last article we loaded our synthetic credit card data into the Snowflake platform.

						</p>

						<p>
							We want to start building some models in Sagemaker Studio Lab, but first we need to do some scalable feature engineering. In many cases we will have a non-trivial amount of raw data in our data warehouse, so anything we can do in-storage / in-database (scalably) is going to be an advantage in terms of saving compute time later on in our pipeline.

						</p>
						<p>
							Snowpark in Snowflake gives us a great way to do scalable feature generation. In this article we are going to use Snowpark to build most of our core dataset features for model training.

						</p>


					</div>
				</div>

				<!-- Section 1 of 5: Intro, PM in Cloud -->








				<!-- Section 3 of 5: Snowflake bulk load -->

				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">
						


						<h1>Scalable Feature Engineering with Snowpark</h1>

						<p>
							Let's start off by giving a specific definition for "feature engineering":

						</p>

<blockquote>Feature engineering is process where we use domain expertise to extract features (characteristics, properties) from raw data. We use the data we already have to generate new features (columns) in our dataset.</blockquote>



						<p>
							There is no standard way to do feature engineering for non-numerical or categorical features. There are a few core methods that are known to work well in practice (e.g., "1-hot encoding for categorical features"), but most of the time we use a combination of these practictioner methods and domain expertise to generate good features for out modeling workflow.

						</p>

						<p>
							As previously mentioned, many times the raw dataset is large but the data we want to model is relatively smaller after processing. From this perspective, we want to do as much raw processing of the data in the datawarehouse (e.g., here Snowflake) with tools that will scale linearly with the size of the data input (e.g., Snowpark). Snowpark is nice because it let's us build data processing pipelines in a dataframe-api (similar to Pandas on Python).

						</p>						


						<p>
							
							The work in this series is based on the dataset and general workflow from the online book:
						</p>
						<p>
<figure>
<figcaption>			


						<a href="https://github.com/Fraud-Detection-Handbook/fraud-detection-handbook"><cite>Reproducible Machine Learning for Credit Card Fraud Detection - Practical Handbook</cite></a>, by Le Borgne, Yann-Aël and Siblini, Wissam and Lebichot, Bertrand and Bontempi, Gianluca, 2022, Université Libre de Bruxelles
</figcaption>
</figure>
					</p>



						<p>

							Further, Mats Stellwall (Snowflake Engineer) wrote a blog post <a href="https://medium.com/snowflake/feature-engineering-with-snowflake-9a96ee928b8">Feature Engineering with Snowflake, Using Snowpark and Scala</a> based on the book above.
						</p>
						<p>
							We use portions of Mats' scala code to provide the basis for our Snowflake feature generation pipeline (we provide our implementation <a href="">here on github</a>).


						</p>



						<p>
							With all of this in mind, let's jump into building our feature engineering pipeline in Snowpark.
							

						</p>



				<div class="row row-bottom-padded-sm" style=" border: 1px solid #cccccc; border-radius: 10px; padding: 8px; padding-top: 8px; background-color: #FF5126; color: #ffffff; font-size: 14px; font-weight: normal; margin-bottom: 30px; ">
					
					<div class="col-md-3" id="fh5co-content" style="">

						<h3 style="color: #ffffff;">Looking for Snowflake Help?</h3>

					</div>
					<div class="col-md-9" id="fh5co-content" style="margin-bottom: 0px;">


						<div style="background-color: ; padding: 1px; margin-bottom: 0px;">
						<p style="margin: 0px;">
							Our team can help -- we help companies with <a href="../offerings/snowflake_services.html" style="color: #EEEEEE;">Snowflake platform operations, analytics, and machine learning</a>.

						</p>
						</div>
					</div>


				</div>		

						<h2>Quick Look at the Raw Transaction Data</h2>

						<p>
							The raw transaction data has three types of features:

							<ol>
								<li>identifiers</li>
								<li>timestamps</li>
								<li>amounts</li>

							</ol>

							It also has a flag column to indicate if the record was fraudulent or not.

						</p>

						<p>
							Machine learning works with vectors (or tensors) of floating point numbers requiring us to convert each feature into an integer or real number. In some cases we want to include ordering information about a feature as well.

						</p>

							<p>
								Identifiers (e.g., transaction-ids, customer-ids, and terminal-ids) are not valuable to machine learning modeling due to high cardinality (e.g., large numbers of unique values), so we generally drop those.

							</p>


						<p>
							Raw rates (strings or ms from a date) do not work well with machine learning so we need to do some feature creation work with dates to create meaningful context for the machine learning algorithm to model.


						</p>

						<p>
							With our high-level notes about the data out of the way, let's now take a look at our specific feature engineering workflow overview.

						</p>




						<h2>Feature Engineering Workflow Overview</h2>


						<p>

							The online book <a href="https://fraud-detection-handbook.github.io/fraud-detection-handbook/Chapter_3_GettingStarted/BaselineFeatureTransformation.html">gives a great detailed explanation (Chapter 3: Baseline feature transformation)</a> around the how's and why's of the new features created. In this section we provide a brief summary explanation for these features.


						</p>

						<h4>Methods of Feature Encoding</h4>

						<p>

							The book states that there are 3 types of feature transformations that are known to be relevant for payment card fraud detection:

							<ul>

								<li>Binary encoding or 1-hot encoding</li>
								<li>RFM (Recency, Frequency, Monetary Value)</li>
								<li>Frequency Encoding or Risk encoding</li>

							</ul>

							Now let's briefly review the types of features we'll use these methods to create.


						</p>

						<h4>Creating Temporal Features (Date/Time) Features</h4>
							<p>

								With temporal features (data/time) we want to create binary features that indicate potentially actions during relevant periods of time. In this pipeline we create two features of this type:

								<ul>
									<li>transaction occurs during weekday or weekend</li>
									<li>transaction occurs during day or night</li>
								</ul>

								This features tend to be useful based on fraud patterns in real-world datasets.


							</p>



						<h4>Creating Customer Spending Behavior Features</h4>
							<p>

								The next type of features we want to create are centered on how customer spending behaviors. To create these features we use RFM the (Recency, Frequency, Monetary value) method. We will create 6 total new features that keep track of the average spending amount and number of transactions for each customer over 3 time window sizes.


							</p>






						<h4>Creating Terminal Risk Features</h4>
							<p>

								The final group of features we'll create involve measuring the risk associated with each financial terminal. As more fraud is committed at a terminal, its risk profile will also rise. We will create 6 new features for this group.


							</p>





						<h3>Table of Features to Create</h3>



						<p>

							To summarize our the features to create, the table below shows the complete list:


						</p>


<table class="colwidths-auto table" style="border: 1px solid;">
<thead>
<tr class="row-odd"><th class="head"><p>Original feature name</p></th>
<th class="head"><p>Original feature type</p></th>
<th class="head"><p>Transformation</p></th>
<th class="head"><p>Number of new features</p></th>
<th class="head"><p>New feature(s) type</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>TX_DATE_TIME</p></td>
<td><p>Panda timestamp</p></td>
<td><p>0 if transaction during a weekday, 1 if transaction during a weekend. The new feature is called TX_DURING_WEEKEND.</p></td>
<td><p>1</p></td>
<td><p>Integer (0/1)</p></td>
</tr>
<tr class="row-odd"><td><p>TX_DATE_TIME</p></td>
<td><p>Panda timestamp</p></td>
<td><p>0 if transaction between 6am and 0pm, 1 if transaction between 0pm and 6am. The new feature is called TX_DURING_NIGHT.</p></td>
<td><p>1</p></td>
<td><p>Integer (0/1)</p></td>
</tr>
<tr class="row-even"><td><p>CUSTOMER_ID</p></td>
<td><p>Categorical variable</p></td>
<td><p>Number of transactions by the customer in the last n day(s), for n in {1,7,30}. The new features are called CUSTOMER_ID_NB_TX_nDAY_WINDOW.</p></td>
<td><p>3</p></td>
<td><p>Integer</p></td>
</tr>
<tr class="row-odd"><td><p>CUSTOMER_ID</p></td>
<td><p>Categorical variable</p></td>
<td><p>Average spending amount in the last n day(s), for n in {1,7,30}. The new features are called CUSTOMER_ID_AVG_AMOUNT_nDAY_WINDOW.</p></td>
<td><p>3</p></td>
<td><p>Real</p></td>
</tr>
<tr class="row-even"><td><p>TERMINAL_ID</p></td>
<td><p>Categorical variable</p></td>
<td><p>Number of transactions on the terminal in the last n+d day(s), for n in {1,7,30} and d=7. The parameter d is called delay and will be discussed later in this notebook. The new features are called TERMINAL_ID_NB_TX_nDAY_WINDOW.</p></td>
<td><p>3</p></td>
<td><p>Integer</p></td>
</tr>
<tr class="row-odd"><td><p>TERMINAL_ID</p></td>
<td><p>Categorical variable</p></td>
<td><p>Average number of frauds on the terminal in the last n+d day(s), for n in {1,7,30} and d=7. The parameter d is called delay and will be discussed later in this notebook. The new features are called TERMINAL_ID_RISK_nDAY_WINDOW.</p></td>
<td><p>3</p></td>
<td><p>Real</p></td>
</tr>
</tbody>
</table>



						<p>

							

							Let's now take a look at how we can build these feature transforms with scala and Snowpark on Snowflake.


						</p>











					</div>

				</div>

				<!-- Section 3 of 5: Snowflake bulk load -->




				<!-- Section 4 of 5: Connecting Google Co-lab to Snowflake -->
				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">

						<h1>Running Snowpark Feature Engineering Pipelines</h1>

						<p>


						</p>


						<p>

							In this article we are going to port the feature creation of the following features to Snowpark:

							<ul>
								<li>Create weekend and night features</li>
								<li>Customer Transaction Features</li>
							</ul>

							We'll complete the last set of features ("Terminal Features") in python in part-3 of this series. Let's now jump into how to port the weekend and night features to Snowpark.


						</p>

						<p>
							Our implementation of the snowpark credit card transaction data feature engineering code can be found <a href="https://github.com/pattersonconsulting/cc_fraud_demo/blob/main/snowpark/src/main/scala/CCTxnFeatureEngineering.scala">here on github</a>.

						</p>

						<p>
							For the sake of time and space we are going to cover the highlights of the feature engineering code in the sub-sections below. You are more than welcome to download the project from github and run it against your own Snowflake account.

						</p>




						<h2>Create Scala Project to Connect to Snowflake and Run Snowpark Code</h2>

						<p>

							Check our previous Snowpark article to <a href="./predictive_maintenance_w_snowflake_ml_part_6_snowpark.html">understand how to launch snowpark code</a>.


						</p>		


						<p>
							Let's connect to Snowflake with a <code>Session</code> object:

						</p>



<pre><code>
val session = Session.builder.configFile("conn.properties").create
val df_cust_txns = session.table("CUSTOMER_CC_TRANSACTIONS") 
</code></pre>

						<p>
							Our Snowflake account information is contained in the <code>conn.properties</code> file in the example above, letting our code authenticate with Snowflake.

						</p>

						<h2>Create Weekend and Night Features in Scala for Snowpark</h2>

						<p>


								In the code below we want to generate a feature that has a <code>0</code> if transaction between 6am and 0pm and <code>1</code> if transaction between 0pm and 6am. The new feature is called <code>TX_DURING_NIGHT</code>.


						</p>


						<p>


								The code also generates a feature <code>TX_DURING_WEEKEND</code> that has a <code>0</code> if the transaction's date is during a weekday and <code>1</code> if transaction's date is during the weekend..


						</p>						

<pre><code>
    val dfDateTimeFeat = df_cust_txns.withColumns(
        Seq("TX_DURING_WEEKEND", "TX_DURING_NIGHT"), 
        Seq(
          iff(
            dayofweek(col("TX_DATETIME")) === 6 || dayofweek(col("TX_DATETIME")) === 0, 
            lit(1), 
            lit(0)
          ), 
          iff(hour(col("TX_DATETIME")) <= 6 || hour(col("TX_DATETIME")) > 23, lit(1), lit(0)
        )
      ))
</code></pre>						

						<p>

							This feature creation uses the <a href="https://docs.snowflake.com/en/sql-reference/functions/seq1.html"><code>Seq</code> function</a> in the Snowpark code to generate the 0 or 1 value for the features based on conditions in the data.
							

						</p>						


						<h2>Create Customer Transaction Features in Scala for Snowpark</h2>

						<p>


						</p>			

						<p>

							We want to calculate the number of transactions for the following time windows:

							<ul>
								<li>previous 1 day</li>
								<li>previous 7 days</li>
								<li>previous 30 days</li>

							</ul>

							For both number of transactions and total amount spend across those time periods.

							Snowflake has windowing functions that allow for calculations over time periods (total, average, etc).


						</p>



						<div style="width:900px; margin:0 auto;">

							<div class="w3-panel w3-leftbar w3-light-grey" style="padding: 16px; font-size: 12px; border: 1px solid #999999; width: 85%; text-align: left;">
								<img src="./images/crab_warn_230.png" style=" width: 80px; height: 80px; float: left; margin-right: 20px;" />

								<h4>Rolling Window Calculations in Snowflake</h4>
							  <p style="font-size: 14px; ">
							  <i>
							  	The original code from the online book uses the <a href="https://pandas.pydata.org/docs/reference/api/pandas.core.window.rolling.Rolling.count.html">Pandas rolling window function</a>, which calculates some of the values differently than how <a href="https://docs.snowflake.com/en/sql-reference/functions-analytic.html">Snowflake calculates its window functions</a>. In part 3 of this series we'll see the Pandas rolling window function in action when we generate the terminal features in python.

							  	

							  </i></p>
							  
							</div>	

						</div>


				<p>

					So we need to create the above 6 features for each transaction. Our general strategy (for both feature groups) for our snowpark code is:

					<ol>
						<li>create a dataframe with a single row for each customer and day (between min / mx date in our data)</li>
						<li>calculate transaction count and sum for each customer and day (if no transactions, then 0)</li>
						<li>use built-in Snowflake window functions to build our { 1, 7, 30 } features, and then join it back with original transactions</li>


					</ol>

					In the code listing below, we can see the code for this part of the feature creation in Snowpark.



				</p>


<pre><code>val dateInfo = df_cust_txns.select(
  min(col("TX_DATETIME")).alias("END_DATE"), 
  datediff("DAY", col("END_DATE"), max(col("TX_DATETIME")))
).collect()    

val dStartDate = new SimpleDateFormat("yyyy-MM-dd").format(dateInfo(0).getTimestamp(0))
val nDays = dateInfo(0).getInt(1)

val dfDays = session.range(nDays)
                   .withColumn("TX_DATE", 
                        to_date(dateadd("DAY", callBuiltin("SEQ4"), lit(dStartDate))))

val num_rows_txns_dfDays = dfDays.count()
val dfCustomers = session.table("CUSTOMERS").select("CUSTOMER_ID")
val num_rows_txns_dfCustomers = dfCustomers.count()
val dfCustDay = dfDays.join(dfCustomers)
val num_rows_txns_dfCustDay = dfCustDay.count()
val zeroifnull = builtin("ZEROIFNULL")

// df_cust_txns: the original table of raw transactions
// dfCustDay: the matrix of customers and possible dates

val dfCustTrxByDay = df_cust_txns.join(dfCustDay, df_cust_txns("CUSTOMER_ID") === dfCustDay("CUSTOMER_ID")
      && to_date(df_cust_txns("TX_DATETIME")) === dfCustDay("TX_DATE"), "rightouter")

     .select(dfCustDay("CUSTOMER_ID").alias("CUSTOMER_ID"), 
             dfCustDay("TX_DATE"), 
             zeroifnull(df_cust_txns("TX_AMOUNT")).as("TX_AMOUNT"), 
             iff(col("TX_AMOUNT") > 0, lit(1), lit(0)).as("NO_TRX"))

      .groupBy(col("CUSTOMER_ID"), col("TX_DATE"))

      .agg(
          sum(col("TX_AMOUNT")).alias("TOT_AMOUNT"), 
           sum(col("NO_TRX")).alias("NO_TRX")
       )    

val dfSubset = dfCustTrxByDay.filter(col("CUSTOMER_ID") === lit(0)).sort(col("TX_DATE"))
val custDate = Window.partitionBy(col("customer_id")).orderBy(col("TX_DATE"))
val win7dCust = custDate.rowsBetween(-7, -1)
val win30dCust = custDate.rowsBetween(-30, -1)

val dfCustFeatDay = dfCustTrxByDay
       .select(col("TX_DATE"),col("CUSTOMER_ID"),
               col("NO_TRX"), col("TOT_AMOUNT"),
               lag(col("NO_TRX"),1).over(custDate).as("CUST_TX_PREV_1"),
               sum(col("NO_TRX")).over(win7dCust).as("CUST_TX_PREV_7"),
               sum(col("NO_TRX")).over(win30dCust).as("CUST_TX_PREV_30"),
               lag(col("TOT_AMOUNT"),1).over(custDate).as("CUST_TOT_AMT_PREV_1"),
               sum(col("TOT_AMOUNT")).over(win7dCust).as("CUST_TOT_AMT_PREV_7"),
               sum(col("TOT_AMOUNT")).over(win30dCust).as("CUST_TOT_AMT_PREV_30"))    

</code></pre>


						<p>

							The original project generates 6 features for terminal usage. We're going to leave that function in python in this series to show the difference in how these windows are created.


						</p>

						<h2>Save Created Features as New Table in Snowpark</h2>

						<p>

							Finally, we want to save the new features to a table in Snowflake with the Snowpark command:


						</p>			
<pre>dfCustBehaviurFeat.write.mode(SaveMode.Overwrite).saveAsTable("CUSTOMER_CC_TRANSACTION_FEATURES")
</pre>


					</div>




						<p>

							


						</p>




					<p>
						At this point we have a table in Snowflake we can use to model over in Sagemaker Studio Lab.

					</p>

				</div>

				<!-- Section 4 of 5: Connecting Google Co-lab to Snowflake -->






				<!-- Section 5 of 5: Next Steps: EDA -->
				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">
						
						<h1>Next Steps: Connecting AWS Sagemaker Studio Lab to Snowflake</h1>


						<p>


							In this post in our series we learned how to build features in Snowpark for Snowflake.

						</p>
						<p>
							In the <a href="creditcard_fraud_detection_w_snowflake_sagemaker_part_3.html">next post we'll connect AWS Sagemaker Studio Lab to Snowflake and build out final terminal features</a>.

						</p>

					</div>

				</div>
				<!-- Section 5 of 5: Next Steps: EDA -->







				<div class="row row-bottom-padded-sm" style=" border: 1px solid #cccccc; border-radius: 10px; padding: 8px; padding-top: 8px; background-color: #FF5126; color: #ffffff; font-size: 14px; font-weight: normal; margin-bottom: 30px; ">
					
					<div class="col-md-3" id="fh5co-content" style="">

						<h3 style="color: #ffffff;">Looking for Snowflake Help?</h3>

					</div>
					<div class="col-md-9" id="fh5co-content" style="margin-bottom: 0px;">


						<div style="background-color: ; padding: 1px; margin-bottom: 0px;">
						<p style="margin: 0px;">
							Our team can help -- we help companies with <a href="../offerings/snowflake_services.html" style="color: #EEEEEE;">Snowflake platform operations, analytics, and machine learning</a>.

						</p>
						</div>
					</div>


				</div>		




			</div>
		</div>



		<footer id="fh5co-footer" role="contentinfo">
			<div class="container">
				<div class="row row-bottom-padded-sm">
					<div class="col-md-4 col-sm-12">
					</div>
					<div class="col-md-3 col-md-push-1 col-sm-12 col-sm-push-0">
						<div class="fh5co-footer-widget">
				

						</div>
					</div>
					<div class="col-md-3 col-md-push-2 col-sm-12 col-sm-push-0">
						
						<div class="fh5co-footer-widget">
							<h3>Follow us</h3>
							<ul class="fh5co-social">
								<li class="twitter"><a href="https://twitter.com/PattersonCnsltg"><i class="icon-twitter"></i></a></li>
								<li class="linkedin"><a href="https://www.linkedin.com/company/patterson-consulting-tn"><i class="icon-linkedin"></i></a></li>
								<li class="message"><a href="mailto:josh@pattersonconsultingtn.com"><i class="icon-mail"></i></a></li>
							</ul>
						</div>
					</div>

				</div>

			</div>
		</footer>


	</div>
	</div>

	<div class="gototop js-top">
		<a href="#" class="js-gotop"><i class="icon-chevron-down"></i></a>
	</div>
	
	<script src="../js/jquery.min.js"></script>
	<script src="../js/jquery.easing.1.3.js"></script>
	<script src="../js/bootstrap.min.js"></script>
	<script src="../js/owl.carousel.min.js"></script>
	<script src="../js/main.js"></script>

	</body>
</html>					
