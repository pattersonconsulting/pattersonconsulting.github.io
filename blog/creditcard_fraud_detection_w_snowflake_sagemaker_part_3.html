
<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
	<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-119541534-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-119541534-1');
</script>
		
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Detecting Credit Card Fraud with Snowflake, Snowpark, and SageMaker Studio - Part 3 of 3: Grid Search Model Construction with Sagemaker Studio Lab</title>
	<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="description" content="In this blog post series on ....." />
	<meta name="keywords" content="snowflake, predictive maintenance, exploratory data analysis, machine learning, data science, snowpark" />
	<meta name="author" content="Patterson Consulting" />

  	<!-- Facebook and Twitter integration -->
	<meta property="og:title" content="Detecting Credit Card Fraud with Snowflake, Snowpark, and SageMaker Studio - Part 3 of 3: Grid Search Model Construction with Sagemaker Studio Lab"/>
	<meta property="og:image" content="http://www.pattersonconsultingtn.com/blog/images/meta_og_images/pct_apm_p2_og_card.png"/>
	<meta property="og:url" content="http://www.pattersonconsultingtn.com/blog/predictive_maintenance_w_snowflake_ml_part_2_ingest.html"/>
	<meta property="og:site_name" content=""/>
	<meta property="og:description" content="In this blog post series o...."/>
	

	<meta name="twitter:title" content="Detecting Credit Card Fraud with Snowflake, Snowpark, and SageMaker Studio - Part 3 of 3: Grid Search Model Construction with Sagemaker Studio Lab" />
	<meta data-rh="true" property="twitter:description" content="In this blog post series ...."/>

	<meta name="twitter:image" content="http://www.pattersonconsultingtn.com/blog/images/meta_og_images/pct_apm_p2_og_card.png" />
	<meta name="twitter:url" content="http://www.pattersonconsultingtn.com/blog/predictive_maintenance_w_snowflake_ml_part_2_ingest.html" />
	<meta name="twitter:card" content="summary_large_image" />

	<!-- Place favicon.ico and apple-touch-icon.png in the root directory -->
	<!-- <link rel="shortcut icon" href="favicon.ico"> -->
	
	<link rel="stylesheet" href="../css/animate.css">
	<link rel="stylesheet" href="../css/bootstrap.css">
	<link rel="stylesheet" href="../css/icomoon.css">

	<link rel="stylesheet" href="../css/owl.carousel.min.css">
	<link rel="stylesheet" href="../css/owl.theme.default.min.css">

	<link rel="stylesheet" href="../css/style.css">

	<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">

	<link rel="shortcut icon" href="http://www.pattersonconsultingtn.com/pct.ico" type="image/x-icon" />

	<style>
		a { 
			color: #FF0000; 
			text-decoration: underline;
		}

		span.quote_to_rewrite {
			color: #FF0000;
			font-style: italic;
		}

table {
  font-family: arial, sans-serif;
  border-collapse: collapse;
  width: 100%;
}

td, th {
  border: 1px solid #dddddd;
  text-align: left;
  padding: 8px;
}

tr:nth-child(even) {
  background-color: #dddddd;
}

h2 {
	color: #555555;
}

pre {
    background: #f4f4f4;
    border: 1px solid #ddd;
    border-left: 3px solid #f36d33;
    color: #666;
    page-break-inside: avoid;
    font-family: monospace;
    font-size: 15px;
    line-height: 1.6;
    margin-bottom: 1.6em;
    max-width: 100%;
    overflow: auto;
    padding: 1em 1.5em;
    display: block;
    word-wrap: break-word;
}

.news_item_row {
	border: 0px solid #999999; 
	padding: 0px; 
	padding-top: 20px; 
	padding-bottom: 24px; 
	margin: 0px; 
	margin-bottom: 6px; 
	background-color: #ffffff;

}

.news_item_label {
	border: 1px solid #cccccc; 
	border-bottom: 0px; 
	width: 50%; 
	padding: 12px; 
	padding-top: 18px; 
	margin: 0px; 
	margin-left: 0px; 
	background-color: #dddddd;
}


.news_item_body {
	border: 2px solid #cccccc; 
	padding: 12px; 
	padding-top: 18px; 
	margin: 20px; 
	margin-left: 0px; 
	margin-top: 0px; 
	background-color: #ffffff;

}

blockquote.rewrite {

	color:  red;
}

</style>	

	<script src="../js/modernizr-2.6.2.min.js"></script>
	<!--[if lt IE 9]>
	<script src="js/respond.min.js"></script>
	<![endif]-->

	</head>
	<body class="boxed">
	<!-- Loader -->
	<div class="fh5co-loader"></div>

	<div id="wrap">

	<div id="fh5co-page">
		<header id="fh5co-header" role="banner">
			<div class="container">
				<a href="#" class="js-fh5co-nav-toggle fh5co-nav-toggle dark"><i></i></a>
				<div id="fh5co-logo"><a href="index.html"><img src="../images/website_header_top_march2018_v0.png" ></a></div>
				<nav id="fh5co-main-nav" role="navigation">
		          <ul>
		            
		            <li class="has-sub">
		              <div class="drop-down-menu">
		                <a href="#">Services</a>
		                <div class="dropdown-menu-wrap">
		                  <ul>
		                    
		                    <li><a href="../offerings/snowflake_services.html">Snowflake</a></li>
		                    <li><a href="../offerings/data_engineering.html">Data Engineering</a></li>
		                    <li><a href="../offerings/data_science.html">Data Science</a></li>

		                    <li><a href="../offerings/cloud_operations.html">Cloud Operations and Engineering</a></li>
		                    
		                    <li><a href="../offerings/managed_kubeflow.html">Managed Kubeflow</a></li>

		                    <li><a href="../offerings/managed_kafka.html">Managed Kafka</a></li>

		                    <li><a href="../offerings/research_partnerships.html">Research Partnerships</a></li>
		                    
		                  </ul>
		                </div>
		              </div>
		            </li>
		            
		            <li><a href="../partners.html">Partners</a></li>

		            <li><a href="../blog/blog_index.html">Blog</a></li>
		          
		            <li class="cta"><a href="../contact.html">Contact</a></li>
		          </ul>
		        </nav>
			</div>
		</header>
		<!-- Header -->

		
		<div id="fh5co-intro" class="fh5co-section">
			<div class="container">


		
				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">
						<h1>Detecting Credit Card Fraud with Snowflake, Snowpark, and SageMaker Studio</h1>
						<p>
							<h3>Part 3 of 3: Grid Search Model Construction with Sagemaker Studio Lab</h3>


						</p>
						<p>
							Author: Josh Patterson<br/>
							Date: zzzzzzz xxth, 2022
						</p>
						

						<p>
							Other entries in this series:

							<ul>

								<li>Part 1: <a href="creditcard_fraud_detection_w_snowflake_sagemaker_part_1.html">Loading the Credit Card Transaction Data Into Snowflake</a></li>
								<li>Part 2: <a href="creditcard_fraud_detection_w_snowflake_sagemaker_part_2.html">Scalable Feature Engineering with Snowpark</a></li>
								<li>Part 3: <a href="creditcard_fraud_detection_w_snowflake_sagemaker_part_3.html">Grid Search Model Construction with Sagemaker Studio Lab</a></li>
							</ul>


						</p>

						For more use cases like these, check out our <a href="http://www.pattersonconsultingtn.com/use_case_repository/finserv_vertical.html">Financial Services vertical</a> in our <a href="http://www.pattersonconsultingtn.com/use_case_repository/intro.html">Use Case Repository</a>.





					</div>

				</div>




				<!-- Section 1 of 5: Intro, PM in Cloud -->

				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">

						<h1>Introduction</h1>

						<p>
							In our last article ....

						</p>
					
						<p>
							Key Take Aways:
							<ol>
								<li>a</li>
								<li>b</li>
								<li>c</li>

							</ol>

						</p>

					</div>
				</div>

				<!-- Section 1 of 5: Intro, PM in Cloud -->




				<!-- Section 2 of 5: UCI Dataset -->

				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">


						<h1>What is AWS Sagemaker Studio Lab?</h1>

						<p>

							Reference: https://aws.amazon.com/blogs/machine-learning/load-and-transform-data-from-delta-lake-using-amazon-sagemaker-studio-and-apache-spark/							

						</p>

<blockquote class="rewrite">

 Amazon SageMaker is a fully managed service that provides a versatile workbench for building ML solutions and provides highly tailored tooling for data ingestion, data processing, model training, and model hosting						
</blockquote>


						<p>
							

							[ we have a lot of content from slides that go here ]
							
We will use SageMaker Studio Lab (SMSL)
AWS Recommends:
When you're starting a new notebook, we recommend that you create the notebook in Amazon SageMaker Studio instead of launching a notebook instance from the Amazon SageMaker console. 
And pimp the upgrade to Studio
Compare it to Google CoLab
Also: similar to Kubeflow UX
Request an account
https://studiolab.sagemaker.aws/
Getting data from Snowflake  to SMSL

						</p>


<p>
	<pre>
"Amazon SageMaker Studio Lab is cloud-hosted ML environment based on JupyterLab that is free to use and quick to set up for teaching, learning, and experimenting with ML"

1/ No-charge, no billing, no AWS account required
2/ Based on open-source JupyterLab, so you can install open-source JupyterLab extensions
3/ CPU (t3.xlarge) and GPU (g4dn.xlarge) option
4/ 15GB persistent storage and 16GB of RAM
5/ Git integration: Git command line and Git UI / Share content via GitHub
6/ You can export your projects and transition from Studio Lab to production-grade SageMaker if needed
7/ Package management: Persistent installation of pip/conda packages within notebooks and from command line
8/ Provides terminal access
</pre>

</p>


					</div>

				</div>


				<!-- Section 2 of 5: UCI Dataset -->


				<!-- Section 2 of 5: UCI Dataset -->

				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">


						<h1>Connecting SageMaker to Snowflake</h1>

						<p>

<blockquote class="rewrite">

In this post, we describe how to use SageMaker Studio notebooks to easily load and transform data stored in the Delta Lake format. We use a standard Jupyter notebook to run Apache Spark commands that read and write table data in CSV and Parquet format. The open-source library delta-spark allows you to directly access this data in its native format. This library allows you to take advantage of the many API operations to apply data transformations, make schema modifications, and use time-travel or as-of-timestamp queries to pull a particular version of the data.

In our sample notebook, we load raw data into a Spark DataFrame, create a Delta table, query it, display audit history, demonstrate schema evolution, and show various methods for updating the table data. We use the DataFrame API from the PySpark library to ingest and transform the dataset attributes. We use the delta-spark library to read and write data in Delta Lake format and to manipulate the underlying table structure, referred to as the schema.
</blockquote>

						</p>

<pre>

# Gets the version
ctx = snowflake.connector.connect(
  user=snowflake_username,
  password=snowflake_pwd,
  account=snowflake_acct
  )
cs = ctx.cursor()
try:
    cs.execute("SELECT current_version()")
    one_row = cs.fetchone()
    print(one_row[0])



    #cs.cursor().execute("USE WAREHOUSE tiny_warehouse_mg")
    #cs.execute("USE DATABASE PREDICTIVE_MAINTENANCE;")    
    cs.execute("USE DATABASE CREDIT_CARD_COMPANY_DB;")    


    #qry_out = 
    all_rows = cs.execute("select * FROM CUSTOMER_CC_TRANSACTION_FEATURES;")
    #all_rows = cs.execute("select TYPE, AIR_TEMPERATURE, PROCESS_TEMPERATURE, ROTATIONAL_SPEED, TORQUE, TOOL_WEAR, MACHINE_FAILURE  from SUMMARY_SENSOR_DATA;")
    df_cc_customer_txn_features = all_rows.fetch_pandas_all()

    #one_row = cs.fetchone()
    #print("Records with Failures: " + str(one_row[0]))

    #query_output = cs.execute( "select TYPE, AIR_TEMPERATURE, PROCESS_TEMPERATURE, ROTATIONAL_SPEED, TORQUE, TOOL_WEAR, MACHINE_FAILURE  from SUMMARY_SENSOR_DATA;" )

    #df_cc_customer_txn_features = qry_out.fetch_pandas_all() #.to_csv("/path/to/write/table.csv")	
    #df.to_csv("./data/full_snowflake_dataset.csv", index=False)	

    #print( df )


finally:
    cs.close()



ctx.close()
</pre>



					</div>

				</div>





				<!-- Section 2 of 5: UCI Dataset -->

				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">


						<h1>Grid Search with scikit-learn for Credit Card Fraud Detection AWS Sagemaker Studio Lab</h1>

						<p>
							what data did we start with?
							

						</p>


						<h2>Load Data from Snowflake</h2>

						<p>
							where did the data come from?

							[ give the original project some pub ]
							

						</p>

						<h2>Create Terminal Features</h2>

						<p>

reference original code

						</p>

<pre>
def get_count_risk_rolling_window(terminal_transactions, delay_period=7, windows_size_in_days=[1,7,30], feature="TERMINAL_ID"):
    
    terminal_transactions=terminal_transactions.sort_values('TX_DATETIME')
    
    terminal_transactions.index=terminal_transactions.TX_DATETIME
    
    NB_FRAUD_DELAY=terminal_transactions['TX_FRAUD'].rolling(str(delay_period)+'d').sum()
    NB_TX_DELAY=terminal_transactions['TX_FRAUD'].rolling(str(delay_period)+'d').count()
    
    for window_size in windows_size_in_days:
    
        NB_FRAUD_DELAY_WINDOW=terminal_transactions['TX_FRAUD'].rolling(str(delay_period+window_size)+'d').sum()
        NB_TX_DELAY_WINDOW=terminal_transactions['TX_FRAUD'].rolling(str(delay_period+window_size)+'d').count()
    
        NB_FRAUD_WINDOW=NB_FRAUD_DELAY_WINDOW-NB_FRAUD_DELAY
        NB_TX_WINDOW=NB_TX_DELAY_WINDOW-NB_TX_DELAY
    
        RISK_WINDOW=NB_FRAUD_WINDOW/NB_TX_WINDOW
        
        terminal_transactions[feature+'_NB_TX_'+str(window_size)+'DAY_WINDOW']=list(NB_TX_WINDOW)
        terminal_transactions[feature+'_RISK_'+str(window_size)+'DAY_WINDOW']=list(RISK_WINDOW)
        
    terminal_transactions.index=terminal_transactions.TRANSACTION_ID
    
    # Replace NA values with 0 (all undefined risk scores where NB_TX_WINDOW is 0) 
    terminal_transactions.fillna(0,inplace=True)
    
    return terminal_transactions

</pre>



						<h2>Split Dataset into Train and Test</h2>

						<p>

							yadda

						</p>

<pre>
	def get_train_test_set(transactions_df,
                       start_date_training,
                       delta_train=7,delta_delay=7,delta_test=7):
    
    # Get the training set data
    train_df = transactions_df[(transactions_df.TX_DATETIME&le;=start_date_training) &
                               (transactions_df.TX_DATETIME&ge;start_date_training+datetime.timedelta(days=delta_train))]
    
    # Get the test set data
    test_df = []
    
    # Note: Cards known to be compromised after the delay period are removed from the test set
    # That is, for each test day, all frauds known at (test_day-delay_period) are removed
    
    # First, get known defrauded customers from the training set
    known_defrauded_customers = set(train_df[train_df.TX_FRAUD==1].CUSTOMER_ID)
    
    # Get the relative starting day of training set (easier than TX_DATETIME to collect test data)
    start_tx_time_days_training = train_df.TX_TIME_DAYS.min()
    
    # Then, for each day of the test set
    for day in range(delta_test):
    
        # Get test data for that day
        test_df_day = transactions_df[transactions_df.TX_TIME_DAYS==start_tx_time_days_training+
                                                                    delta_train+delta_delay+
                                                                    day]
        
        # Compromised cards from that test day, minus the delay period, are added to the pool of known defrauded customers
        test_df_day_delay_period = transactions_df[transactions_df.TX_TIME_DAYS==start_tx_time_days_training+
                                                                                delta_train+
                                                                                day-1]
        
        new_defrauded_customers = set(test_df_day_delay_period[test_df_day_delay_period.TX_FRAUD==1].CUSTOMER_ID)
        known_defrauded_customers = known_defrauded_customers.union(new_defrauded_customers)
        
        test_df_day = test_df_day[~test_df_day.CUSTOMER_ID.isin(known_defrauded_customers)]
        
        test_df.append(test_df_day)
        
    test_df = pd.concat(test_df)
    
    # Sort data sets by ascending order of transaction ID
    train_df=train_df.sort_values('TRANSACTION_ID')
    test_df=test_df.sort_values('TRANSACTION_ID')
    
    return (train_df, test_df)

</pre>

						<h2>Pull in Helper Functions</h2>

						<p>
							yadda

						</p>

<pre>!curl -O https://raw.githubusercontent.com/Fraud-Detection-Handbook/fraud-detection-handbook/main/Chapter_References/shared_functions.py
%run shared_functions.py</pre>




						<h2>Define List of Models to Perform Grid Search</h2>

						<p>
							In our last series we did grid search.

							In this series we're going to try a new variant of grid search where we focus on gradient boosting methods do and hypertuning with <code>shap-hypetune</code>



						</p>

<blockquote class="rewrite">
Hyperparameters tuning and features selection are two common steps in every machine learning pipeline. Most of the time they are computed separately and independently. This may result in suboptimal performances and in a more time expensive process.

shap-hypetune aims to combine hyperparameters tuning and features selection in a single pipeline optimizing the optimal number of features while searching for the optimal parameters configuration. Hyperparameters Tuning or Features Selection can also be carried out as standalone operations.

</blockquote>

						<p>

https://github.com/cerlymarco/shap-hypetune
						</p>

						<p>

							TODO: ADD SOME ACTUAL "GRID SEARCH" TO THE CODE


						</p>

						<h3>Automated Feature Selection</h3>

						<p>




						</p>

<blockquote class="rewrite">

shap-hypetune aims to combine hyperparameters tuning and features selection in a single pipeline optimizing the optimal number of features while searching for the optimal parameters configuration. Hyperparameters Tuning or Features Selection can also be carried out as standalone operations.

</blockquote>


						<h2>Define Evaluation Function to Meet Our Goals for Fraud Detection</h2>

						<p>
							yadda

						</p>



						<h2>Define Performance Assessment Metric</h2>

						<p>
							yadda - mention discussion from last series

						</p>



						<h2>How do our <code>shap-hypetune</code> models compare to original models?</h2>

						<p>
							yadda 

						</p>


						<h2>Understanding Model Features with Shap</h2>

						<p>
							yadda 

						</p>

						<p>
<blockquote class="rewrite">

							SHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions (see papers for details and citations).
</blockquote>


						</p>



					</div>

				</div>


				<!-- Section 2 of 5: UCI Dataset -->



				<!-- Section 5 of 5: Next Steps: EDA -->
				<div class="row row-bottom-padded-sm">
					<div class="col-md-12" id="fh5co-content">
						
						<h1>Conclusion and Next Steps</h1>


						<p>


							In this post we ....

						</p>
						<p>
							todo

						</p>

					</div>

				</div>
				<!-- Section 5 of 5: Next Steps: EDA -->







				<div class="row row-bottom-padded-sm" style=" border: 1px solid #cccccc; border-radius: 10px; padding: 8px; padding-top: 8px; background-color: #FF5126; color: #ffffff; font-size: 14px; font-weight: normal; margin-bottom: 30px; ">
					
					<div class="col-md-3" id="fh5co-content" style="">

						<h3 style="color: #ffffff;">Looking for Snowflake Help?</h3>

					</div>
					<div class="col-md-9" id="fh5co-content" style="margin-bottom: 0px;">


						<div style="background-color: ; padding: 1px; margin-bottom: 0px;">
						<p style="margin: 0px;">
							Our team can help -- we help companies with <a href="../offerings/snowflake_services.html" style="color: #EEEEEE;">Snowflake platform operations, analytics, and machine learning</a>.

						</p>
						</div>
					</div>


				</div>		




			</div>
		</div>



		<footer id="fh5co-footer" role="contentinfo">
			<div class="container">
				<div class="row row-bottom-padded-sm">
					<div class="col-md-4 col-sm-12">
					</div>
					<div class="col-md-3 col-md-push-1 col-sm-12 col-sm-push-0">
						<div class="fh5co-footer-widget">
				

						</div>
					</div>
					<div class="col-md-3 col-md-push-2 col-sm-12 col-sm-push-0">
						
						<div class="fh5co-footer-widget">
							<h3>Follow us</h3>
							<ul class="fh5co-social">
								<li class="twitter"><a href="https://twitter.com/PattersonCnsltg"><i class="icon-twitter"></i></a></li>
								<li class="linkedin"><a href="https://www.linkedin.com/company/patterson-consulting-tn"><i class="icon-linkedin"></i></a></li>
								<li class="message"><a href="mailto:josh@pattersonconsultingtn.com"><i class="icon-mail"></i></a></li>
							</ul>
						</div>
					</div>

				</div>

			</div>
		</footer>


	</div>
	</div>

	<div class="gototop js-top">
		<a href="#" class="js-gotop"><i class="icon-chevron-down"></i></a>
	</div>
	
	<script src="../js/jquery.min.js"></script>
	<script src="../js/jquery.easing.1.3.js"></script>
	<script src="../js/bootstrap.min.js"></script>
	<script src="../js/owl.carousel.min.js"></script>
	<script src="../js/main.js"></script>

	</body>
</html>					
