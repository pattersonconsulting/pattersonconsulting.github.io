<!DOCTYPE html>
<html lang="en" data-bs-theme="light">
  <head>
    <meta charset="utf-8">

    <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1, maximum-scale=1, viewport-fit=cover">
    
    <title>Deploying Agents to MLflow</title>
    <meta name="description" content="This article explains how to turn a Python-based MLflow ResponsesAgent into a production-ready, versioned intelligence service by packaging it as a standardized model artifact, registering it in the MLflow Model Registry, and serving it reliably across environments.">
    <meta name="keywords" content="databricks, retail, lakeflow connect, CTAS, python, data pipeline, ETL, workflow automation">
    <meta name="author" content="Patterson Consulting Engineering Team">


    <meta property="og:title" content="Deploying Agents to MLflow"/>
    <meta property="og:image" content="https://pattersonconsultingtn.com/assets/img/deploying_agents_to_mlflow_header_0.jpg"/>
    <meta property="og:url" content="https://pattersonconsultingtn.com/blog/deploying_agents_to_mlflow.html"/>
    <meta property="og:site_name" content="Patterson Consulting"/>
    <meta property="og:description" content="This article explains how to turn a Python-based MLflow ResponsesAgent into a production-ready, versioned intelligence service by packaging it as a standardized model artifact, registering it in the MLflow Model Registry, and serving it reliably across environments."/>


    <meta name="twitter:title" content="Deploying Agents to MLflow" />
    <meta name="twitter:image" content="https://pattersonconsultingtn.com/assets/img/deploying_agents_to_mlflow_header_0.jpg" />
    <meta name="twitter:url" content="https://pattersonconsultingtn.com/blog/deploying_agents_to_mlflow.html" />
    <meta name="twitter:card" content="summary_large_image" />


    <link rel="manifest" href="/alpha_manifest.json">
    
    <link rel="icon" type="image/png" sizes="16x16" href="../assets/app-icons/pct_box_logo_16x16.png">
    <link rel="icon" type="image/png" sizes="32x32" href="../assets/app-icons/pct_box_logo_32x32.png">
        
    
    <script src="../assets/js/theme-switcher.js"></script>

    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&amp;display=swap" rel="stylesheet" id="google-font">


    <link rel="stylesheet" media="screen" href="../assets/vendor/swiper/swiper-bundle.min.css">
    <link rel="stylesheet" media="screen" href="../assets/vendor/lightgallery/css/lightgallery-bundle.min.css">

    <link rel="stylesheet" media="screen" href="../assets/vendor/aos/dist/aos.css">

    <link rel="stylesheet" href="../assets/icons/around-icons.min.css">

    <link rel="stylesheet" media="screen" href="../assets/css/theme.pct.v2.css">

    <link href="../assets/css/prism.css" rel="stylesheet" />


    <style>
      .page-loading {
        position: fixed;
        top: 0;
        right: 0;
        bottom: 0;
        left: 0;
        width: 100%;
        height: 100%;
        -webkit-transition: all .4s .2s ease-in-out;
        transition: all .4s .2s ease-in-out;
        background-color: #fff;
        opacity: 0;
        visibility: hidden;
        z-index: 9999;
      }
      [data-bs-theme="dark"] .page-loading {
        background-color: #121519;
      }
      .page-loading.active {
        opacity: 1;
        visibility: visible;
      }
      .page-loading-inner {
        position: absolute;
        top: 50%;
        left: 0;
        width: 100%;
        text-align: center;
        -webkit-transform: translateY(-50%);
        transform: translateY(-50%);
        -webkit-transition: opacity .2s ease-in-out;
        transition: opacity .2s ease-in-out;
        opacity: 0;
      }
      .page-loading.active > .page-loading-inner {
        opacity: 1;
      }
      .page-loading-inner > span {
        display: block;
        font-family: "Inter", sans-serif;
        font-size: 1rem;
        font-weight: normal;
        color: #6f788b;
      }
      [data-bs-theme="dark"] .page-loading-inner > span {
        color: #fff;
        opacity: .6;
      }
      .page-spinner {
        display: inline-block;
        width: 2.75rem;
        height: 2.75rem;
        margin-bottom: .75rem;
        vertical-align: text-bottom;
        background-color: #d7dde2; 
        border-radius: 50%;
        opacity: 0;
        -webkit-animation: spinner .75s linear infinite;
        animation: spinner .75s linear infinite;
      }
      [data-bs-theme="dark"] .page-spinner {
        background-color: rgba(255,255,255,.25);
      }
      @-webkit-keyframes spinner {
        0% {
          -webkit-transform: scale(0);
          transform: scale(0);
        }
        50% {
          opacity: 1;
          -webkit-transform: none;
          transform: none;
        }
      }
      @keyframes spinner {
        0% {
          -webkit-transform: scale(0);
          transform: scale(0);
        }
        50% {
          opacity: 1;
          -webkit-transform: none;
          transform: none;
        }
      }

      .todo_edit { 
        color: #ff0000;
       }

      .todo_consider { 
        color: #dddddd;
       }


      .working_outline { 
        color: #aaaaaa;
       }

       .todo_segue {
        color: #0000dd;
       }


       .todo_blue {
        color: #0000ff;
       }

       .narrative {
        color: #fc9003;
        font-weight: bold;
        font-style: italic;
       }


       .gpt-copy {
        color: #eb34db;
        font-weight: bold;
        font-style: italic;
       }

       .core_thesis {
        color: #777777;
        font-weight: bold;
        font-style: italic;
        margin-bottom: 50px;
        margin-left: 50px;
       }
       .narrative_scaffolding {

        color: #cccccc;
        
        font-style: italic;

       }


      .pre {
          display: block;
          unicode-bidi: embed;
          
          white-space: pre;
      }   
    </style>

    <script>
      (function () {
        window.onload = function () {
          const preloader = document.querySelector('.page-loading')
          preloader.classList.remove('active')
          setTimeout(function () {
            preloader.remove()
          }, 1500)

          const theme = 'light'
          document.documentElement.setAttribute('data-bs-theme', theme)
          

        }
      })()
    </script>

    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-N6H6PTM9');</script>
    </head>


  <body>


    <div class="page-loading active">
      <div class="page-loading-inner">
        <div class="page-spinner"></div>
        <span>Loading...</span>
      </div>
    </div>


    <main class="page-wrapper">

      <header data-bs-theme="light">
        <div class="navbar navbar-expand-lg fixed-top bg-light">
          <div class="container">

            <a class="navbar-brand pe-sm-3" href="../../index.html">
              <span class="text-primary flex-shrink-0 me-2">
                <svg width="35" height="32" viewBox="0 0 36 33" xmlns="http://www.w3.org/2000/svg">
                  <g transform="matrix(0.004459, 0, 0, -0.00433, -8154.369629, -2022.807495)" fill="#000000" stroke="none" style="transform-origin: 8189.37px 2055.78px;">
  <path d="M340 9410 l0 -260 1348 0 c807 0 1370 -4 1403 -9 30 -6 101 -15 159
-21 177 -19 447 -88 605 -155 242 -103 389 -186 553 -310 124 -94 287 -257
390 -390 26 -34 100 -148 140 -215 214 -362 327 -901 282 -1345 -11 -115 -47
-341 -58 -362 -5 -10 -14 -45 -21 -78 -7 -33 -16 -64 -20 -70 -4 -5 -13 -30
-20 -55 -7 -25 -19 -58 -26 -75 -70 -160 -92 -205 -132 -277 -45 -80 -161
-257 -189 -288 -8 -8 -33 -37 -56 -65 -60 -71 -200 -208 -277 -270 -88 -70
-241 -175 -258 -175 -7 0 -13 -3 -13 -8 0 -11 -304 -162 -326 -162 -3 0 -20
-7 -37 -14 -45 -21 -210 -74 -254 -82 -21 -4 -45 -10 -55 -15 -9 -5 -72 -18
-140 -30 -67 -12 -145 -26 -173 -31 -29 -6 -359 -12 -782 -15 l-733 -4 0
-1175 0 -1174 3270 0 3270 0 0 3695 0 3695 -3925 0 -3925 0 0 -260z" style="fill: rgb(255, 149, 0);"></path>
  <path d="M1650 6884 l0 -1096 648 4 647 4 120 28 c66 16 125 32 130 36 6 4 28
13 50 20 53 17 129 56 179 92 23 16 52 36 66 46 86 60 201 201 261 322 84 168
109 281 116 525 7 251 -18 402 -97 580 -56 126 -184 280 -295 355 -27 18 -62
42 -77 52 -15 10 -29 18 -32 18 -3 0 -30 11 -60 25 -30 14 -61 25 -68 25 -7 1
-31 8 -53 16 -101 37 -228 44 -892 44 l-643 0 0 -1096z" style="fill: rgb(255, 149, 0);"></path>
</g>



                </svg>
              </span>
              Patterson Consulting
            </a>


            <a class="btn btn-primary btn-sm fs-sm order-lg-3 d-none d-sm-inline-flex" href="../../contact_us.html" target="_blank" rel="noopener">
              <i class="fs-xl me-2 ms-n1"></i>
              Contact Us
            </a>

            <button class="navbar-toggler ms-sm-3" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-label="Toggle navigation">
              <span class="navbar-toggler-icon"></span>
            </button>

            <nav class="collapse navbar-collapse" id="navbarNav">
              <ul class="navbar-nav navbar-nav-scroll me-auto" style="--ar-scroll-height: 520px;">


                <li class="nav-item dropdown">
                  <a class="nav-link dropdown-toggle" href="#" data-bs-toggle="dropdown" aria-expanded="false">Industries</a>
                  <ul class="dropdown-menu">
                    
                    <li><a class="dropdown-item" href="../retail_industry.html">Retail</a></li>
                    <li><a class="dropdown-item" href="../insurance_industry.html">Insurance</a></li>
                    <li><a class="dropdown-item" href="../municipal_industry.html">Smart City</a></li>

                  </ul>
                </li>


                <li class="nav-item dropdown">
                  <a class="nav-link dropdown-toggle" href="#" data-bs-toggle="dropdown" data-bs-auto-close="outside" aria-expanded="false">Engineering Services</a>
                  <ul class="dropdown-menu">
                    <li><a class="dropdown-item" href="../offerings/migrations_to_databricks.html">Migration to Databricks</a></li>
                    <li><a class="dropdown-item" href="../platform_engineering.html">Platform Engineering</a></li>
                    <li><a class="dropdown-item" href="../data_engineering.html">Data Engineering</a></li>
                    <li><a class="dropdown-item" href="../generative_ai.html">GenAI Services</a></li>
                    </ul>

                </li>

                <li class="nav-item dropdown">
                  <a class="nav-link dropdown-toggle" href="#" data-bs-toggle="dropdown" data-bs-auto-close="outside" aria-expanded="false">Resources</a>
                  <ul class="dropdown-menu">
                    <li><a class="dropdown-item" href="../blog/blog_index.html">Blog</a></li>
                    <li><a class="dropdown-item" href="../publications.html">Team Publications</a></li>
                    <li><a class="dropdown-item" href="../index.html#case_studies">Case Studies</a></li>
                    <li><a class="dropdown-item" href="https://www.youtube.com/channel/UCmaki2Xq1AeFL8XbWGIWyQg">Videos</a></li>
                  </ul>

                </li>

                <li class="nav-item">
                  <a class="nav-link" href="../about.html">About</a>
                </li>
              </ul>
            </nav>

          </div>
        </div>
      </header>


      <section class="container py-5 mt-5 mb-md-2 mb-lg-3 mb-xl-4">

        <nav aria-label="breadcrumb">
          
          <ol class="pt-lg-3 pb-lg-4 pb-2 breadcrumb">
            <li class="breadcrumb-item"><a href="">Home</a></li>
            <li class="breadcrumb-item"><a href="./blog_index.html">Blog Index</a></li>
            <li class="breadcrumb-item active" aria-current="page">Deploying Agents to MLflow</li>
          </ol>
          
        </nav>

        <h1 class="display-4 text-left pb-2 pb-lg-3">Deploying Agents to MLflow</h1>

        <div class="d-flex flex-wrap align-items-center justify-content-between border-bottom mb-4">
              <div class="d-flex align-items-center mb-4 me-4">
                <span class="fs-sm me-2">By:</span>
                <a class="nav-link position-relative fw-semibold p-0" href="#author" data-scroll data-scroll-offset="80">
                  Patterson Consulting Engineering Team
                  <span class="d-block position-absolute start-0 bottom-0 w-100" style="background-color: currentColor; height: 1px;"></span>
                </a>
              </div>

            </div>

      </section>


      <section class="jarallax" data-jarallax data-speed=".65">
        <div class="jarallax-img bg-position-center-y" style="background-image: url(../assets/img/deploying_agents_to_mlflow_header_0.jpg);"></div>
        <div class="d-none d-xxl-block" style="height: 600px;"></div>
        <div class="d-none d-xl-block d-xxl-none" style="height: 650px;"></div>
        <div class="d-none d-lg-block d-xl-none" style="height: 500px;"></div>
        <div class="d-none d-md-block d-lg-none" style="height: 400px;"></div>
        <div class="d-md-none" style="height: 300px;"></div>
      </section>

















      <section class="container pt-5 mt-md-2 mt-lg-3 mt-xl-4">
        <div class="row justify-content-center pt-xxl-2">
          <div class="col-lg-9 col-xl-8">




<p class="fs-lg">
  There are a lot of latent challenges around the management of agents for integration into your enteprise application.
</p>

<p class="fs-lg">
In the <a href="building_mlflow_responseagent_agents.html" target="_blank">previous article</a>, we built a <strong>ResponsesAgent</strong>—a Python-defined agent containing instructions, contextual data access, reasoning logic, and an LLM backend with enough “horsepower” to support generative AI applicaitions. Building an agent is only the first milestone. 

To make it usable in real applications, the agent must be <strong>packaged</strong>, <strong>registered</strong>, <strong>versioned</strong>, and <strong>served</strong> through MLflow’s model ecosystem.
</p>
<!--
<p class="fs-lg todo_edit">

The next step is to turn that agent into something deployable. That requires packaging the agent so MLflow can version it, serve it, and provide a stable inference interface to downstream applications. Packaging is simply the process of taking your agent’s code, prompts, configuration files, and dependency metadata and bundling them into an MLflow model artifact. 

This artifact contains the agent implementation once—its Python modules, configuration, and supporting resources—so that a model server can load it consistently without recreating or copying these assets on every inference call.
</p>
-->

<p class="fs-lg">
In the <a href="architecture_patterns_for_integrating_agents_into_knowledge_work.html" target="_blank">first article in our series on MLflow</a> we discussed 3 generalized architecture for building generative AI application. In the image below you can see the decision intelligence architecture that is a great example to keep in mind while we deploy our agent in this article.
</p>


<div class="hotspots mx-auto mt-5 mb-5" style="max-width: 1200px;">
  <img class="d-block img-thumbnail rounded-0" src="../assets/img/arch_pattern_integration_mlflow_agent_server.png" alt="MLflow as Agent Server">
</div>

<p class="fs-lg">
This article focuses on the two major steps after authoring an agent:
</p>

<ol>
  <li class="fs-lg">
    <strong>Packaging</strong> the agent so MLflow can serialize its code, prompts, configuration, and dependencies into a deployable model artifact.
  </li>
  <li class="fs-lg">
    <strong>Registering</strong> the agent in the MLflow Model Registry so it can be versioned, promoted, and deployed consistently across environments.
  </li>
</ol>

<p class="fs-lg">
By the end, you will have a <code>ResponsesAgent</code> published in the <a href="https://mlflow.org/docs/latest/ml/model-registry/" target="_blank">MLflow Model Registry</a>, served as an HTTP microservice, and verified to be operational.
</p>




<h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">Packaging the ResponsesAgent</h2>

<p class="fs-lg">
Packaging is the process of turning your agent’s Python implementation into a <strong>standardized MLflow model artifact</strong>. This artifact is what the model server loads to perform inference, ensuring consistent behavior across environments—local development, Databricks Model Serving, or self-hosted MLflow servers.
</p>


<p class="fs-lg">
Packaging takes your in-code ResponsesAgent definition:
</p>

<pre class="line-numbers mt-5 mb-5"><code class="lang-python">import mlflow
from mlflow.pyfunc import ResponsesAgent

from mlflow.types.responses import (
    ResponsesAgentRequest,
    ResponsesAgentResponse
)

class MyMinimalAgent(ResponsesAgent):

    def load_context(self, context):
        pass

    #def predict(self, model_input):
    def predict(self, request: ResponsesAgentRequest) -> ResponsesAgentResponse:
        return ResponsesAgentResponse(
                    output=[
                        # "id" can be any stable string you choose for this output item
                        self.create_text_output_item(text="hello world", id="msg_1"),
                    ]
                )
</code></pre>

<p class="fs-lg pt-3">
…and turns it into a <strong>portable, immutable snapshot</strong> that contains:
</p>

<ul>
  <li class="fs-lg">The agent’s Python code</li>
  <li class="fs-lg">Prompt templates and YAML configuration</li>
  <li class="fs-lg">Tool definitions</li>
  <li class="fs-lg">LLM client dependencies</li>
  <li class="fs-lg">The MLmodel metadata file</li>
  <li class="fs-lg">Any additional resources (e.g., embeddings, retrieval index pointers)</li>
</ul>

<p class="fs-lg">
MLflow bundles these assets so the model server does not need access to your development environment.
</p>



<h3 class="h3 mb-lg-4 pt-3 pt-md-4 pt-xl-5">What physical assets are produced?</h3>

<p class="fs-lg mb-3">
When packaged, the agent becomes a directory inside the MLflow run’s artifact store:
</p>

<pre class="line-numbers"><code>
artifacts/
    my_agent/
        MLmodel
        python_env.yaml  (or conda.yaml)
        code/
            my_agent_code.py
            tools/
            prompts/
        artifacts/
            config/
            resource_files/
</code></pre>

<p class="fs-lg mt-5">
The <strong>MLmodel</strong> file describes how the agent should be reconstructed and which Python class implements inference.
The <strong>code/ directory</strong> contains exactly the agent source code you provided through <code>code_paths=...</code>.
</p>







<h3 class="h3 mb-lg-4 pt-3 pt-md-4 pt-xl-5">Add the Model to the MLflow Tracking Server by Logging the Model</h3>

<p class="fs-lg">
You send the package by <strong>logging the model</strong> with the call <code>mlflow.pyfunc.log_model(...)</code>. Logging is the act of serializing the agent into the MLflow tracking server’s artifact store.
</p>

<p class="fs-lg ">
Logging an agent establishes a fixed snapshot of its code and configuration at a specific point in time, enabling consistent evaluation of quality, behavior, and performance as the agent evolves. This snapshot provides a stable reference for experimentation, regression testing, and comparison across iterations of the agent’s design.
</p>







            <div class="card bg-primary bg-opacity-10 border-0 overflow-hidden pt-1 pt-xl-2 px-lg-2 px-xl-4 mb-5 mt-5">
              <div class="card-body position-relative z-2 pb-0">
                <h3 class="h4 card-title text-primary">Models from Code</h3>


                <p class="pb-sm3 pb-md-4 mb-2">

Databricks recommends using <a href="https://mlflow.org/docs/latest/ml/model/models-from-code/" target="_blank">MLflow's Models from Code</a> capability for this workflow. Under this approach, the agent’s implementation is stored as a Python file, and its execution environment is recorded as a set of required packages. When the agent is deployed, MLflow reconstructs the environment and executes the Python file to load the agent into memory so it can serve inference requests reliably and consistently across deployments.

                </p>




              </div>
            </div>


<h4 class="h4 mb-lg-4 pt-3 pt-md-4 pt-xl-5">Models from Code Approach: Packaging via PyFunc</h4>

<p class="fs-lg">
Once you have your ResponsesAgent defined, then you'll need to log it with the tracking server to get started with your deployment as seen in the code below.
</p>

<pre class="line-numbers mb-3"><code class="language-python">
    agent = helloworld.MyMinimalAgent()

    with mlflow.start_run():
        logged = mlflow.pyfunc.log_model(
            name="MyMinimalAgent",
            python_model=agent,
        )
        run_id = mlflow.active_run().info.run_id

    print("Model URI:", logged.model_uri)
    print("Run ID: ", run_id)
</code></pre>

<p class="fs-lg">
Note: <code>artifact_path</code> defines the directory inside the MLflow Run’s artifact store where the model will be logged.
</p>

<p class="fs-lg">
When you call <code>mlflow.pyfunc.log_model()</code>, MLflow must place the serialized model (its MLmodel file, code assets, environment spec, and dependencies) somewhere within the run’s artifact hierarchy. The <code>artifact_path</code> value becomes the subdirectory name under that run.
</p>

<p class="fs-lg">
You can also provide a python file that contains a <code>ResponsesAgent</code> subclassed agent definition as well for the <code>python_model</code>.

</p>

<p class="fs-lg">
  <strong>In that case, inside the python file you'll need to provide a <code>mlflow.models.set_model()</code> call.</strong>
</p>

<p class="fs-lg">
The <code>mlflow.models.set_model()</code> API is a fluent interface used with the <a href="https://mlflow.org/docs/latest/ml/model/models-from-code/" target="_blank">"Models from Code"</a> feature in MLflow, which programmatically defines an MLflow model within a Python script. 

<code>mlflow.models.set_model()</code> is a packaging-time hook used with Models from Code to tell MLflow “this is the actual ResponsesAgent object to package in this file.”

It tells MLflow which Python object in the script is the model to be logged. 
</p>

<p class="fs-lg">
Once we have our model URI from MLflow, we want to register the agent in the MLFlow Model Registry to manage its lifecycle.

</p>












            <div class="card bg-primary bg-opacity-10 border-0 overflow-hidden pt-1 pt-xl-2 px-lg-2 px-xl-4 mb-5 mt-5">
              <div class="card-body position-relative z-2 pb-0">
                <h3 class="h4 card-title text-primary">What Does <code>mlflow.start_run()</code> Do?</h3>


                <p class="pb-sm3 pb-md-4 mb-2">

  <strong>What does <code>mlflow.start_run()</code> do in MLflow 3.6?</strong><br><br>
  <code>mlflow.start_run()</code> creates (or resumes) a run context—a structured container where MLflow logs everything associated with an execution, such as:

                </p>




              <ul class="fs-lg">
                <li>Parameters</li>
                <li>Metrics</li>
                <li>Artifacts (files, code, prompt assets, knowledge bases, etc.)</li>
                <li>Logged models and agents</li>
                <li>Run metadata (timestamps, status, user, environment, etc.)</li>
              </ul>

              <p class="pb-sm3 pb-md-4 mb-2">
                It’s like pressing the “Record” button: everything you log inside this context is versioned and attached to that run.
              </p>


<p class="pb-sm3 pb-md-4 mb-2">
  A run is the atomic tracked execution in MLflow—it represents a single attempt to create or update a model or agent. But its purpose differs slightly depending on the asset type.
</p>




<p class="pb-sm3 pb-md-4 mb-2">

  A run represents a training lifecycle event, such as:
</p>

<ul class="fs-lg">
  <li>Training a regression model</li>
  <li>Fine-tuning a neural network</li>
  <li>Running feature experiments</li>
</ul>

<p class="pb-sm3 pb-md-4 mb-2">
  It captures the full lineage of the model including inputs, outputs, and lifecycle. So if you retrain tomorrow you get a new run.
</p>



<p class="pb-sm3 pb-md-4 mb-2">
<storng>Ok, but how does this relate to agents?</storng>
</p>


<p class="pb-sm3 pb-md-4 mb-2">
  <strong>A run represents the packaging and publishing event: defining agent behavior (system prompt, tools, routing logic), bundling assets (text files, embeddings, yaml configs), and versioning the code and prompt instructions.</strong>
</p>

<p class="pb-sm3 pb-md-4 mb-2">
  Agents aren’t trained—they’re versioned and governed like other MLflow models. A ResponsesAgent run is basically: “I am capturing how this agent works at this moment in time and what it depends on.”
</p>




              </div>
            </div>
























<h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">Registering the Agent with the MLflow Model Registry</h2>

<p class="fs-lg">
Once packaged, the agent must be <strong>registered</strong> in the Model Registry. This is where lifecycle operations occur—versioning, promotion, rollback, and auditability.
</p>




<p class="fs-lg">
If you logged the agent with <code>registered_model_name=...</code>, MLflow automatically created a model version. If not, you can manually register:
</p>


<pre class="line-numbers"><code class="language-python">
registered_model_name = "MyMinimalAgent_Registered"
registered_model_stage = "candidate"

mv = mlflow.register_model(register_full_model_uri, registered_model_name)
</code></pre>
<!--
<pre class="line-numbers"><code class="language-python">
model_uri = "runs:/&lt;RUN_ID&gt;/hello_world_agent"
mlflow.register_model(model_uri, "retail.ai.hello_world_agent")
</code></pre>
-->
<p class="fs-lg mt-3">
This creates <strong>Version 1</strong> of the model.
</p>

<p class="fs-lg">
  Just to be clear in how the lifecycle works and how its different from the packaging phase above, I want again state:
</p>

<ul>
  <li>
<code>mlflow.models.set_model()</code> is a packaging-time hook used with Models from Code to tell MLflow “this is the actual ResponsesAgent object to package in this file.”
</li>
  <li>
<code>mlflow.register_model()</code> is a lifecycle/registry API used after logging to create a named, versioned entry for that agent in the Model Registry (Unity Catalog or workspace).
</li>
</ul>

<p class="fs-lg">
They solve completely different problems in the deployment pipeline.
</p>

<h4 class="h4 mb-lg-4 pt-3 pt-md-4 pt-xl-5">Managing the Agent Lifecycle</h4>

<p class="fs-lg">
As you refine the agent—improved prompts, updated tools, different reasoning logic—new versions are created. The code listing below shows how to programmatically get the latest version number of your model.
</p>

<pre class="line-numbers mt-3 mb-3"><code class="language-python">
client = MlflowClient()
client.get_model_version_by_alias(
    name="MyMinimalAgent_Registered",
    alias="candidate"
)
</code></pre>




<p class="fs-lg">
Once you are satisfied with the performance of your agent, you can promote it to a <code>staging</code> or <code>production</code> status in the model registry, as shown in the python code listing below.

</p>
<!--
<pre class="line-numbers"><code class="language-python">
client.transition_model_version_stage(
    name="retail.ai.hello_world_agent",
    version=3,
    stage="Production"
)
</code></pre>
-->

<pre class="line-numbers"><code class="language-python">
  client = MlflowClient()
client.set_registered_model_alias(
    name="MyMinimalAgent_Registered",
    alias="prod",
    version="7"
)
</code></pre>


<p class="fs-lg">
Additionally the URI format to load a ResponseAgent registered agent is shown in the example below.

</p>

<pre class="line-numbers"><code class="language-python">
registered_model_name = "MyMinimalAgent_Registered"
registered_model_stage = "prod"
load_full_model_uri = "models:/" + registered_model_name + "@" + registered_model_stage
model = mlflow.pyfunc.load_model(load_full_model_uri)
</code></pre>


            <div class="card bg-primary bg-opacity-10 border-0 overflow-hidden pt-1 pt-xl-2 px-lg-2 px-xl-4 mb-5 mt-5">
              <div class="card-body position-relative z-2 pb-0">
                <h3 class="h4 card-title text-primary">Aliases Replace Stages in MLflow 3.x</h3>


                <p class="pb-sm3 pb-md-4 mb-2">

Stages are being removed and how aliases replace them in MLflow 3.x.


                </p>

                <p class="pb-sm3 pb-md-4 mb-2">
Why?

</p>
                <p class="pb-sm3 pb-md-4 mb-2">

Model stages encoded a global, mutually exclusive lifecycle state that proved too rigid for modern CI/CD, multi-environment deployments, and parallel serving patterns. Model aliases replace stages with explicit, versioned routing pointers that enable safe promotion, instant rollback, and concurrent deployments without ambiguity.


                </p>


              </div>
            </div>










<p class="fs-lg">
Downstream consuming applications can then not worry about model versions and just focus on working with the aliased <code>staging</code> or <code>production</code> (or whichever alias system you designate) model provided.

</p>

<p class="fs-lg">
A best practice is that applications should reference the alias, not a specific version number:
</p>

<pre class="line-numbers"><code>
models:/retail.ai.logistics_agent@Production
</code></pre>

<p class="fs-lg mt-4">
This allows version 3 → version 4 promotion without breaking downstream systems.
</p>




<h3 class="h3 mb-lg-4 pt-3 pt-md-4 pt-xl-5">Confirm the model is operational</h3>

<p class="fs-lg">
You can load and test the deployed agent locally:
</p>

<pre class="line-numbers"><code class="language-python">
registered_model_name = "MyMinimalAgent_Registered"
registered_model_stage = "prod"
load_full_model_uri = "models:/" + registered_model_name + "@" + registered_model_stage
model = mlflow.pyfunc.load_model(load_full_model_uri)

result = model.predict({
    "input": [
        {"role": "user", "content": "Why is OTIF down this week?"}
    ]
})

print(result)   
</code></pre>

<p class="fs-lg mt-5">
Or test the HTTP-serving endpoint --- start by taking the registered model alias and starting a dedicated model server:
</p>

<pre class="line-numbers"><code class="language-python">
mlflow models serve \
  --model-uri models:/MyMinimalAgent_Registered_2@prod \
  --host 0.0.0.0 \
  --port 5000 \
  --no-conda
</code></pre>


<p class="fs-lg mt-5">
Once the server is running, the REST inference endpoint is:
</p>

<pre class="line-numbers"><code class="language-python">
POST http://localhost:5000/invocations
</code></pre>

<p class="fs-lg mt-5">
This endpoint is <strong>always /invocations for the MLflow model server.</strong>
</p>

<p class="fs-lg">
Once we have our model server running we can test it with a python program such as:
</p>

<pre class="line-numbers"><code class="language-python">
import requests

payload = {
    "input": [
        {"role": "user", "content": "Why is OTIF down this week?"}
    ]
}

response = requests.post(
    "http://localhost:5001/invocations",
    json=payload
)

print("Testing hello world registered mlflow ResonsesAgent:")
print(response.json())

</code></pre>

<p class="fs-lg">
Your response should look similar to:
</p>

<pre class="line-numbers"><code class="language-python">
python test_hello_world_model_server.py
Testing hello world registered mlflow ResonsesAgent:
{'object': 'response', 'output': [{'type': 'message', 'id': 'msg_1', 'content': [{'text': 'hello world', 'type': 'output_text'}], 'role': 'assistant'}]}
</code></pre>


<br/><br/>

                  <div class="card overflow-hidden mb-4 mt-4 bg-dark" data-bs-theme="dark">
                    <div class="row g-0">
                      
                      <div class="col-sm-4 bg-repeat-0 bg-size-cover" style="background-image: url(../assets/img/mlflow_responseagent_header_0.jpg); min-height: 14rem;background-position: center center;" ></div>
                      
                      <div class="col-sm-8">
                        <div class="card-body">
                          <h2 class="h2 card-title" ><a href="../accelerated_agents_for_databricks.html" style="color: #FFFFFF;">Agent Accelerator</a></h2>
                          <h4 class="h3 card-title"><a href="../accelerated_agents_for_databricks.html"  style="color: #cccccc;">For the <span style="color: rgb(255, 149, 0);">Databricks</span> Platform</a></h4>


                          <p class="card-text">
A 4-week engagement that delivers a custom Decision Intelligence agent on Databricks—grounded in a clear decision owner, explicit business rules, and governed Unity Catalog data models—then deployed to a Databricks Agent Endpoint for testing and production rollout.
</p>


                <a class="btn btn-lg btn-link px-0" href="../accelerated_agents_for_databricks.html">
                  Learn More
                  <i class="ai-arrow-right ms-2"></i>
                </a>
                          

                        </div>
                      </div>
                    </div>
                  </div>




<h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">Summary</h2>

<p class="fs-lg">
Packaging and registering a ResponsesAgent transforms it from a Python class into a <strong>versioned, deployable intelligence service</strong>. Once the agent is logged and registered:
</p>

<ul>
  <li class="fs-lg">The model registry tracks every change</li>
  <li class="fs-lg">The serving system loads a stable artifact</li>
  <li class="fs-lg">Each prediction call is repeatable and observable</li>
  <li class="fs-lg">Multiple agent versions can be promoted without code changes</li>
</ul>

<p class="fs-lg">
With our agent now fully deployed, the next article will focus on <strong>integrating the agent into applications</strong>—including web dashboards, workflow automation, RPA extensions, BI tools, and microservices. You will see how a deployed MLflow agent becomes a knowledge-work accelerant embedded directly inside operational software.
</p>


<!--

<hr/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>



























<h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">Managing LLM Access Secret Tokens</code></h2>
<p class="fs-lg todo_edit">
  TODO
</p>




<h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">How MLflow Model Serving Handles Authentication and Authorization</h2>

<p class="fs-lg">
  By default, MLflow model serving does <strong>not</strong> enforce a strong, built-in authentication/authorization layer — you need to add external or surrounding infrastructure for production-grade security. ([protectai.com](https://protectai.com/blog/hacking-ai-steal-models-from-mlflow-no-exploit-needed?utm_source=chatgpt.com))  
</p>

<p class="fs-lg">
  Here’s a breakdown of how MLflow handles auth/authorization (or doesn’t), what features exist, and what you need to do if you care about security.  
</p>

<h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">What MLflow can (optionally) do</h2>

<ul class="fs-lg">
  <li>MLflow offers a basic HTTP authentication mechanism, which can be enabled to restrict access to the tracking server, model registry, and registered models. ([mlflow.org](https://mlflow.org/docs/latest/self-hosting/security/basic-http-auth/?utm_source=chatgpt.com))</li>
  <li>When this basic auth is enabled, only authenticated users can list experiments, retrieve model metadata, or perform registry operations — that helps protect model artifacts and metadata. ([mlflow.org](https://www.mlflow.org/docs/3.3.0/ml/auth/?utm_source=chatgpt.com))</li>
  <li>MLflow’s “custom serving applications” feature documentation mentions “built-in authentication and authorization” support. ([mlflow.org](https://mlflow.org/docs/3.3.1/genai/serving/custom-apps/?utm_source=chatgpt.com))</li>
</ul>

<h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">What you should know: defaults &amp; limitations</h2>

<ul class="fs-lg">
  <li>By default, a standard MLflow model server (e.g. via <code>mlflow models serve</code>) comes with <strong>no authentication or authorization</strong>. If you just run it “out-of-the-box,” anyone who can reach the endpoint can invoke predictions. ([protectai.com](https://protectai.com/blog/hacking-ai-steal-models-from-mlflow-no-exploit-needed?utm_source=chatgpt.com))</li>
  <li>The basic auth feature applies to MLflow’s tracking server / registry — but depending on your deployment (especially serving endpoints), it may not automatically gate the inference API. In other words: permissions that protect model metadata do not necessarily protect the runtime inference endpoint.</li>
  <li>Basic HTTP auth is fairly rudimentary: it doesn’t provide fine-grained permissions (e.g. “user A can read models, user B can’t”) with anything like role-based ACLs out-of-the-box. ([community-charts.github.io](https://community-charts.github.io/docs/charts/mlflow/authentication-configuration?utm_source=chatgpt.com))</li>
  <li>For many production uses, relying solely on MLflow’s auth is unsafe — especially if the model server is reachable beyond a private network or inside a shared environment. This is echoed in warnings that simply placing the MLflow server behind a firewall isn’t sufficient security. ([protectai.com](https://protectai.com/blog/hacking-ai-steal-models-from-mlflow-no-exploit-needed?utm_source=chatgpt.com))</li>
</ul>

<h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">What you should do to secure MLflow model serving in production</h2>

<ul class="fs-lg">
  <li>Place the model-serving endpoint behind a reverse proxy / API gateway (e.g., NGINX, Traefik, AWS ALB, Kong) that enforces <strong>authentication (OAuth, API tokens)</strong> and <strong>authorization</strong> (who can call what).</li>
  <li>Use network-level controls (e.g. VPC, firewall rules) to restrict access to the serving endpoint — ideally make it accessible only from internal services or VPN.</li>
  <li>If you’re using the basic auth for the tracking/registry server, keep credentials in a secure store (avoid hardcoding), use HTTPS to avoid leaking credentials, and limit default permissions as strictly as possible.</li>
  <li>Audit / log requests: wrap serving calls via a layer that does authentication + logging + rate limiting to prevent misuse.</li>
</ul>

<h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">Why this matters (especially for production / sensitive models)</h2>

<p class="fs-lg">
  Because MLflow’s serving is designed for convenience and rapid deployment, it's easy to spin up a model serving endpoint quickly — but that comes with tradeoffs in security. If a model server is exposed unchecked, anyone could call it, possibly abuse resources, or extract proprietary models/data. Because of that risk, many teams treat MLflow’s built-in features as minimal baseline and rely on external infrastructure for hardened deployment.
</p>
-->

          </div>
        </div>
      </section>










      <section class="container pt-5 mt-md-2 mt-lg-3 mt-xl-4">


            
            <div class="d-flex flex-wrap pb-5 pt-3 pt-md-4 pt-xl-5 mt-xl-n2 pl-3">
              <h3 class="h3 py-1 mb-0 me-4">Next in Series</h3>
            </div>



                  <div class="card overflow-hidden mb-4">
                    <div class="row g-0">
                      <div class="col-sm-4 bg-repeat-0 bg-size-cover" style="background-image: url(../assets/img/integrating_mlflow_endpoints_header_0.jpg); min-height: 14rem;"></div>
                      <div class="col-sm-8">
                        <div class="card-body">
                          <h4 class="card-title">Integrating Applications with Deployed MLflow Agent Endpoints</h4>
                          <p class="card-text">MLflow ResponsesAgents enable organizations to embed production-grade, automated reasoning directly into applications, workflows, and decision systems—moving generative AI beyond chat interfaces and into scalable, governed operational intelligence.</p>
                          
                <a class="btn btn-lg btn-link px-0" href="integrating_mlflow_endpoints.html">
                  Read next article in series
                  <i class="ai-arrow-right ms-2"></i>
                </a>

                        </div>
                      </div>
                    </div>
                  </div>

      </section>
   




    </main>

    

  <footer class="footer py-5 bg-dark" data-bs-theme="dark">
      <div class="container pt-md-2 pt-lg-3 pt-xl-4">
        <div class="row pb-5 pt-sm-2 mb-lg-2">
          <div class="col-md-4 col-lg-3 pb-2 pb-md-0 mb-4 mb-md-0">


            <a class="navbar-brand pe-sm-3" href="/index.html">
              <span class="text-primary flex-shrink-0 me-2">
                <svg width="35" height="32" viewBox="0 0 36 33" xmlns="http://www.w3.org/2000/svg">

                  <g transform="matrix(0.004459, 0, 0, -0.00433, -8154.369629, -2022.807495)" fill="#000000" stroke="none" style="transform-origin: 8189.37px 2055.78px;">
                    <path d="M340 9410 l0 -260 1348 0 c807 0 1370 -4 1403 -9 30 -6 101 -15 159
                  -21 177 -19 447 -88 605 -155 242 -103 389 -186 553 -310 124 -94 287 -257
                  390 -390 26 -34 100 -148 140 -215 214 -362 327 -901 282 -1345 -11 -115 -47
                  -341 -58 -362 -5 -10 -14 -45 -21 -78 -7 -33 -16 -64 -20 -70 -4 -5 -13 -30
                  -20 -55 -7 -25 -19 -58 -26 -75 -70 -160 -92 -205 -132 -277 -45 -80 -161
                  -257 -189 -288 -8 -8 -33 -37 -56 -65 -60 -71 -200 -208 -277 -270 -88 -70
                  -241 -175 -258 -175 -7 0 -13 -3 -13 -8 0 -11 -304 -162 -326 -162 -3 0 -20
                  -7 -37 -14 -45 -21 -210 -74 -254 -82 -21 -4 -45 -10 -55 -15 -9 -5 -72 -18
                  -140 -30 -67 -12 -145 -26 -173 -31 -29 -6 -359 -12 -782 -15 l-733 -4 0
                  -1175 0 -1174 3270 0 3270 0 0 3695 0 3695 -3925 0 -3925 0 0 -260z" style="fill: rgb(255, 149, 0);"></path>
                    <path d="M1650 6884 l0 -1096 648 4 647 4 120 28 c66 16 125 32 130 36 6 4 28
                  13 50 20 53 17 129 56 179 92 23 16 52 36 66 46 86 60 201 201 261 322 84 168
                  109 281 116 525 7 251 -18 402 -97 580 -56 126 -184 280 -295 355 -27 18 -62
                  42 -77 52 -15 10 -29 18 -32 18 -3 0 -30 11 -60 25 -30 14 -61 25 -68 25 -7 1
                  -31 8 -53 16 -101 37 -228 44 -892 44 l-643 0 0 -1096z" style="fill: rgb(255, 149, 0);"></path>
                  </g>

                </svg>
              </span>
              <span class="text-light">
              Patterson Consulting
              </span>
            </a>    

            <p class="fs-sm pb-2 pb-md-3 mb-3 text-light">Delivering data pipelines, analytics, and large language model applications.</p>
            <div class="d-flex gap-3">
              <a class="btn btn-icon btn-sm btn-secondary btn-linkedin rounded-circle" href="https://www.linkedin.com/company/patterson-consulting-tn/" aria-label="LinkedIn">
                <i class="ai-linkedin"></i>
              </a>
            </div>
          </div>
          <div class="col-md-8 col-lg-7 col-xl-6 offset-lg-2 offset-xl-3">
            <div class="row row-cols-1 row-cols-sm-3">
              <div class="col mb-4 mb-md-0">
              </div>
              <div class="col mb-4 mb-md-0">

              </div>
              <div class="col mb-4 mb-md-0">
                <h4 class="h6 fw-bold pb-lg-1">Company</h4>
                <ul class="nav flex-column">
                  <li><a class="nav-link fw-normal py-1 px-0" href="/contact_us.html">Contact Us</a></li>
                  <li><a class="nav-link fw-normal py-1 px-0" href="/blog/blog_index.html">Blog</a></li>
                  <li><a class="nav-link fw-normal py-1 px-0" href="/index.html#case_studies">Case Studies</a></li>
                  <li><a class="nav-link fw-normal py-1 px-0" href="/publications.html">eBooks</a></li>
                  <li><a class="nav-link fw-normal py-1 px-0" href="https://www.youtube.com/channel/UCmaki2Xq1AeFL8XbWGIWyQg">Videos</a></li>
                  <li><a class="nav-link fw-normal py-1 px-0" href="/about.html">About</a></li>
                </ul>
              </div>
            </div>
          </div>
        </div>
        <p class="nav fs-sm mb-0">
          <span class="text-body-secondary">© All rights reserved. Made by</span>
          <a class="nav-link fw-normal p-0 ms-1" href="https://www.pattersonconsultingtn.com/" target="_blank" rel="noopener">Patterson Consulting</a>
        </p>
      </div>
    </footer>    


    <a class="btn-scroll-top" href="#top" data-scroll aria-label="Scroll back to top">
      <svg viewBox="0 0 40 40" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
        <circle cx="20" cy="20" r="19" fill="none" stroke="currentColor" stroke-width="1.5" stroke-miterlimit="10"></circle>
      </svg>
      <i class="ai-arrow-up"></i>
    </a>



  <script src="../assets/js/prism.js"></script>

    <script src="../assets/vendor/jarallax/dist/jarallax.min.js"></script>
    <script src="../assets/vendor/swiper/swiper-bundle.min.js"></script>
    


    <script src="../assets/vendor/swiper/swiper-bundle.min.js"></script>
    <script src="../assets/vendor/lightgallery/lightgallery.min.js"></script>


    <script src="../assets/vendor/lightgallery/plugins/fullscreen/lg-fullscreen.min.js"></script>
    <script src="../assets/vendor/lightgallery/plugins/zoom/lg-zoom.min.js"></script>
    <script src="../assets/vendor/lightgallery/plugins/video/lg-video.min.js"></script>
    <script src="../assets/vendor/lightgallery/plugins/thumbnail/lg-thumbnail.min.js"></script>



    <script src="../assets/js/theme.min.js"></script>
  </body>
</html>

