<!DOCTYPE html>
<html lang="en" data-bs-theme="light">
  <head>
    <meta charset="utf-8">

    <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1, maximum-scale=1, viewport-fit=cover">
    
    <title>Deploying Agents to MLflow</title>
    <meta name="description" content="...">
    <meta name="keywords" content="databricks, retail, lakeflow connect, CTAS, python, data pipeline, ETL, workflow automation">
    <meta name="author" content="Patterson Consulting Engineering Team">


    <meta property="og:title" content="Deploying Agents to MLflow"/>
    <meta property="og:image" content="https://pattersonconsultingtn.com/assets/img/deploying_agents_to_mlflow_header_0.jpg"/>
    <meta property="og:url" content="https://pattersonconsultingtn.com/blog/deploying_agents_to_mlflow.html"/>
    <meta property="og:site_name" content="Patterson Consulting"/>
    <meta property="og:description" content="..."/>


    <meta name="twitter:title" content="Deploying Agents to MLflow" />
    <meta name="twitter:image" content="https://pattersonconsultingtn.com/assets/img/deploying_agents_to_mlflow_header_0.jpg" />
    <meta name="twitter:url" content="https://pattersonconsultingtn.com/blog/deploying_agents_to_mlflow.html" />
    <meta name="twitter:card" content="summary_large_image" />


    <link rel="manifest" href="/alpha_manifest.json">
    
    <link rel="icon" type="image/png" sizes="16x16" href="../assets/app-icons/pct_box_logo_16x16.png">
    <link rel="icon" type="image/png" sizes="32x32" href="../assets/app-icons/pct_box_logo_32x32.png">
        
    
    <script src="../assets/js/theme-switcher.js"></script>

    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&amp;display=swap" rel="stylesheet" id="google-font">


    <link rel="stylesheet" media="screen" href="../assets/vendor/swiper/swiper-bundle.min.css">
    <link rel="stylesheet" media="screen" href="../assets/vendor/lightgallery/css/lightgallery-bundle.min.css">

    <link rel="stylesheet" media="screen" href="../assets/vendor/aos/dist/aos.css">

    <link rel="stylesheet" href="../assets/icons/around-icons.min.css">

    <link rel="stylesheet" media="screen" href="../assets/css/theme.pct.v2.css">

    <link href="../assets/css/prism.css" rel="stylesheet" />


    <style>
      .page-loading {
        position: fixed;
        top: 0;
        right: 0;
        bottom: 0;
        left: 0;
        width: 100%;
        height: 100%;
        -webkit-transition: all .4s .2s ease-in-out;
        transition: all .4s .2s ease-in-out;
        background-color: #fff;
        opacity: 0;
        visibility: hidden;
        z-index: 9999;
      }
      [data-bs-theme="dark"] .page-loading {
        background-color: #121519;
      }
      .page-loading.active {
        opacity: 1;
        visibility: visible;
      }
      .page-loading-inner {
        position: absolute;
        top: 50%;
        left: 0;
        width: 100%;
        text-align: center;
        -webkit-transform: translateY(-50%);
        transform: translateY(-50%);
        -webkit-transition: opacity .2s ease-in-out;
        transition: opacity .2s ease-in-out;
        opacity: 0;
      }
      .page-loading.active > .page-loading-inner {
        opacity: 1;
      }
      .page-loading-inner > span {
        display: block;
        font-family: "Inter", sans-serif;
        font-size: 1rem;
        font-weight: normal;
        color: #6f788b;
      }
      [data-bs-theme="dark"] .page-loading-inner > span {
        color: #fff;
        opacity: .6;
      }
      .page-spinner {
        display: inline-block;
        width: 2.75rem;
        height: 2.75rem;
        margin-bottom: .75rem;
        vertical-align: text-bottom;
        background-color: #d7dde2; 
        border-radius: 50%;
        opacity: 0;
        -webkit-animation: spinner .75s linear infinite;
        animation: spinner .75s linear infinite;
      }
      [data-bs-theme="dark"] .page-spinner {
        background-color: rgba(255,255,255,.25);
      }
      @-webkit-keyframes spinner {
        0% {
          -webkit-transform: scale(0);
          transform: scale(0);
        }
        50% {
          opacity: 1;
          -webkit-transform: none;
          transform: none;
        }
      }
      @keyframes spinner {
        0% {
          -webkit-transform: scale(0);
          transform: scale(0);
        }
        50% {
          opacity: 1;
          -webkit-transform: none;
          transform: none;
        }
      }

      .todo_edit { 
        color: #ff0000;
       }

      .todo_consider { 
        color: #dddddd;
       }


      .working_outline { 
        color: #aaaaaa;
       }

       .todo_segue {
        color: #0000dd;
       }


       .todo_blue {
        color: #0000ff;
       }

       .narrative {
        color: #fc9003;
        font-weight: bold;
        font-style: italic;
       }


       .gpt-copy {
        color: #eb34db;
        font-weight: bold;
        font-style: italic;
       }

       .core_thesis {
        color: #777777;
        font-weight: bold;
        font-style: italic;
        margin-bottom: 50px;
        margin-left: 50px;
       }
       .narrative_scaffolding {

        color: #cccccc;
        
        font-style: italic;

       }


      .pre {
          display: block;
          unicode-bidi: embed;
          
          white-space: pre;
      }   
    </style>

    <script>
      (function () {
        window.onload = function () {
          const preloader = document.querySelector('.page-loading')
          preloader.classList.remove('active')
          setTimeout(function () {
            preloader.remove()
          }, 1500)

          const theme = 'light'
          document.documentElement.setAttribute('data-bs-theme', theme)
          

        }
      })()
    </script>

    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-N6H6PTM9');</script>
    </head>


  <body>


    <div class="page-loading active">
      <div class="page-loading-inner">
        <div class="page-spinner"></div>
        <span>Loading...</span>
      </div>
    </div>


    <main class="page-wrapper">

      <header data-bs-theme="light">
        <div class="navbar navbar-expand-lg fixed-top bg-light">
          <div class="container">

            <a class="navbar-brand pe-sm-3" href="../../index.html">
              <span class="text-primary flex-shrink-0 me-2">
                <svg width="35" height="32" viewBox="0 0 36 33" xmlns="http://www.w3.org/2000/svg">
                  <g transform="matrix(0.004459, 0, 0, -0.00433, -8154.369629, -2022.807495)" fill="#000000" stroke="none" style="transform-origin: 8189.37px 2055.78px;">
  <path d="M340 9410 l0 -260 1348 0 c807 0 1370 -4 1403 -9 30 -6 101 -15 159
-21 177 -19 447 -88 605 -155 242 -103 389 -186 553 -310 124 -94 287 -257
390 -390 26 -34 100 -148 140 -215 214 -362 327 -901 282 -1345 -11 -115 -47
-341 -58 -362 -5 -10 -14 -45 -21 -78 -7 -33 -16 -64 -20 -70 -4 -5 -13 -30
-20 -55 -7 -25 -19 -58 -26 -75 -70 -160 -92 -205 -132 -277 -45 -80 -161
-257 -189 -288 -8 -8 -33 -37 -56 -65 -60 -71 -200 -208 -277 -270 -88 -70
-241 -175 -258 -175 -7 0 -13 -3 -13 -8 0 -11 -304 -162 -326 -162 -3 0 -20
-7 -37 -14 -45 -21 -210 -74 -254 -82 -21 -4 -45 -10 -55 -15 -9 -5 -72 -18
-140 -30 -67 -12 -145 -26 -173 -31 -29 -6 -359 -12 -782 -15 l-733 -4 0
-1175 0 -1174 3270 0 3270 0 0 3695 0 3695 -3925 0 -3925 0 0 -260z" style="fill: rgb(255, 149, 0);"></path>
  <path d="M1650 6884 l0 -1096 648 4 647 4 120 28 c66 16 125 32 130 36 6 4 28
13 50 20 53 17 129 56 179 92 23 16 52 36 66 46 86 60 201 201 261 322 84 168
109 281 116 525 7 251 -18 402 -97 580 -56 126 -184 280 -295 355 -27 18 -62
42 -77 52 -15 10 -29 18 -32 18 -3 0 -30 11 -60 25 -30 14 -61 25 -68 25 -7 1
-31 8 -53 16 -101 37 -228 44 -892 44 l-643 0 0 -1096z" style="fill: rgb(255, 149, 0);"></path>
</g>



                </svg>
              </span>
              Patterson Consulting
            </a>


            <a class="btn btn-primary btn-sm fs-sm order-lg-3 d-none d-sm-inline-flex" href="../../contact_us.html" target="_blank" rel="noopener">
              <i class="fs-xl me-2 ms-n1"></i>
              Contact Us
            </a>

            <button class="navbar-toggler ms-sm-3" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-label="Toggle navigation">
              <span class="navbar-toggler-icon"></span>
            </button>

            <nav class="collapse navbar-collapse" id="navbarNav">
              <ul class="navbar-nav navbar-nav-scroll me-auto" style="--ar-scroll-height: 520px;">


                <li class="nav-item dropdown">
                  <a class="nav-link dropdown-toggle" href="#" data-bs-toggle="dropdown" aria-expanded="false">Industries</a>
                  <ul class="dropdown-menu">
                    
                    <li><a class="dropdown-item" href="../retail_industry.html">Retail</a></li>
                    <li><a class="dropdown-item" href="../insurance_industry.html">Insurance</a></li>
                    <li><a class="dropdown-item" href="../municipal_industry.html">Smart City</a></li>

                  </ul>
                </li>


                <li class="nav-item dropdown">
                  <a class="nav-link dropdown-toggle" href="#" data-bs-toggle="dropdown" data-bs-auto-close="outside" aria-expanded="false">Engineering Services</a>
                  <ul class="dropdown-menu">
                    <li><a class="dropdown-item" href="../offerings/migrations_to_databricks.html">Migration to Databricks</a></li>
                    <li><a class="dropdown-item" href="../platform_engineering.html">Platform Engineering</a></li>
                    <li><a class="dropdown-item" href="../data_engineering.html">Data Engineering</a></li>
                    <li><a class="dropdown-item" href="../generative_ai.html">GenAI Services</a></li>
                    </ul>

                </li>

                <li class="nav-item dropdown">
                  <a class="nav-link dropdown-toggle" href="#" data-bs-toggle="dropdown" data-bs-auto-close="outside" aria-expanded="false">Resources</a>
                  <ul class="dropdown-menu">
                    <li><a class="dropdown-item" href="../blog/blog_index.html">Blog</a></li>
                    <li><a class="dropdown-item" href="../publications.html">Team Publications</a></li>
                    <li><a class="dropdown-item" href="../index.html#case_studies">Case Studies</a></li>
                    <li><a class="dropdown-item" href="https://www.youtube.com/channel/UCmaki2Xq1AeFL8XbWGIWyQg">Videos</a></li>
                  </ul>

                </li>

                <li class="nav-item">
                  <a class="nav-link" href="../about.html">About</a>
                </li>
              </ul>
            </nav>

          </div>
        </div>
      </header>


      <section class="container py-5 mt-5 mb-md-2 mb-lg-3 mb-xl-4">

        <nav aria-label="breadcrumb">
          
          <ol class="pt-lg-3 pb-lg-4 pb-2 breadcrumb">
            <li class="breadcrumb-item"><a href="">Home</a></li>
            <li class="breadcrumb-item"><a href="../">Blog Index</a></li>
            <li class="breadcrumb-item active" aria-current="page">Deploying Agents to MLflow</li>
          </ol>
          
        </nav>

        <h1 class="display-4 text-left pb-2 pb-lg-3">Deploying Agents to MLflow</h1>

        <div class="d-flex flex-wrap align-items-center justify-content-between border-bottom mb-4">
              <div class="d-flex align-items-center mb-4 me-4">
                <span class="fs-sm me-2">By:</span>
                <a class="nav-link position-relative fw-semibold p-0" href="#author" data-scroll data-scroll-offset="80">
                  Patterson Consulting Engineering Team
                  <span class="d-block position-absolute start-0 bottom-0 w-100" style="background-color: currentColor; height: 1px;"></span>
                </a>
              </div>

            </div>

      </section>


      <section class="jarallax" data-jarallax data-speed=".65">
        <div class="jarallax-img bg-position-center-y" style="background-image: url(../assets/img/deploying_agents_to_mlflow_header_0.jpg);"></div>
        <div class="d-none d-xxl-block" style="height: 600px;"></div>
        <div class="d-none d-xl-block d-xxl-none" style="height: 650px;"></div>
        <div class="d-none d-lg-block d-xl-none" style="height: 500px;"></div>
        <div class="d-none d-md-block d-lg-none" style="height: 400px;"></div>
        <div class="d-md-none" style="height: 300px;"></div>
      </section>

















      <section class="container pt-5 mt-md-2 mt-lg-3 mt-xl-4">
        <div class="row justify-content-center pt-xxl-2">
          <div class="col-lg-9 col-xl-8">



<p class="fs-lg">
the whole "secret sauce" of any use case is 
</p>


<ol>
<li>prompt instructions</li>
<li>the right contextual data to analyze</li>
<li>a LLM with enough "reasoning horsepower"</li>
</ol>


<h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">ResponsesAgent Code vs Packaging the Agent</h2>

<p class="fs-lg">
   Here’s the clean mental model:
</p>
<ul class="fs-lg">
   <li>
      <strong>ResponsesAgent</strong> = <em>a Python class / runtime construct</em> that implements the agent behavior (how it uses tools, how it reasons, how it formats responses, etc.).
   </li>
   <li>
      <strong>Packaging the agent</strong> = <em>turning that class + its dependencies into an MLflow model artifact</em> so it can be logged, versioned, and served (locally, Databricks model serving, etc.).
   </li>
</ul>
<p class="fs-lg">
   I’ll break it into two parts and then give practical packaging patterns.
</p>
<hr class="my-4" />
<h2 class="h2 mb-lg-4 pt-3">
   1. How <code>ResponsesAgent</code> differs from “packaging an agent”
</h2>
<h3 class="h3 mb-3">
   What <code>ResponsesAgent</code> is
</h3>
<p class="fs-lg">
   In MLflow 3.6, a <strong>ResponsesAgent</strong> is:
</p>
<ul class="fs-lg">
   <li>
      A <strong>Python object / class</strong> that:
      <ul>
         <li>Defines how to handle a request (inputs → messages → tools → model calls → outputs).</li>
         <li>
            Encapsulates:
            <ul>
               <li>The underlying LLM or endpoint</li>
               <li>Tool definitions</li>
               <li>System / developer instructions</li>
               <li>Any routing / orchestration logic</li>
            </ul>
         </li>
      </ul>
   </li>
   <li>
      It lives in your <strong>application code</strong>:
      <ul>
         <li>You import <code>ResponsesAgent</code> (or a specific agent base class / helper).</li>
         <li>You implement something like <code>class MyAgent(ResponsesAgent): ...</code> or configure one via a factory.</li>
         <li>You can test it directly in Python before you ever touch MLflow logging.</li>
      </ul>
   </li>
</ul>
<p class="fs-lg">
   Think of <strong>ResponsesAgent</strong> as the <em>behavioral definition</em> of your agent.
</p>
<h3 class="h3 mb-3 mt-4">
   What “packaging an agent” is in MLflow
</h3>
<p class="fs-lg">
   “Packaging” is about making that <code>ResponsesAgent</code>:
</p>
<ul class="fs-lg">
   <li>
      <strong>Serializable</strong> into an MLflow model artifact:
      <ul>
         <li>Code</li>
         <li>Environment (conda/venv, pip requirements)</li>
         <li>Any resource files (YAML configs, prompt templates, tools metadata)</li>
      </ul>
   </li>
   <li>
      <strong>Standardized</strong> behind a <strong>model signature</strong> and <strong>predict API</strong>, so you can:
      <ul>
         <li>Log it with <code>mlflow.&lt;flavor&gt;.log_model(...)</code></li>
         <li>Register versions in the <strong>Model Registry</strong></li>
         <li>Serve it via MLflow model serving (or Databricks Model Serving)</li>
         <li>Call it through a simple <code>predict()</code> / REST endpoint, regardless of implementation details.</li>
      </ul>
   </li>
</ul>
<p class="fs-lg">
   So:
</p>
<ul class="fs-lg">
   <li><code>ResponsesAgent</code> is <em>how the agent behaves</em>.</li>
   <li>
      Packaging is <em>how you wrap that behavior into an MLflow model</em> so it can be:
      <ul>
         <li>Discovered</li>
         <li>Versioned</li>
         <li>Deployed</li>
         <li>Called in a standardized way by other systems.</li>
      </ul>
   </li>
</ul>
<hr class="my-4" />
<h2 class="h2 mb-lg-4 pt-3">
   2. Best ways to package a <code>ResponsesAgent</code> in MLflow 3.6
</h2>
<p class="fs-lg">
   You basically have three useful patterns. Which you choose depends on how “production” you need to be and how much flexibility you want.
</p>
<h3 class="h3 mb-3">
   Pattern A: Use the built-in MLflow agent flavor (if available in 3.6)
</h3>
<p class="fs-lg">
   If you are already using the MLflow 3.6 agent/Responses APIs, the preferred path is to use the dedicated agent flavor (or a thin wrapper MLflow provides) that knows how to:
</p>
<ul class="fs-lg">
   <li>Take a <code>ResponsesAgent</code> (or configuration object).</li>
   <li>Persist it as an MLflow model.</li>
   <li>Restore it on the serving side with the same interface.</li>
</ul>
<p class="fs-lg">
   Typical flow (pseudo-code):
</p>
<pre><code class="language-python">import mlflow
from my_project.agents import MyDecisionAgent

agent = MyDecisionAgent(...)

with mlflow.start_run():
    mlflow.agents.log_model(
        agent=agent,
        registered_model_name="main.ai.agents.my_decision_agent",
        artifact_path="my_decision_agent"
    )
</code></pre>
<p class="fs-lg">
   Key characteristics:
</p>
<ul class="fs-lg">
   <li>
      <strong>Pros</strong>
      <ul>
         <li>Minimal boilerplate: the flavor knows how to handle <code>ResponsesAgent</code>.</li>
         <li>You get a <strong>standard API</strong> (usually something like <code>predict()</code> / <code>responses()</code>).</li>
         <li>Unified lifecycle: same patterns as other MLflow models.</li>
      </ul>
   </li>
   <li>
      <strong>Cons</strong>
      <ul>
         <li>You are tightly coupled to the MLflow agent flavor’s expectations.</li>
         <li>You have less freedom to customize the predict interface compared to a custom pyfunc (though often that’s fine).</li>
      </ul>
   </li>
</ul>
<p class="fs-lg">
   When you can use this pattern, it is usually the <strong>best default</strong> for agents built directly on <code>ResponsesAgent</code>.
</p>
<h3 class="h3 mb-3 mt-4">
   Pattern B: Package the agent as a <code>pyfunc</code> model
</h3>
<p class="fs-lg">
   You can also wrap your <code>ResponsesAgent</code> in a <strong>custom MLflow pyfunc model</strong>. Here:
</p>
<ul class="fs-lg">
   <li>The <code>ResponsesAgent</code> instance is just an internal field of your pyfunc “wrapper.”</li>
   <li><code>predict()</code> translates between your <code>input_df</code> / structured input and the agent’s message format.</li>
</ul>
<p class="fs-lg">
   Example:
</p>
<pre><code class="language-python">import mlflow
from mlflow.pyfunc import PythonModel
from my_project.agents import MyDecisionAgent

class AgentPyfuncWrapper(PythonModel):
    def load_context(self, context):
        # Rebuild or load the agent
        self.agent = MyDecisionAgent(...)

    def predict(self, context, model_input):
        """
        model_input could be:
        - a DataFrame with columns like 'user_id', 'question'
        - or a JSON-like dict passed via REST
        """
        # For simplicity, assume `model_input` is a dict with "messages"
        messages = model_input["messages"]
        result = self.agent.run(messages)  # or whatever your agent method is
        return result  # often a dict/list that MLflow converts to JSON

agent_model = AgentPyfuncWrapper()

with mlflow.start_run():
    mlflow.pyfunc.log_model(
        artifact_path="my_agent",
        python_model=agent_model,
        code_paths=["./my_project"],
        registered_model_name="main.ai.agents.my_decision_agent"
    )
</code></pre>
<p class="fs-lg">
   <strong>When to use pyfunc for agents:</strong>
</p>
<ul class="fs-lg">
   <li>
      You want full control over:
      <ul>
         <li>Input format</li>
         <li>Output format</li>
         <li>How the agent is instantiated and configured at load time.</li>
      </ul>
   </li>
   <li>You might want to support <strong>multiple modes</strong> (e.g., raw tool traces vs final answer only).</li>
   <li>You want to be able to swap the internals (or even move away from <code>ResponsesAgent</code>) without breaking the model contract.</li>
</ul>
<p class="fs-lg">
   <strong>Best practices here:</strong>
</p>
<ul class="fs-lg">
   <li>Use <code>code_paths</code> to package your project modules so the agent class is importable.</li>
   <li>
      Use <code>artifacts</code> or files inside <code>artifact_path</code> for:
      <ul>
         <li>Prompt templates</li>
         <li>Tool config</li>
         <li>YAML/JSON settings</li>
      </ul>
   </li>
   <li>
      Clearly document the expected input schema (e.g., <code>messages: List[Dict[str, str]]</code>) in:
      <ul>
         <li>The model signature (if you’re using structured types)</li>
         <li>The model’s description / tags.</li>
      </ul>
   </li>
</ul>
<h3 class="h3 mb-3 mt-4">
   Pattern C: Bundle the agent + resources via <code>artifacts</code> and <code>code_paths</code>
</h3>
<p class="fs-lg">
   Regardless of whether you use the agent flavor or pyfunc, you should think explicitly about:
</p>
<ol class="fs-lg">
   <li>
      <strong>Where the code lives</strong>
      <ul>
         <li>Put your agent code in a proper Python package (e.g., <code>my_project/agents/</code>).</li>
         <li>
            Add that directory to <code>code_paths</code> when logging the model:
            <pre><code class="language-python">mlflow.pyfunc.log_model(
    artifact_path="my_agent",
    python_model=agent_model,
    code_paths=["./my_project"],
    ...
)</code></pre>
         </li>
         <li>This ensures the serving environment can import the same agent code.</li>
      </ul>
   </li>
   <li>
      <strong>Where the configuration / prompts live</strong>
      <ul>
         <li>
            Store prompt templates, tool configs, and other settings as:
            <ul>
               <li>YAML / JSON files in a subdirectory, e.g., <code>./resources/prompts/</code>.</li>
            </ul>
         </li>
         <li>Log them as <strong>artifacts</strong> or include them under the model <code>artifact_path</code>.</li>
         <li>In <code>load_context</code>, read these files from <code>context.artifacts</code> or relative paths inside the model directory.</li>
      </ul>
   </li>
   <li>
      <strong>How you define dependencies</strong>
      <ul>
         <li>
            Use <code>pip_requirements</code> or <code>conda_env</code> in <code>log_model()</code> so the serving environment has:
            <ul>
               <li>Your LLM client libraries</li>
               <li>Any tool-specific packages</li>
               <li>Frameworks (e.g., <code>requests</code>, <code>pydantic</code>, etc.)</li>
            </ul>
         </li>
      </ul>
   </li>
</ol>
<p class="fs-lg">
   This is where <code>artifact_path</code> vs <code>code_paths</code> matters:
</p>
<ul class="fs-lg">
   <li><strong><code>code_paths</code></strong>: “Your Python modules” – what needs to be <code>import</code>-able.</li>
   <li><strong><code>artifact_path</code></strong>: “Your model’s payload” – non-code resources + the serialized model metadata.</li>
</ul>
<hr class="my-4" />
<h2 class="h2 mb-lg-4 pt-3">
   Recommended packaging approach (practical guidance)
</h2>
<p class="fs-lg">
   For MLflow 3.6 and <code>ResponsesAgent</code>, a good standard pattern is:
</p>
<ol class="fs-lg">
   <li>
      <strong>Implement the agent cleanly, without MLflow concerns</strong>
      <ul>
         <li><code>my_project/agents/decision_agent.py</code> with a <code>class DecisionAgent(ResponsesAgent): ...</code></li>
         <li>Agent constructor takes config objects / paths, not hard-coded environment.</li>
      </ul>
   </li>
   <li>
      <strong>Create a thin MLflow “wrapper”</strong>
      <ul>
         <li>
            Either:
            <ul>
               <li>Use the dedicated <em>agent flavor</em> (<code>mlflow.agents.log_model(...)</code>), or</li>
               <li>Implement a small <code>PythonModel</code> as shown above.</li>
            </ul>
         </li>
      </ul>
   </li>
   <li>
      <strong>Log with robust packaging metadata</strong>
      <ul>
         <li><code>code_paths=["./my_project"]</code></li>
         <li><code>pip_requirements="requirements.txt"</code> or inline list.</li>
         <li><code>artifacts={"prompts": "./resources/prompts"}</code> if needed.</li>
      </ul>
   </li>
   <li>
      <strong>Register and alias</strong>
      <ul>
         <li>
            Use the <strong>Model Registry</strong>:
            <ul>
               <li>Name like <code>main.ai.agents.decision_support_agent</code>.</li>
               <li>Use aliases: <code>Staging</code>, <code>Production</code>.</li>
            </ul>
         </li>
         <li>
            For promotion:
            <ul>
               <li>Update alias from version N → N+1, rather than clients hardcoding versions.</li>
            </ul>
         </li>
      </ul>
   </li>
   <li>
      <strong>Integrate via a single API</strong>
      <ul>
         <li>
            Frontend / other services should hit:
            <ul>
               <li>Databricks Model Serving endpoint, or</li>
               <li>Local MLflow model server, or</li>
               <li><code>mlflow.pyfunc.load_model()</code> in Python.</li>
            </ul>
         </li>
         <li>All see the same agent behind a stable interface.</li>
      </ul>
   </li>
</ol>















<p class="fs-lg">
  <strong>What does <code>mlflow.start_run()</code> do in MLflow 3.6?</strong><br><br>
  <code>mlflow.start_run()</code> creates (or resumes) a run context—a structured container where MLflow logs everything associated with an execution, such as:
</p>

<ul class="fs-lg">
  <li>Parameters</li>
  <li>Metrics</li>
  <li>Artifacts (files, code, prompt assets, knowledge bases, etc.)</li>
  <li>Logged models and agents</li>
  <li>Run metadata (timestamps, status, user, environment, etc.)</li>
</ul>

<p class="fs-lg">
  It’s like pressing the “Record” button: everything you log inside this context is versioned and attached to that run.
</p>










<h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">What is a “run” in MLflow?</h2>
<p class="fs-lg">
  A run is the atomic tracked execution in MLflow—it represents a single attempt to create or update a model or agent. But its purpose differs slightly depending on the asset type.
</p>




<h2 class="h3 mb-lg-4 pt-3 pt-md-4 pt-xl-5">Runs for Traditional ML Models</h2>
<p class="fs-lg">
  A run represents a training lifecycle event, such as:
</p>

<ul class="fs-lg">
  <li>Training a regression model</li>
  <li>Fine-tuning a neural network</li>
  <li>Running feature experiments</li>
</ul>

<p class="fs-lg">
  It captures the full lineage of the model including inputs, outputs, and lifecycle. So if you retrain tomorrow you get a new run.
</p>





<h2 class="h3 mb-lg-4 pt-3 pt-md-4 pt-xl-5">Runs for MLflow ResponsesAgent Models</h2>
<p class="fs-lg">
  A run represents the packaging and publishing event: defining agent behavior (system prompt, tools, routing logic), bundling assets (text files, embeddings, yaml configs), and versioning the code and prompt instructions.
</p>

<p class="fs-lg">
  Agents aren’t trained—they’re versioned and governed like other MLflow models. A ResponsesAgent run is basically: “I am capturing how this agent works at this moment in time and what it depends on.”
</p>



<h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">Why use <code>mlflow.start_run()</code> when logging a ResponsesAgent?</h2>
<p class="fs-lg">
  Because MLflow must persist tools, prompts, and code; assign a unique version ID; enable deployment via Model Registry; track changes over time (audit/compliance); and capture traces and cost metrics later on.
</p>

<p class="fs-lg">
  Even though no training occurs, the run is still critical for governance, lineage, observability, deployment & rollback, and side-by-side evaluation.
</p>



<hr/>


<p class="fs-lg">
  <strong>Short, precise answer:</strong><br>
  A <strong>run represents the calling of the <code>predict()</code> method</strong>, <em>not</em> the deployment of a ResponsesAgent.
</p>

<p class="fs-lg">
  Here is the clear breakdown:
</p>

<h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">1. Deployment does NOT create a run</h2>
<p class="fs-lg">
  Deploying a ResponsesAgent (e.g., via MLflow Model Serving or Databricks Model Serving) is an <strong>infrastructure event</strong>, not an experiment.
  MLflow <strong>does not log a run</strong> when you:
</p>
<p class="fs-lg">
  – register the agent<br>
  – deploy it to a serving endpoint<br>
  – update its stage (Staging → Production)<br>
  – start or restart a model server
</p>
<p class="fs-lg">
  Deployment is a lifecycle operation in the <strong>model registry / serving system</strong>, not an execution, so it does not produce runs.
</p>

<h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">2. A run is created when you CALL the agent (predict/inference) IF logging is enabled</h2>
<p class="fs-lg">
  MLflow 3.6’s <strong>ResponsesAgent</strong> creates runs when you <strong>invoke its <code>predict()</code> method</strong>, <em>if</em> the agent is configured to log interactions.
</p>
<p class="fs-lg">
  A prediction call may log:
</p>
<p class="fs-lg">
  – input messages<br>
  – output responses<br>
  – tool call traces<br>
  – metrics<br>
  – artifacts (transcripts, JSON traces, reasoning logs)
</p>
<p class="fs-lg">
  Each call to <code>predict()</code> is <strong>one execution</strong>, and therefore <strong>one run</strong>.







<h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">Final Summary</h2>

<table class="table table-bordered table-striped fs-lg mt-3 mb-4">
  <thead>
    <tr>
      <th>Item</th>
      <th>Traditional Model</th>
      <th>MLflow ResponsesAgent</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>What is a run?</td>
      <td>A training execution</td>
      <td>A packaging + versioning execution</td>
    </tr>
    <tr>
      <td>Why does it exist?</td>
      <td>Track data → model performance lifecycle</td>
      <td>Track agent reasoning behavior + tools lifecycle</td>
    </tr>
    <tr>
      <td>What does it log?</td>
      <td>Params, metrics, weights</td>
      <td>Prompt, tools, artifacts, code</td>
    </tr>
    <tr>
      <td>What changes between versions?</td>
      <td>Model parameters</td>
      <td>Agent logic or instructions</td>
    </tr>
  </tbody>
</table>





<h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">Managing LLM Access Secret Tokens</code></h2>
<p class="fs-lg todo_edit">
  TODO
</p>



<h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">Deploying HTTP Microservice Using <code>mlflow models serve</code></h2>
<p class="fs-lg">
  Serve the agent as a standalone HTTP endpoint accessible from any programming language.
</p>
<pre class="line-numbers mt-5 mb-5">
<code class="lang-bash">
mlflow models serve -m "models:/my_agent_model/Production" -p 5000 --env-manager local
</code>
</pre>
<p class="fs-lg">
  Then call the REST API from your backend:
</p>
<pre class="line-numbers mt-5 mb-5">
<code class="lang-python">
import requests

def call_agent(prompt):
    url = "http://localhost:5000/invocations"
    payload = {
        "inputs": {
            "messages": [
                {"role": "user", "content": prompt}
            ]
        }
    }
    return requests.post(url, json=payload).json()
</code>
</pre>
<p class="fs-lg">
  This allows completely decoupled deployment so the model can scale and update independently of the app.
</p>


<h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">How MLflow Model Serving Handles Authentication and Authorization</h2>

<p class="fs-lg">
  By default, MLflow model serving does <strong>not</strong> enforce a strong, built-in authentication/authorization layer — you need to add external or surrounding infrastructure for production-grade security. ([protectai.com](https://protectai.com/blog/hacking-ai-steal-models-from-mlflow-no-exploit-needed?utm_source=chatgpt.com))  
</p>

<p class="fs-lg">
  Here’s a breakdown of how MLflow handles auth/authorization (or doesn’t), what features exist, and what you need to do if you care about security.  
</p>

<h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">What MLflow can (optionally) do</h2>

<ul class="fs-lg">
  <li>MLflow offers a basic HTTP authentication mechanism, which can be enabled to restrict access to the tracking server, model registry, and registered models. ([mlflow.org](https://mlflow.org/docs/latest/self-hosting/security/basic-http-auth/?utm_source=chatgpt.com))</li>
  <li>When this basic auth is enabled, only authenticated users can list experiments, retrieve model metadata, or perform registry operations — that helps protect model artifacts and metadata. ([mlflow.org](https://www.mlflow.org/docs/3.3.0/ml/auth/?utm_source=chatgpt.com))</li>
  <li>MLflow’s “custom serving applications” feature documentation mentions “built-in authentication and authorization” support. ([mlflow.org](https://mlflow.org/docs/3.3.1/genai/serving/custom-apps/?utm_source=chatgpt.com))</li>
</ul>

<h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">What you should know: defaults &amp; limitations</h2>

<ul class="fs-lg">
  <li>By default, a standard MLflow model server (e.g. via <code>mlflow models serve</code>) comes with <strong>no authentication or authorization</strong>. If you just run it “out-of-the-box,” anyone who can reach the endpoint can invoke predictions. ([protectai.com](https://protectai.com/blog/hacking-ai-steal-models-from-mlflow-no-exploit-needed?utm_source=chatgpt.com))</li>
  <li>The basic auth feature applies to MLflow’s tracking server / registry — but depending on your deployment (especially serving endpoints), it may not automatically gate the inference API. In other words: permissions that protect model metadata do not necessarily protect the runtime inference endpoint.</li>
  <li>Basic HTTP auth is fairly rudimentary: it doesn’t provide fine-grained permissions (e.g. “user A can read models, user B can’t”) with anything like role-based ACLs out-of-the-box. ([community-charts.github.io](https://community-charts.github.io/docs/charts/mlflow/authentication-configuration?utm_source=chatgpt.com))</li>
  <li>For many production uses, relying solely on MLflow’s auth is unsafe — especially if the model server is reachable beyond a private network or inside a shared environment. This is echoed in warnings that simply placing the MLflow server behind a firewall isn’t sufficient security. ([protectai.com](https://protectai.com/blog/hacking-ai-steal-models-from-mlflow-no-exploit-needed?utm_source=chatgpt.com))</li>
</ul>

<h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">What you should do to secure MLflow model serving in production</h2>

<ul class="fs-lg">
  <li>Place the model-serving endpoint behind a reverse proxy / API gateway (e.g., NGINX, Traefik, AWS ALB, Kong) that enforces <strong>authentication (OAuth, API tokens)</strong> and <strong>authorization</strong> (who can call what).</li>
  <li>Use network-level controls (e.g. VPC, firewall rules) to restrict access to the serving endpoint — ideally make it accessible only from internal services or VPN.</li>
  <li>If you’re using the basic auth for the tracking/registry server, keep credentials in a secure store (avoid hardcoding), use HTTPS to avoid leaking credentials, and limit default permissions as strictly as possible.</li>
  <li>Audit / log requests: wrap serving calls via a layer that does authentication + logging + rate limiting to prevent misuse.</li>
</ul>

<h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">Why this matters (especially for production / sensitive models)</h2>

<p class="fs-lg">
  Because MLflow’s serving is designed for convenience and rapid deployment, it's easy to spin up a model serving endpoint quickly — but that comes with tradeoffs in security. If a model server is exposed unchecked, anyone could call it, possibly abuse resources, or extract proprietary models/data. Because of that risk, many teams treat MLflow’s built-in features as minimal baseline and rely on external infrastructure for hardened deployment.
</p>


          </div>
        </div>
      </section>










      <section class="container pt-5 mt-md-2 mt-lg-3 mt-xl-4">


            
            <div class="d-flex flex-wrap pb-5 pt-3 pt-md-4 pt-xl-5 mt-xl-n2 pl-3">
              <h3 class="h3 py-1 mb-0 me-4">Next in Series</h3>
            </div>



                  <div class="card overflow-hidden mb-4">
                    <div class="row g-0">
                      <div class="col-sm-4 bg-repeat-0 bg-size-cover" style="background-image: url(../assets/img/databricks_semantic_metric_views_header_0.jpg); min-height: 14rem;"></div>
                      <div class="col-sm-8">
                        <div class="card-body">
                          <h4 class="card-title">Building a Retail Semantic Layer with Unity Catalog Metric Views</h4>
                          <p class="card-text">This article explains how Databricks Unity Catalog Metric Views create a governed semantic layer that transforms complex retail data into consistent, business-ready insights—empowering teams to accelerate knowledge work and make revenue-driving decisions with confidence.</p>
                          
                <a class="btn btn-lg btn-link px-0" href="building_retail_semantic_layer_with_unity_catalog_metric_views.html">
                  Read next article in series
                  <i class="ai-arrow-right ms-2"></i>
                </a>

                        </div>
                      </div>
                    </div>
                  </div>

      </section>
   




    </main>

    

  <footer class="footer py-5 bg-dark" data-bs-theme="dark">
      <div class="container pt-md-2 pt-lg-3 pt-xl-4">
        <div class="row pb-5 pt-sm-2 mb-lg-2">
          <div class="col-md-4 col-lg-3 pb-2 pb-md-0 mb-4 mb-md-0">


            <a class="navbar-brand pe-sm-3" href="/index.html">
              <span class="text-primary flex-shrink-0 me-2">
                <svg width="35" height="32" viewBox="0 0 36 33" xmlns="http://www.w3.org/2000/svg">

                  <g transform="matrix(0.004459, 0, 0, -0.00433, -8154.369629, -2022.807495)" fill="#000000" stroke="none" style="transform-origin: 8189.37px 2055.78px;">
                    <path d="M340 9410 l0 -260 1348 0 c807 0 1370 -4 1403 -9 30 -6 101 -15 159
                  -21 177 -19 447 -88 605 -155 242 -103 389 -186 553 -310 124 -94 287 -257
                  390 -390 26 -34 100 -148 140 -215 214 -362 327 -901 282 -1345 -11 -115 -47
                  -341 -58 -362 -5 -10 -14 -45 -21 -78 -7 -33 -16 -64 -20 -70 -4 -5 -13 -30
                  -20 -55 -7 -25 -19 -58 -26 -75 -70 -160 -92 -205 -132 -277 -45 -80 -161
                  -257 -189 -288 -8 -8 -33 -37 -56 -65 -60 -71 -200 -208 -277 -270 -88 -70
                  -241 -175 -258 -175 -7 0 -13 -3 -13 -8 0 -11 -304 -162 -326 -162 -3 0 -20
                  -7 -37 -14 -45 -21 -210 -74 -254 -82 -21 -4 -45 -10 -55 -15 -9 -5 -72 -18
                  -140 -30 -67 -12 -145 -26 -173 -31 -29 -6 -359 -12 -782 -15 l-733 -4 0
                  -1175 0 -1174 3270 0 3270 0 0 3695 0 3695 -3925 0 -3925 0 0 -260z" style="fill: rgb(255, 149, 0);"></path>
                    <path d="M1650 6884 l0 -1096 648 4 647 4 120 28 c66 16 125 32 130 36 6 4 28
                  13 50 20 53 17 129 56 179 92 23 16 52 36 66 46 86 60 201 201 261 322 84 168
                  109 281 116 525 7 251 -18 402 -97 580 -56 126 -184 280 -295 355 -27 18 -62
                  42 -77 52 -15 10 -29 18 -32 18 -3 0 -30 11 -60 25 -30 14 -61 25 -68 25 -7 1
                  -31 8 -53 16 -101 37 -228 44 -892 44 l-643 0 0 -1096z" style="fill: rgb(255, 149, 0);"></path>
                  </g>

                </svg>
              </span>
              <span class="text-light">
              Patterson Consulting
              </span>
            </a>    

            <p class="fs-sm pb-2 pb-md-3 mb-3 text-light">Delivering data pipelines, analytics, and large language model applications.</p>
            <div class="d-flex gap-3">
              <a class="btn btn-icon btn-sm btn-secondary btn-linkedin rounded-circle" href="https://www.linkedin.com/company/patterson-consulting-tn/" aria-label="LinkedIn">
                <i class="ai-linkedin"></i>
              </a>
            </div>
          </div>
          <div class="col-md-8 col-lg-7 col-xl-6 offset-lg-2 offset-xl-3">
            <div class="row row-cols-1 row-cols-sm-3">
              <div class="col mb-4 mb-md-0">
              </div>
              <div class="col mb-4 mb-md-0">

              </div>
              <div class="col mb-4 mb-md-0">
                <h4 class="h6 fw-bold pb-lg-1">Company</h4>
                <ul class="nav flex-column">
                  <li><a class="nav-link fw-normal py-1 px-0" href="/contact_us.html">Contact Us</a></li>
                  <li><a class="nav-link fw-normal py-1 px-0" href="/blog/blog_index.html">Blog</a></li>
                  <li><a class="nav-link fw-normal py-1 px-0" href="/index.html#case_studies">Case Studies</a></li>
                  <li><a class="nav-link fw-normal py-1 px-0" href="/publications.html">eBooks</a></li>
                  <li><a class="nav-link fw-normal py-1 px-0" href="https://www.youtube.com/channel/UCmaki2Xq1AeFL8XbWGIWyQg">Videos</a></li>
                  <li><a class="nav-link fw-normal py-1 px-0" href="/about.html">About</a></li>
                </ul>
              </div>
            </div>
          </div>
        </div>
        <p class="nav fs-sm mb-0">
          <span class="text-body-secondary">© All rights reserved. Made by</span>
          <a class="nav-link fw-normal p-0 ms-1" href="https://www.pattersonconsultingtn.com/" target="_blank" rel="noopener">Patterson Consulting</a>
        </p>
      </div>
    </footer>    


    <a class="btn-scroll-top" href="#top" data-scroll aria-label="Scroll back to top">
      <svg viewBox="0 0 40 40" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
        <circle cx="20" cy="20" r="19" fill="none" stroke="currentColor" stroke-width="1.5" stroke-miterlimit="10"></circle>
      </svg>
      <i class="ai-arrow-up"></i>
    </a>



  <script src="../assets/js/prism.js"></script>

    <script src="../assets/vendor/jarallax/dist/jarallax.min.js"></script>
    <script src="../assets/vendor/swiper/swiper-bundle.min.js"></script>
    


    <script src="../assets/vendor/swiper/swiper-bundle.min.js"></script>
    <script src="../assets/vendor/lightgallery/lightgallery.min.js"></script>


    <script src="../assets/vendor/lightgallery/plugins/fullscreen/lg-fullscreen.min.js"></script>
    <script src="../assets/vendor/lightgallery/plugins/zoom/lg-zoom.min.js"></script>
    <script src="../assets/vendor/lightgallery/plugins/video/lg-video.min.js"></script>
    <script src="../assets/vendor/lightgallery/plugins/thumbnail/lg-thumbnail.min.js"></script>



    <script src="../assets/js/theme.min.js"></script>
  </body>
</html>

