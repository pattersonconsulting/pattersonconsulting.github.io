
<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
	<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-119541534-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-119541534-1');
</script>
		
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Patterson Consulting: Forecasting Your AWS GPU Cloud Spend</title>
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="blog page for Patterson Consulting" />
	<meta name="keywords" content="blog, patterson consulting, deep learning, machine learning, apache hadoop, apache spark, etl, consulting" />
	<meta name="author" content="Patterson Consulting" />

  	<!-- Facebook and Twitter integration -->
	<meta property="og:title" content="Forecasting Your AWS GPU Cloud Spend"/>
	<meta property="og:image" content="http://www.pattersonconsultingtn.com/images/exec_strategy_bg.png"/>
	<meta property="og:url" content="http://www.pattersonconsultingtn.com/blog/deploying_huggingface_with_kfserving.html"/>
	<meta property="og:site_name" content=""/>
	<meta property="og:description" content="In this example we demonstrate how to take a Hugging Face NLP Question Answer pre-trained model and run it as a KFServing hosted model."/>
	

	<meta name="twitter:title" content="Forecasting Your AWS GPU Cloud Spend" />
	<meta data-rh="true" property="twitter:description" content="In this example we demonstrate how to take a Hugging Face NLP Question Answer pre-trained model and run it as a KFServing hosted model."/>

	<meta name="twitter:image" content="http://www.pattersonconsultingtn.com/images/exec_strategy_bg.png" />
	<meta name="twitter:url" content="http://www.pattersonconsultingtn.com/blog/deploying_huggingface_with_kfserving.html" />
	<meta name="twitter:card" content="summary_large_image" />

	<!-- Place favicon.ico and apple-touch-icon.png in the root directory -->
	<!-- <link rel="shortcut icon" href="favicon.ico"> -->
	
	<link rel="stylesheet" href="../css/animate.css">
	<link rel="stylesheet" href="../css/bootstrap.css">
	<link rel="stylesheet" href="../css/icomoon.css">

	<link rel="stylesheet" href="../css/owl.carousel.min.css">
	<link rel="stylesheet" href="../css/owl.theme.default.min.css">

	<link rel="stylesheet" href="../css/style.css">

	<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">

	<link rel="shortcut icon" href="http://www.pattersonconsultingtn.com/pct.ico" type="image/x-icon" />

	<style>
		a { 
			color: #FF0000; 
			text-decoration: underline;
		}

table {
  font-family: arial, sans-serif;
  border-collapse: collapse;
  width: 100%;
}

td, th {
  border: 1px solid #dddddd;
  text-align: left;
  padding: 8px;
}

tr:nth-child(even) {
  background-color: #dddddd;
}

.news_item_row {
	border: 0px solid #999999; 
	padding: 0px; 
	padding-top: 20px; 
	padding-bottom: 24px; 
	margin: 0px; 
	margin-bottom: 6px; 
	background-color: #ffffff;

}

.news_item_label {
	border: 1px solid #cccccc; 
	border-bottom: 0px; 
	width: 50%; 
	padding: 12px; 
	padding-top: 18px; 
	margin: 0px; 
	margin-left: 0px; 
	background-color: #dddddd;
}


.news_item_body {
	border: 2px solid #cccccc; 
	padding: 12px; 
	padding-top: 18px; 
	margin: 20px; 
	margin-left: 0px; 
	margin-top: 0px; 
	background-color: #ffffff;

}

</style>	

	<script src="../js/modernizr-2.6.2.min.js"></script>
	<!--[if lt IE 9]>
	<script src="js/respond.min.js"></script>
	<![endif]-->

	</head>
	<body class="boxed">
	<!-- Loader -->
	<div class="fh5co-loader"></div>

	<div id="wrap">

	<div id="fh5co-page">
		<header id="fh5co-header" role="banner">
			<div class="container">
				<a href="#" class="js-fh5co-nav-toggle fh5co-nav-toggle dark"><i></i></a>
				<div id="fh5co-logo"><a href="index.html"><img src="../images/website_header_top_march2018_v0.png" ></a></div>
				<nav id="fh5co-main-nav" role="navigation">
		          <ul>
		            
		            <li class="has-sub">
		              <div class="drop-down-menu">
		                <a href="#">Services</a>
		                <div class="dropdown-menu-wrap">
		                  <ul>
		                    
		                    <li><a href="../offerings/data_engineering.html">Data Engineering</a></li>
		                    <li><a href="../offerings/data_science.html">Data Science</a></li>

		                    <li><a href="../offerings/cloud_operations.html">Cloud Operations and Engineering</a></li>
		                    
		                    <li><a href="../offerings/managed_kubeflow.html">Managed Kubeflow</a></li>

		                    <li><a href="../offerings/managed_kafka.html">Managed Kafka</a></li>

		                    <li><a href="../offerings/research_partnerships.html">Research Partnerships</a></li>
		                    
		                  </ul>
		                </div>
		              </div>
		            </li>
		            
		            <li><a href="../partners.html">Partners</a></li>

		            <li><a href="../blog/blog_index.html">Blog</a></li>
		          
		            <li class="cta"><a href="../contact.html">Contact</a></li>
		          </ul>
		        </nav>
			</div>
		</header>
		<!-- Header -->

<!--
		<div class="fh5co-slider" >
			<div class="container" >
				
				<div class="cd-hero__content cd-hero__content--half-width" style="width: 80%; padding-left: 50px;">
						<h1>Rail, Aquariums, and Data</h1>
				</div>		
			</div>
		</div>
-->

		
		<div id="fh5co-intro" class="fh5co-section">
			<div class="container">


				<div class="row row-bottom-padded-sm">


					<div class="col-md-12" id="fh5co-content">
						<h1 style="font-weight: bold !important;">Forecasting Your AWS GPU Cloud Spend for Deep Learning</h1>
						<p>Author: <a href="http://www.twitter.com/jpatanooga">Josh Patterson</a>
							<br/>
							

							</p>


<!--
					<div class="col-md-3" id="fh5co-content" style="float: right;">
						<a href="../content/kubeflow_operations_oreilly_book.html">
							<img src="../images/kfops_book_cover_final.png" style="width: 212px; height: 280px; border: 1px solid;" >
						</a>
					</div>
-->
						<p>

							In this post we look at how to forecast your AWS GPU spend.
							we cover:
							- how a typical user consumes GPU hours over the course of a month
							- the types of users in an organization for GPUs

							- general resource requirements for working with different types of models
							
							- what kinds of GPUs the users typically train models on

							- build a spreadsheet model for how to forecast a monthly and yearly GPU spend


						</p>
						<p>

							We're going to focus purely on modeling GPU usage in this post. There are other services that a team may use but for the purposes of this analysis we are going to leave those AWS components out of the cost model for now.

						</p>


						


					</div>

					<!-- end content -->



					<div class="col-md-12" id="fh5co-content">



						<h1>How Does a Data Scientist Use Public Cloud GPU Hours?</h1>

						<p>

							What we we trying to calculate here?

							why is this key to our argument?

						</p>
						<p>

							what is our methodology?

							<ol>
								<li>Build criteria for what kind of workfloads we'll run</li>
								<li>Take a look at different types of public cloud GPU options on AWS</li>
								<li>Understand any other tools on AWS, such as SageMaker, that may be relevant to building our cost model</li>

							</ol>

							we are looking to model "who are our users" and "what do they do", giving us the parameters to forecast our GPU spend on AWS.

						</p>

					</div>

					<!-- end content -->

					<div class="col-md-12" id="fh5co-content">

						<h2>Resource Requirements for Different Types of Data Science Workflows</h2>
						
							<p>

								What are some common models that are run by data scientists?

								What are the GPU requirements?

								what are the memory requirements for the GPU and model size?
							

							</p>

							<p>
								If we're looking at modeling our GPU spend on AWS then its likely that we're supporting a team that is doing at least some deep learning workloads, so we'll focus our efforts on those types of workflows.

							</p>

							<p>

								For context, we note <A href="https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/">Tim Dettmer's blog article on "Which GPU for Deep Learning"</A> where he makes some rough guidelines for memory requirements:

								<ul>
									<li>Using pretrained transformers; training small transformer from scratch >= 11GB</li>
									<li>Training large transformer or convolutional nets in research / production: >= 24 GB</li>
									<li>Prototyping neural networks (either transformer or convolutional nets) >= 10 GB</li>
									<li>Kaggle competitions >= 8 GB</li>
									<li>Applying computer vision >= 10GB</li>
									<li>Neural networks for video: 24 GB</li>
									<li>Reinforcement learning =10GB + a strong deep learning desktop the largest Threadripper or EPYC CPU you can afford.</li>
								</ul>

								For the purposes of modeling an enterprise data science group doing deep learning on AWS GPUs, we'll say that our "normal users" are running workloads that need from 8GB up to 16GB of GPU RAM (applying pre-trained networks and doing things in the "Kaggle"-class/jupyter notebooks).






							</p>
							<p>
								Beyond that, some of our power users may want to do things such as train transformer or convolutional neural networks and that will require more than 24GB of ram.

							</p>


					</div>	

						

					<div class="col-md-12" id="fh5co-content">

						<h2>Understanding the Different Types of Public Cloud GPU Options</h2>
						
							<p>

								what GPUs are available to us on AWS?

								what instances match up?

								which make the most sense for our workloads?
							

							</p>	


							<p>
								here we're looking at the enterprise / data center as context for our GPU usage

								there are certain restrictions around using certain types of GPUs in a data center (RTX), etc

								GPUs that are not "data center"-rated, so they won't show up as an option in the public cloud: (Titan V, Titan RTX, RTX 2080 Ti, and RTX 2080)

								we are focused on the ones available (K80, T4, V100, A100)

							</p>
							<p>
								For an analysis of deep learning GPUs from the perpsective of the research / non-data center crowd, check out:

								https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/

							</p>
							<p>

								NVIDIA restricted use of the Geforce / Titan line of Cards (Titan)

								https://www.cnbc.com/2017/12/27/nvidia-limits-data-center-uses-for-geforce-titan-gpus.html

								https://www.theregister.com/2018/01/03/nvidia_server_gpus/

							</p>
							<p>
								The K80 is the p2.xlarge on amazon and is roughly 1/5 as powerful as the V100 .


							</p>
							<p>
								The T4 chipset (G4 AWS Instances) is focused on inference workloads

								"Best single-GPU instance for developing, testing and prototyping: g4dn.xlarge(T4, 16 GB GPU). Consider g4dn.(2/4/8/16)xlarge for more vCPUs and higher system memory."

							</p>
							<p>

								G3 Instances with M60 GPUs

								"G3 instances give you access to NVIDIA M60 GPUs based on the NVIDIA Maxwell architecture. NVIDIA refers to the M60 GPUs as virtual workstations and positions them for professional graphics, but you can also use them for deep learning. However, with much more powerful and cost-effective options for deep learning with P3 and G4 instances, G3 instances should be your last option for deep learning."

							</p>

							<p>
								Why are we focused on the V100 as the core instance for training here? (p3)

								Your choice order should be P3 > G4 > P2 > G3.

								P3 and G4 GPU instances offer memory sizes to support large models, high throughput, and low-latency access to CUDA

								P3 and G4 instance types give access to Tensor Cores for mixed-precision training


							</p>
							<p>
								Make the case for the p3.2xlarge as the baseline for the exercise

								Best single GPU training performance: p3.2xlarge(V100, 16 GB GPU)


							</p>

					</div>		

				
					<div class="col-md-12" id="fh5co-content">

						<h2>AWS EC2 and SageMaker</h2>
						
							<p>

								you may run ML just a stock GPU images

								a lot of people like a jupyter notebook env, so SageMaker often comes into play

								how do we model the cost of sagemaker usage?
							

							</p>	


					</div>				


				
				</div>
				<!-- end of section -->

				<!-- start of section -->

				<div class="row row-bottom-padded-sm">

					<div class="col-md-12" id="fh5co-content">


						<h1>Modeling an Organization's Group of Data Scientists</h1>

						<p>

							What kinds of data scientists do we have?

						</p>	

						<p>

							how many of each group do we have?

						</p>	

						<p>

							how many hours per month does a DS use a GPU?

						</p>	

						<p>
							what does this make for a monthly GPU hour budget?

						</p>			


					</div>
				
				</div>
				<!-- end of section -->





				<!-- start of section -->

				<div class="row row-bottom-padded-sm">

					<div class="col-md-12" id="fh5co-content">


						<h1>Forecasting Your Yearly Public Cloud GPU Spend</h1>

						<p>

							If we know
							- what kind of gpus / instances we'll use
							- how many DSs of each type
							- how many hours / month each type uses

							we can now forecast a monthly spend on AWS gpus

						</p>	

						<h2>Other Considerations</h2>

						<p>

							- capex vs opex

							- budgets

							- is the cloud easier? how?


						</p>


					</div>
				
				</div>
				<!-- end of section -->		





				<!-- start of section -->

				<div class="row row-bottom-padded-sm">

					<div class="col-md-12" id="fh5co-content">


						<h1>Summary</h1>

						<p>

							TODO

						</p>	

						<p>
							If you'd like to better understand your company's GPU usage or would like us to build you a free customized forecast report of your company's specific GPU spend, please reach out.

						</p>
						

					</div>
				
				</div>
				<!-- end of section -->											

			</div>
		</div>




	</div>
	</div>

	<div class="gototop js-top">
		<a href="#" class="js-gotop"><i class="icon-chevron-down"></i></a>
	</div>
	
	<script src="../js/jquery.min.js"></script>
	<script src="../js/jquery.easing.1.3.js"></script>
	<script src="../js/bootstrap.min.js"></script>
	<script src="../js/owl.carousel.min.js"></script>
	<script src="../js/main.js"></script>

	</body>
</html>
