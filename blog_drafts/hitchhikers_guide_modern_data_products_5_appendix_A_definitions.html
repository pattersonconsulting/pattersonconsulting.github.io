<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Josh Patterson" />
  <meta name="keywords" content="snowflake, snowpark, automl, AutoGluon, pandas, dataframe, whl, pip, anaconda, dependency" />
  <title>Appendix A - Definitions</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header>
<h1 class="title">Appendix A - Definitions</h1>
<p class="subtitle">The Hitchhiker’s Guide To Building Modern Data Products</p>
<p class="author">Josh Patterson</p>
</header>
<nav id="TOC">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#analytics-terms-definitions">Analytics Terms Definitions</a><ul>
<li><a href="#table">Table</a></li>
<li><a href="#view">View</a></li>
<li><a href="#metrics">Metrics</a></li>
<li><a href="#kpis">KPIs</a></li>
<li><a href="#analytics">Analytics</a></li>
<li><a href="#business-intelligence-bi">Business Intelligence (BI)</a></li>
<li><a href="#data-modeling">Data Modeling</a></li>
<li><a href="#data-warehouse">Data Warehouse</a></li>
<li><a href="#data-products">Data Products</a></li>
<li><a href="#dimensions">Dimensions</a></li>
<li><a href="#cubes">Cubes</a></li>
<li><a href="#the-kimball-data-warehouse-architecture">The Kimball Data Warehouse Architecture</a></li>
</ul></li>
<li><a href="#machine-learning-terms-definitions">Machine Learning Terms Definitions</a><ul>
<li><a href="#vectors-features-and-tensors-oh-my">Vectors, Features, and Tensors – Oh, My</a></li>
<li><a href="#vector">Vector</a></li>
<li><a href="#matrix">Matrix</a></li>
<li><a href="#tensor">Tensor</a></li>
<li><a href="#feature">Feature</a></li>
<li><a href="#feature-vector">Feature Vector</a></li>
<li><a href="#feature-construction">Feature Construction</a></li>
<li><a href="#feature-engineering">Feature Engineering</a></li>
<li><a href="#vectorization">Vectorization</a></li>
<li><a href="#data-engineer">Data Engineer</a></li>
<li><a href="#data-engineering">Data Engineering</a></li>
<li><a href="#machine-learning-modeling">Machine Learning Modeling</a></li>
<li><a href="#machine-learning-model-inference">Machine Learning Model Inference</a></li>
<li><a href="#artificial-intelligence">Artificial Intelligence</a></li>
</ul></li>
</ul>
</nav>
<h1 id="introduction">Introduction</h1>
<p>Purpose of this series:</p>
<blockquote>
<p>To develop a clear step-by-step process to design and operate data infrastructure for your data product.</p>
</blockquote>
<p>The intended audience for this series is:</p>
<blockquote>
<p>Individual researchers, data scientists, and then also enterprise data teams as well</p>
</blockquote>
<p>Series:</p>
<ul>
<li><a href="hitchhikers_guide_modern_data_products_1_prologue.html">Prologue (Don’t Panic)</a></li>
<li><a href="hitchhikers_guide_modern_data_products_2_evolution_data_platforms.html">The Evolution of Modern Data Platforms</a></li>
<li><a href="hitchhikers_guide_modern_data_products_3_lab_and_factory_redux.html">Revisting The Lab and the Factory</a></li>
<li><a href="hitchhikers_guide_modern_data_products_4_methodology_for_data_products.html">A Methodology for Building Data Products</a></li>
<li><a href="hitchhikers_guide_modern_data_products_5_appendix_A_definitions.html">Appendix A: Definitions</a></li>
<li><a href="hitchhikers_guide_modern_data_products_6_appendix_B_roles.html">Appendix B: Roles</a></li>
</ul>
<p>We spend the first 3 posts of this series providing background and definitions to set the stage for our methodology and in part 4 we lay out our step by step process.</p>
<p>TODO: * create a key visualization to represent the core ideas of the page * this will also serve as the meta og card image</p>
<h1 id="analytics-terms-definitions">Analytics Terms Definitions</h1>
<p>Some good definitions on reddit blog:</p>
<p>https://dataengineering.wiki/FAQ/What+is+the+difference+between+a+Data+Engineer+and+X</p>
<h2 id="table">Table</h2>
<p>alpha</p>
<h2 id="view">View</h2>
<p>beta</p>
<h2 id="metrics">Metrics</h2>
<p>For this marketing activity, relevant metrics may be:</p>
<ol type="1">
<li>Total visitors to the landing page</li>
<li>Total visitors broken down by acquisition channel (organic search, referral, cpc, etc.)</li>
<li>Total time spent on the page</li>
<li>Total form submissions</li>
</ol>
<p>Again, these are just the data building blocks.</p>
<h2 id="kpis">KPIs</h2>
<p>Key Performance Indicators</p>
<blockquote>
<p>Of the metrics, you – as the marketer or analyst – need to select those indicators of success. You may not actually care about the total visitors to the landing page, but rather, focus solely on the number of total form submissions (As as all know, more traffic is not always a positive thing, if your visitors aren’t taking the action you want them to take). So, your KPIs may break down as follows:</p>
</blockquote>
<ol type="1">
<li>Total form submissions</li>
<li>Form conversion rate (submissions/total visits)</li>
<li>Form conversion rate broken down by acquisition source</li>
</ol>
<p>These three metrics are examples of numbers that can be <em>directly</em> bound to definitions of success or failure from a business perspective.</p>
<h3 id="metrics-vs-kpis">Metrics vs KPIs</h3>
<blockquote>
<p>We take these terms seriously because there is real business value tied to each term in different ways. For example, your intern may be qualified to pull metrics from your Google Analytics account, but until those metrics are studied and summarized into business insights, they are nothing more than numbers in a spreadsheet. Similarly, the same intern might be able to pull hundreds of different metrics to report to your senior leadership, but if they aren’t aligned behind a set of KPIs, the usefulness of the data will fall short.</p>
</blockquote>
<h2 id="analytics">Analytics</h2>
<p>https://www.foxgr.com/insights/blog-analytics-vs-metrics-vs-kpis-data-terminology-defined</p>
<blockquote>
<p>Arguably the most misused term of them all, Analytics refers to the systematic study and analysis of data (i.e. Metrics and KPIs). That is, the output of information by a person or system who studied the Metics and worked to extract insights and/or conclusions about what they mean for a business.</p>
</blockquote>
<blockquote>
<p>“Analytics” in their truest form, are not data points that can be pulled directly from an analytics system. Rather, they are the interpretations of data that transform numbers and metrics into actionable ideas and insights.</p>
</blockquote>
<p>(Refactor) * Analytics, on the other hand, involves the use of statistical and quantitative methods to identify and interpret patterns and relationships in data. * Analytics can be used to answer specific questions or solve particular problems by analyzing data sets and identifying trends, patterns, and correlations that might not be immediately apparent. * Analytics can be used to gain insights into customer behavior, improve operational efficiency, and drive business growth.</p>
<blockquote>
<p>Outlining the metrics and KPIs was actually the first step in proper analysis – it’s understanding what you’re measuring and why. Next, it’s your job as the marketer or analyst to provide context and ultimately draw insights out of the data you see.</p>
</blockquote>
<p>For example:</p>
<ol type="1">
<li>You know that previous landing pages have achieved an average form conversion rate of 6%. How far above or below this benchmark does your current landing page perform?</li>
<li>What’s your hypothesis for why it is under performing or over performing? What’s different about this landing page when compared to your past efforts? Can you narrow down the success/failure to specific content attributes?</li>
<li>Based on your study, what do you recommend to change about the current tactic, or what attributes should you include in future tactics to build upon your positive outcomes?</li>
</ol>
<p>https://preset.io/blog/introducing-entity-centric-data-modeling-for-analytics/?</p>
<h3 id="what-are-3-examples-of-analytics">What are 3 Examples of Analytics?</h3>
<ol type="1">
<li>a</li>
<li>b</li>
<li>c</li>
</ol>
<h2 id="business-intelligence-bi">Business Intelligence (BI)</h2>
<blockquote>
<p>Business Intelligence (BI) involves the collection, integration, analysis, and presentation of business data in order to inform decision-making. BI tools allow organizations to gather and store data from various sources, clean and transform it into a usable format, and then analyze it to identify patterns and insights. The goal of BI is to provide business leaders with the information they need to make data-driven decisions that improve organizational performance.</p>
</blockquote>
<h3 id="bi-vs-analytics">BI vs Analytics</h3>
<p>While BI focuses on collecting and presenting data in a way that is easy to understand and use, Analytics focuses on using statistical and quantitative techniques to uncover insights and make predictions.</p>
<p>In short, BI provides the information necessary for decision-making, while Analytics provides the tools and techniques necessary for analysis and interpretation of that information.</p>
<h2 id="data-modeling">Data Modeling</h2>
<blockquote>
<p>“This is the process of producing a data model, an abstract model to describe the data and relationships between different parts of the data.[27]”</p>
</blockquote>
<h3 id="what-are-3-examples-of-data-modeling">What are 3 Examples of Data Modeling?</h3>
<ol type="1">
<li>a</li>
<li>b</li>
<li>c</li>
</ol>
<h2 id="data-warehouse">Data Warehouse</h2>
<ul>
<li>todo: clearly state the purpose of the data warehouse</li>
</ul>
<h2 id="data-products">Data Products</h2>
<ul>
<li>downstream from the core data models of the data warehouse</li>
</ul>
<h3 id="what-are-some-examples-of-data-products">What are Some Examples of Data Products?</h3>
<ol type="1">
<li>Data for a Business Intelligence Dashboard</li>
<li>Aggregated dataset for downstream machine learning</li>
<li>Operational Data (todo: differentiate this from BI data)</li>
<li>Monitoring Data</li>
<li>Data for Exploratory Discovery</li>
<li>Analytical Dataset</li>
</ol>
<h2 id="dimensions">Dimensions</h2>
<p>In data warehousing, a dimension is a categorical variable or attribute that provides context for the measures or numerical values in a dataset. Dimensions are used to categorize or group the data, and are often used to filter, aggregate, and analyze the data in various ways.</p>
<p>Examples of dimensions in a data warehouse might include time, geography, product, customer, or sales channel. These dimensions can be used to group and categorize the measures, such as sales revenue, profit margin, or units sold.</p>
<p>Dimensions are typically hierarchical, meaning that they have levels or layers of granularity. For example, a time dimension might have levels such as year, quarter, month, week, and day, which can be used to aggregate or drill down into the data as needed.</p>
<p>Dimensions can also have attributes, which provide additional information about the dimension. For example, a product dimension might have attributes such as product name, product category, manufacturer, and price.</p>
<p>Overall, dimensions are an important concept in data warehousing, and are used to provide context and structure to the data, making it easier to analyze and understand.</p>
<h2 id="cubes">Cubes</h2>
<p>In data warehousing, a cube is a multi-dimensional data structure that allows for efficient and flexible querying and analysis of large datasets. A cube is sometimes also referred to as a data cube or OLAP (Online Analytical Processing) cube.</p>
<p>A cube consists of dimensions and measures. Dimensions are the categorical variables or attributes that define the data, such as time, location, or product category. Measures are the numerical values that are being analyzed, such as sales revenue, units sold, or profit margin.</p>
<p>The cube organizes the data along these dimensions, creating a multi-dimensional view of the data. This allows for fast and flexible querying of the data along multiple dimensions, as well as the ability to perform complex analysis and calculations.</p>
<p>For example, consider a retail company that wants to analyze their sales data. They could create a cube with dimensions such as time, location, and product category, and measures such as sales revenue and units sold. The cube would allow them to easily query and analyze the sales data by different dimensions, such as sales by location and product category, or sales over time.</p>
<p>Overall, cubes are an important data structure in data warehousing, and allow for efficient querying and analysis of large, complex datasets.</p>
<h2 id="the-kimball-data-warehouse-architecture">The Kimball Data Warehouse Architecture</h2>
<h1 id="machine-learning-terms-definitions">Machine Learning Terms Definitions</h1>
<h2 id="vectors-features-and-tensors-oh-my">Vectors, Features, and Tensors – Oh, My</h2>
<p>https://stats.stackexchange.com/questions/192873/difference-between-feature-feature-set-and-feature-vector</p>
<p>https://stats.stackexchange.com/questions/351514/usage-of-the-term-feature-vector-in-lindsay-i-smiths-pca-tutorial?rq=1</p>
<blockquote>
<p>A feature vector is a vector that stores the features for a particular observation in a specific order.</p>
</blockquote>
<blockquote>
<p>For example, Alice is 26 years old and she is 5’ 6&quot; tall. Her feature vector could be [26, 5.5] or [5.5, 26] depending on your choice of how to order the elements. The order is only important insofar as it is consistent.</p>
</blockquote>
<blockquote>
<p>A feature set is a set of all the attributes that you’re interested in, e.g. height and age.</p>
</blockquote>
<blockquote>
<p>The implicit assumption when using this terminology is that your data is tabular – somehow, you have chosen to represent it as a “flat”, matrix-like format. But non-tabular data formats, like network graphs, video, audio, images, binary data sequences, … these all require some amount of engineering to represent as feature vectors.</p>
</blockquote>
<p>ISLR Book</p>
<p>https://www.statlearning.com/</p>
<h2 id="vector">Vector</h2>
<p>asda</p>
<p>In machine learning, a vector is a one-dimensional array or list of numbers. Vectors are commonly used to represent data points or features in a dataset. For example, in image recognition, each image can be represented as a vector of pixel values, where each element of the vector represents the intensity of a specific pixel.</p>
<p>Vectors can be used to perform various mathematical operations in machine learning, such as dot products, element-wise multiplication, and addition. These operations can be used to compute similarities between vectors, transform data, and build models.</p>
<p>In addition, vectors can be represented in different spaces, such as Euclidean space, where the length and direction of the vector are important, or in feature space, where each element of the vector represents a feature of the data.</p>
<h2 id="matrix">Matrix</h2>
<p>asdf</p>
<p>In machine learning, vectors and matrices are both fundamental data structures used to represent and manipulate data.</p>
<p>A vector is a one-dimensional array or list of numbers, while a matrix is a two-dimensional array of numbers. A matrix can be thought of as a collection of vectors arranged in rows and columns.</p>
<p>In machine learning, matrices are commonly used to represent datasets, where each row represents a data point or sample, and each column represents a feature or attribute of the data. For example, in a dataset of housing prices, a matrix could be used to represent the prices of different houses, where each row represents a house, and each column represents a feature such as the number of bedrooms, square footage, or location.</p>
<p>Matrices can be used to perform various operations in machine learning, such as matrix multiplication, which is used in linear regression and neural networks to transform and combine data.</p>
<p>In summary, while vectors and matrices are different data structures, they are related in that a matrix is a collection of vectors, and both are commonly used to represent and manipulate data in machine learning.</p>
<h2 id="tensor">Tensor</h2>
<p>asdf</p>
<p>In machine learning, tensors are multi-dimensional arrays or matrices that can have any number of dimensions. They are used to represent and manipulate large amounts of data, especially in deep learning.</p>
<p>Tensors are used to represent a wide variety of data, such as images, audio, video, text, and time-series data. For example, in image recognition, an image can be represented as a tensor of pixel values, where each dimension represents a different aspect of the image, such as its width, height, and color channels.</p>
<p>Tensors can be manipulated using tensor operations, which are similar to matrix operations, but are extended to handle multi-dimensional arrays. Some common tensor operations used in machine learning include tensor addition, multiplication, and convolution.</p>
<p>Tensors are used extensively in deep learning frameworks like TensorFlow and PyTorch, where they form the backbone of neural network models. Neural networks consist of layers of interconnected nodes, or neurons, that perform tensor operations on input data to produce output predictions.</p>
<p>Overall, tensors are an important data structure in machine learning, and are used to represent and manipulate large, complex datasets in a wide variety of applications.</p>
<h2 id="feature">Feature</h2>
<blockquote>
<p>“In machine learning and pattern recognition, a feature is an individual measurable property or characteristic of a phenomenon.[1] Choosing informative, discriminating and independent features is a crucial element of effective algorithms in pattern recognition, classification and regression. Features are usually numeric, but structural features such as strings and graphs are used in syntactic pattern recognition. The concept of”feature&quot; is related to that of explanatory variable used in statistical techniques such as linear regression.&quot;</p>
</blockquote>
<p>Bishop, Christopher (2006). Pattern recognition and machine learning. Berlin: Springer. ISBN 0-387-31073-8.</p>
<p>TODO: This book was published in 2006, but when did this term become widely used?</p>
<blockquote>
<p>Features are usually numeric, but structural features such as strings and graphs are used in syntactic pattern recognition. The concept of “feature” is related to that of explanatory variable used in statistical techniques such as linear regression.</p>
</blockquote>
<h3 id="numeric-feature">Numeric Feature</h3>
<p>A numeric feature can be conveniently described by a feature vector.</p>
<h2 id="feature-vector">Feature Vector</h2>
<blockquote>
<p>“In pattern recognition and machine learning, a feature vector is an n-dimensional vector of numerical features that represent some object. Many algorithms in machine learning require a numerical representation of objects, since such representations facilitate processing and statistical analysis.”</p>
</blockquote>
<blockquote>
<p>“The vector space associated with these vectors is often called the feature space. In order to reduce the dimensionality of the feature space, a number of dimensionality reduction techniques can be employed.”</p>
</blockquote>
<p>Many times in ML literature the term feature vector is used differently:</p>
<p>https://stats.stackexchange.com/questions/351514/usage-of-the-term-feature-vector-in-lindsay-i-smiths-pca-tutorial?rq=1</p>
<h2 id="feature-construction">Feature Construction</h2>
<blockquote>
<p>“Higher-level features can be obtained from already available features and added to the feature vector; for example, for the study of diseases the feature ‘Age’ is useful and is defined as Age = ‘Year of death’ minus ‘Year of birth’ . This process is referred to as feature construction.[2][3] Feature construction is the application of a set of constructive operators to a set of existing features resulting in construction of new features.”</p>
</blockquote>
<p>Attributes?</p>
<h2 id="feature-engineering">Feature Engineering</h2>
<blockquote>
<p>“Feature engineering or feature extraction or feature discovery is the process of using domain knowledge to extract features (characteristics, properties, attributes) from raw data.[1] The motivation is to use these extra features to improve the quality of results from a machine learning process, compared with supplying only the raw data to the machine learning process.”</p>
</blockquote>
<p>https://en.wikipedia.org/wiki/Feature_engineering</p>
<h3 id="discussion-on-feature-engineering">Discussion on Feature Engineering</h3>
<p>The definition for “Feature Engineering” is always some form of:</p>
<p>“Feature engineering or feature extraction or feature discovery is the process of using domain knowledge to extract features (characteristics, properties, attributes) from raw data.[1]”</p>
<p>https://en.wikipedia.org/wiki/Feature_engineering</p>
<p>However, it feels like many people in the analytics / ML world bleed this into “data extraction” or “data munging” type activities. They arent doing the “last step” and converting the tabular-dataset into an n-dimensional array of numeric features (imho)</p>
<p>SIDE NOTE: in my DL book we wrote, we call the chapter on this topic “Vectorization”, and we used that a lot of places, and it seemed to pass muster (in 2016-ish, at least. times change?). I FEEL as if we were more referring to the stage of the transforms where we convert data into its final pre-modeling form of numeric features, and less of the “lets go do transforms and junk and create new features”…</p>
<p>So</p>
<p>My question: “should we consider the final step of feature engineering to be ‘vectorization’ or ‘feature encoding’ ?”</p>
<p>Susan Says:</p>
<blockquote>
<p>I feel like vectorization or feature encoding are both fine terms to describe the process of going from something that is not numeric to numeric. I definitely think about it as separate from feature engineering. Feature encoding/vectorization has to happen always (ie everything has to have a numeric representation). But feature engineering is something that might be useful but not always necessary (maybe a neural net will learn all these relationships..aka automatic feature extraction).</p>
</blockquote>
<p>TODO:</p>
<ul>
<li>reference weka book (as early practitioner guide)</li>
<li>check terminology in Bishop book</li>
</ul>
<h2 id="vectorization">Vectorization</h2>
<p>From our book:</p>
<blockquote>
<p>“take each data type and represent it as a numerical vector (or in some cases, a multidimensional array of numbers)”</p>
</blockquote>
<p>GPT</p>
<p>Vectorization in machine learning refers to the process of converting a set of data points or features into a mathematical vector or matrix format, which can be easily understood and processed by a computer.</p>
<p>In other words, it is a way to represent data in a structured format that is suitable for machine learning algorithms to process efficiently. This is usually done by converting the raw data into a numerical format, such as through one-hot encoding, normalization, or other methods.</p>
<p>Vectorization is a crucial step in many machine learning tasks, such as image recognition, natural language processing, and recommender systems, where large amounts of data need to be processed quickly and accurately. By using vectorization techniques, we can reduce the complexity of the data and make it more manageable for machine learning algorithms to work with.</p>
<p>From Geron:</p>
<blockquote>
<p>“We already discussed two of these layers: the keras.layers.Normalization layer that will perform feature standardization (it will be equivalent to the Standardization layer we defined earlier), and the TextVectorization layer that will be capable of encoding each word in the inputs into its index in the vocabulary. In both cases, you create the layer, you call its adapt() method with a data sample, and then you use the layer normally in your model. The other preprocessing layers will follow the same pattern.”</p>
</blockquote>
<h2 id="data-engineer">Data Engineer</h2>
<blockquote>
<p>(redit) “Uses a combination of software engineering best practices and database design to build scalable data pipelines, data integrations, and data models for use in applications and reports”</p>
</blockquote>
<h3 id="data-engineers-vs-cloud-devops">Data Engineers vs Cloud DevOps</h3>
<p>Data Engineer Role and Cloud DevOps Role are both critical roles in modern businesses that rely heavily on technology. Here are the key differences and similarities between these two roles:</p>
<p>Job Responsibilities: Data Engineers are responsible for building and maintaining data pipelines that collect, process, and store large amounts of data. They are skilled in designing, building, and managing data storage systems and data processing infrastructure. They ensure that data is secure, easily accessible, and of high quality.</p>
<p>Cloud DevOps, on the other hand, is responsible for managing the cloud infrastructure that runs an organization’s applications. They work on automating the deployment, scaling, and management of applications on the cloud infrastructure. They ensure the cloud infrastructure is secure, cost-efficient, and always available.</p>
<p>Skills Required: Data Engineers need to have a strong foundation in computer science, database systems, and data modeling. They should be skilled in programming languages such as Python, SQL, and Java. Additionally, they need to have expertise in ETL (extract, transform, load) processes, data warehousing, and big data technologies like Hadoop and Spark.</p>
<p>Cloud DevOps require skills in cloud computing, containerization technologies like Docker and Kubernetes, and Infrastructure as Code (IaC) tools like Terraform and Ansible. They should be proficient in scripting languages like Bash, Python, and PowerShell. Additionally, they need to have strong skills in CI/CD (continuous integration and continuous deployment), monitoring, and logging tools.</p>
<p>Tools and Technologies: Data Engineers work with data storage technologies like Hadoop, Spark, and NoSQL databases like Cassandra, MongoDB, and DynamoDB. They also use data processing frameworks like Apache Beam and Apache Kafka. Additionally, they use data modeling tools like ERwin and ER/Studio.</p>
<p>Cloud DevOps use cloud computing platforms like AWS, Azure, and Google Cloud Platform. They use containerization technologies like Docker and Kubernetes to deploy applications. They also use Infrastructure as Code (IaC) tools like Terraform and Ansible. Additionally, they use CI/CD tools like Jenkins, Travis CI, and CircleCI.</p>
<p>In summary, Data Engineers and Cloud DevOps are both critical roles in modern businesses that rely heavily on technology. The key differences between these two roles are in their job responsibilities, required skills, and the tools and technologies they use. However, they share some similarities in their roles, such as working to ensure security and availability of the organization’s technology infrastructure.</p>
<h2 id="data-engineering">Data Engineering</h2>
<p>abc</p>
<h3 id="what-are-3-examples-of-data-engineering">What are 3 Examples of Data Engineering?</h3>
<p>abc</p>
<h2 id="machine-learning-modeling">Machine Learning Modeling</h2>
<h3 id="what-are-3-examples-of-machine-learning-modeling">What are 3 Examples of Machine Learning Modeling?</h3>
<ol type="1">
<li>a</li>
<li>b</li>
<li>c</li>
</ol>
<h2 id="machine-learning-model-inference">Machine Learning Model Inference</h2>
<h2 id="artificial-intelligence">Artificial Intelligence</h2>
<ul>
<li>marketing</li>
</ul>
</body>
</html>
