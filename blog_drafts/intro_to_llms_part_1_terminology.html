<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Josh Patterson" />
  <meta name="keywords" content="snowflake, snowpark, automl, AutoGluon,
pandas, dataframe, whl, pip, anaconda, dependency" />
  <meta name="description" content="In this post we’ll ….." />
  <title>An Introduction to Large Language Models (LLMs)</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">An Introduction to Large Language Models (LLMs)</h1>
<p class="subtitle">Core Concepts and Terminology</p>
<p class="author">Josh Patterson</p>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#introduction" id="toc-introduction">Introduction</a></li>
<li><a href="#what-are-large-language-models-llms"
id="toc-what-are-large-language-models-llms">What are Large Language
Models (LLMs)?</a>
<ul>
<li><a href="#terminology-in-llms"
id="toc-terminology-in-llms">Terminology in LLMs</a></li>
<li><a href="#deep-learning-transformers-and-deep-learning"
id="toc-deep-learning-transformers-and-deep-learning">Deep Learning,
Transformers, and Deep Learning</a></li>
<li><a href="#generative-language-models"
id="toc-generative-language-models">Generative Language Models</a></li>
<li><a href="#gpt-architecture" id="toc-gpt-architecture">GPT
Architecture</a></li>
<li><a href="#prompts-and-prompt-engineering"
id="toc-prompts-and-prompt-engineering">Prompts and Prompt
Engineering</a></li>
<li><a href="#in-context-learning"
id="toc-in-context-learning">In-Context Learning</a></li>
</ul></li>
</ul>
</nav>
<h1 id="introduction">Introduction</h1>
<p>Purpose of this series:</p>
<blockquote>
<p>To understand what LLMs are</p>
</blockquote>
<p>The intended audience for this series is:</p>
<blockquote>
<p>Individual researchers, data scientists, and then also enterprise
data teams as well</p>
</blockquote>
<p>Series:</p>
<ul>
<li><a href="intro_to_llms_part_1_terminology.html">Core Concepts and
Terminology in LLMs</a></li>
<li><a href="intro_to_llms_part_2_applications.html">LLMs and Enterprise
Applications</a></li>
<li><a href="intro_to_llms_part_3_model_management.html">Model Training
and Management in LLMs</a></li>
</ul>
<h1 id="what-are-large-language-models-llms">What are Large Language
Models (LLMs)?</h1>
<p>todo</p>
<h2 id="terminology-in-llms">Terminology in LLMs</h2>
<h2 id="deep-learning-transformers-and-deep-learning">Deep Learning,
Transformers, and Deep Learning</h2>
<p>todo</p>
<ul>
<li>DL is about automated feature learning</li>
</ul>
<p>todo</p>
<ul>
<li>dont need to create features</li>
<li>can use tons of data</li>
<li>can use tons of parameters</li>
</ul>
<h2 id="generative-language-models">Generative Language Models</h2>
<p>todo</p>
<ul>
<li>refernece our strata talk in 2016</li>
</ul>
<h2 id="gpt-architecture">GPT Architecture</h2>
<ul>
<li>based on transformers</li>
<li>doesnt need feature engineering</li>
<li>just give it structured set of natural language</li>
</ul>
<h2 id="prompts-and-prompt-engineering">Prompts and Prompt
Engineering</h2>
<p>todo</p>
<h2 id="in-context-learning">In-Context Learning</h2>
<p>todo</p>
<h3 id="in-context-learning-and-indexing">In-Context Learning and
Indexing</h3>
<p>todoo</p>
</body>
</html>
