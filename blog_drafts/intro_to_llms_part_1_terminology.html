<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Josh Patterson" />
  <meta name="keywords" content="snowflake, snowpark, automl, AutoGluon,
pandas, dataframe, whl, pip, anaconda, dependency" />
  <meta name="description" content="In this post we’ll ….." />
  <title>Building Enterprise Applications with Large Language Models</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Building Enterprise Applications with Large Language
Models</h1>
<p class="subtitle">Part 1 - An Introduction to Large Language Models
(LLMs)</p>
<p class="author">Josh Patterson</p>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#introduction" id="toc-introduction">Introduction</a></li>
<li><a href="#what-are-large-language-models-llms"
id="toc-what-are-large-language-models-llms">What are Large Language
Models (LLMs)?</a>
<ul>
<li><a href="#terminology-in-large-language-models-llms"
id="toc-terminology-in-large-language-models-llms">Terminology in Large
Language Models (LLMs)</a></li>
<li><a
href="#deep-learning-transformers-and-the-evolution-of-large-language-models"
id="toc-deep-learning-transformers-and-the-evolution-of-large-language-models">Deep
Learning, Transformers, and the Evolution of Large Language
Models</a></li>
<li><a href="#the-gpt-architecture" id="toc-the-gpt-architecture">The
GPT Architecture</a></li>
</ul></li>
<li><a href="#understanding-llm-abilities-and-how-to-measure-them"
id="toc-understanding-llm-abilities-and-how-to-measure-them">Understanding
LLM Abilities and How to Measure Them</a>
<ul>
<li><a href="#gpt-3-abilities-and-evolution"
id="toc-gpt-3-abilities-and-evolution">GPT-3 Abilities and
Evolution</a></li>
<li><a href="#limitations-of-gpt-3"
id="toc-limitations-of-gpt-3">Limitations of GPT-3</a></li>
<li><a href="#meauring-llm-reasoning-ability"
id="toc-meauring-llm-reasoning-ability">Meauring LLM Reasoning
Ability</a></li>
</ul></li>
<li><a href="#why-are-large-language-models-compelling"
id="toc-why-are-large-language-models-compelling">Why Are Large Language
Models Compelling?</a>
<ul>
<li><a href="#natural-language-as-a-driver-for-any-application"
id="toc-natural-language-as-a-driver-for-any-application">Natural
Language as a Driver for Any Application</a></li>
<li><a
href="#you-dont-have-to-re-train-the-foundation-models-to-do-things"
id="toc-you-dont-have-to-re-train-the-foundation-models-to-do-things">You
Don’t Have to Re-Train the Foundation Models to Do Things</a></li>
<li><a href="#large-language-models-and-the-evolution-of-knowledge-work"
id="toc-large-language-models-and-the-evolution-of-knowledge-work">Large
Language Models and the Evolution of Knowledge Work</a></li>
</ul></li>
<li><a href="#summary" id="toc-summary">Summary</a></li>
<li><a href="#references" id="toc-references">References</a></li>
</ul>
</nav>
<h1 id="introduction">Introduction</h1>
<p>Purpose of this series:</p>
<blockquote>
<p>To understand the role of large language models in enteprise
applications and some of the components, tools, and technologies
relevant to building these applications.</p>
</blockquote>
<p>This space is moving fast and its valuable to get a mental framing on
how to think about LLMs to better understand how to apply them in your
projects and organization. This series also sets context for a better
understanding of new developments in LLMs. Our technical series are
based on private reports we produce for our enterprise customers and
other entities we advise as a company.</p>
<p>The intended audience for this series is:</p>
<blockquote>
<p>Individual practitioners, enterprise data teams, and enterprise
executives</p>
</blockquote>
<p>Series:</p>
<ul>
<li><a href="intro_to_llms_part_1_terminology.html">An Introduction to
Large Language Models (LLMs)</a></li>
<li><a href="intro_to_llms_part_2_use_cases.html">Understanding Use
Cases for Large Language Models</a></li>
<li><a href="intro_to_llms_part_3_design_patterns.html">Design Patterns
for Large Language Model Applications</a></li>
<li><a href="intro_to_llms_part_4_model_management.html">Putting LLM
Applications into Production</a></li>
<li><a href="dl_book_appendix_a_ai.html">Appendix A: What is Artificial
Intelligence?</a></li>
</ul>
<p>The final post is where I give context on the arena of artificial
intelligence based on the history of the field. This context and history
gives the reader a better viewpoint on recent developments in large
language models.</p>
<h1 id="what-are-large-language-models-llms">What are Large Language
Models (LLMs)?</h1>
<p>Large language models, such as GPT-3.5, are advanced artificial
intelligence systems designed to understand and generate human-like
text. These models are trained on vast amounts of data to learn the
patterns, structures, and semantics of language. They can then generate
coherent and contextually relevant responses to various prompts.</p>
<p>Training a large language model involves utilizing a massive dataset,
which often includes a wide range of texts from books, articles,
websites, and other written sources. This diverse corpus helps the model
learn the nuances of human language and develop a broad understanding of
various topics.</p>
<p>Once trained, large language models can be used for a wide range of
applications. They can:</p>
<ul>
<li>generate human-like text</li>
<li>answer questions</li>
<li>assist with language translation</li>
<li>write code</li>
<li>summarize articles</li>
<li>create conversational agents</li>
</ul>
<p>and much more. They achieve this by leveraging the knowledge and
patterns they have learned during training.</p>
<p>It’s important to note that while large language models like GPT-3.5
can generate impressive and coherent text, they don’t possess true
understanding or consciousness. They are statistical models that rely on
patterns and associations in the training data rather than true
comprehension. LLMs are good at understanding written language in the
form of plain text input. LLMs output plain text based on the plain text
input and have no mmemory of previous conversations between the context
provided in the input text.</p>
<p>Recently its been <a
href="https://simonwillison.net/2023/Mar/11/llama/">declared that large
language models are having their “stable diffusion”-moment</a>, in that
an audience beyond the research community could see that they were
useful in many tasks beyond their intial focus.</p>
<p>To get a better idea of the key topics in large language models,
let’s take a look at some key terminology in the field.</p>
<h2 id="terminology-in-large-language-models-llms">Terminology in Large
Language Models (LLMs)</h2>
<p>There are a lot of research topics that I can mention in the world of
LLMs but for the purpose of this series I’ll focus on the following
concepts:</p>
<ul>
<li>Prompt</li>
<li>Prompt Engineering</li>
<li>In-Context Learning</li>
<li>Embeddings</li>
<li>Vector databases</li>
</ul>
<p>Let’s now jump into prompts and prompt engineering.</p>
<h3 id="prompts">Prompts</h3>
<p>Prompts are the primary means by which a user leverages LLMs, thus
engineering prompts (prompt engineering) is key to fully utilize the
strengths of LLMs. A prompt can be a question, a statement, or an
incomplete sentence that sets the context for the model to generate a
coherent and relevant output.</p>
<p>Prompts direct generation/retrieval of responses/text. Prompts can be
decomposed into four components, which aren’t strictly necessary for
every prompt. Instructions tie the other pieces together, directing how
each of them should be used. External info/contexts are additional
sources of knowledge. It’s important to note that contexts do not have
to be explicitly provided, and can be retrieved/referenced. User
input/query is self explanatory. Output indicators mark where generated
text begins.</p>
<p>When providing a prompt, users specify their desired outcome or
request, and the model generates a response based on the patterns and
information it has learned during training. The prompt serves as a guide
for the model to understand the user’s intent and generate a suitable
response accordingly.</p>
<h3 id="prompt-engineering">Prompt Engineering</h3>
<p>Prompt engineering, which involves optimizing the wording and
structure of prompts, has become an important practice to improve the
quality and reliability of model-generated responses. Researchers and
developers often experiment with different prompt formulations to
achieve the desired outcomes and mitigate potential biases or
limitations of the language model.</p>
<p>Considerations to keep in mind while Engineering Prompts</p>
<ul>
<li>Understanding the task/domain is crucial to leveraging an LLM.</li>
<li>Bias. Any bias in the input will likely be amplified in the output,
especially since LLMs are not immune from bias as well.</li>
<li>Good prompts should be consistent, even when variations are made
from them. A common practice (seems to be) testing the response to many
slight variations in order to uncover issues.</li>
<li>Iteration is important, thus testing and feedback can often be vital
to arriving at desired outcomes.</li>
</ul>
<p>The effectiveness of a prompt depends on its clarity, specificity,
and relevance to the desired task. Well-crafted prompts help elicit
accurate and meaningful responses from the model, while ambiguous or
poorly phrased prompts may yield inaccurate or undesired outputs.</p>
<p>More resources on prompts and prompt engineering:</p>
<ul>
<li><a
href="https://exchange.scale.com/public/events/llm-prompt-engineering-and-rlhf-history-and-techniques-2023-03-09">https://exchange.scale.com/public/events/llm-prompt-engineering-and-rlhf-history-and-techniques-2023-03-09</a></li>
<li><a
href="https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/">https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/</a></li>
<li><a
href="https://github.com/dair-ai/Prompt-Engineering-Guide">https://github.com/dair-ai/Prompt-Engineering-Guide</a></li>
</ul>
<h3 id="in-context-learning">In-Context Learning</h3>
<p><a href="https://arxiv.org/pdf/2005.14165.pdf">In-context
learning</a> refers to a technique used with large language models to
fine-tune or adapt them to specific tasks or domains by providing
additional training on task-specific examples or data. This process
allows the model to specialize and improve its performance on specific
tasks or to better align with the requirements of a particular
application.</p>
<p>In large language models like GPT-3.5, the initial training involves
exposing the model to a diverse range of text from various sources.
However, this general training may not be sufficient for certain
specific tasks or domains. In-context learning addresses this limitation
by fine-tuning the model with additional examples or data that are
relevant to the target task.</p>
<p>In-context learning is useful if we don’t have direct access to the
model or we don’t have the means to retrain the model.</p>
<h3 id="embeddings">Embeddings</h3>
<p>Embeddings are a fundamental concept in machine learning models,
including Large Language Models (LLMs). They are numerical
representations of data, such as text, images, or audio, that capture
the essence or semantic meaning of the data. The process of embedding
involves converting the input data into vectors of numbers, allowing the
machine learning model to understand and process the data
effectively.</p>
<p>By mapping data into a continuous vector space, embeddings allow for
similarity comparisons (through the use of algorithms like nearest
neighbors) and the clustering of textual data.</p>
<p>Prompts are used in conjunction with vector databases and embeddings.
Effective prompts can include specific instructions that’ll retrieve
relevant data from vector databases. To optimize this, prompts must be
constructed with consideration given to embedding space and the
relationships between embeddings.</p>
<h3 id="vector-databases">Vector Databases</h3>
<p>Vector databases play a crucial role in machine learning (ML) and
large language model (LLM) applications. They are designed to
efficiently store, index, and retrieve high-dimensional vectors, which
are numerical representations of data points. These vectors can
represent various entities such as words, documents, images, or user
preferences. Vector databases work hand in hand with the embedding
models that create such high-dimensional vectors.</p>
<p>The importance of vector databases lies in the many utilities and
operations it allows embeddings to perform once the semantic meaning of
data is vectorized</p>
<h2
id="deep-learning-transformers-and-the-evolution-of-large-language-models">Deep
Learning, Transformers, and the Evolution of Large Language Models</h2>
<p><img style="float: right; max:276px; height: 420px;" src="./images/transformers_architecture_2017.png"></p>
<p>To give a better idea of how large langauge models got to this point,
I want to point out some recent history in the field of neural networks.
Deep learning, transformers, and large language models are
interconnected concepts that play crucial roles in the development and
success of advanced natural language processing (NLP) systems.</p>
<p>Deep learning is a subfield of machine learning that focuses on
training artificial neural networks with multiple layers to learn and
extract complex patterns and representations from data. Deep learning
algorithms, such as convolutional neural networks (CNNs) and recurrent
neural networks (RNNs), have revolutionized various fields, including
computer vision, speech recognition, and natural language
processing.</p>
<p>Before transformers, recurrent neural networks were commonly used as
generative language models but they didn’t have nearly as many abilities
as today’s large language models.</p>
<p>Transformers are a specific type of deep learning architecture that
has significantly advanced NLP tasks. They were introduced in the
seminal paper <a href="https://arxiv.org/abs/1706.03762">“Attention is
All You Need” by Vaswani et al. in 2017</a>. Transformers employ a
self-attention mechanism to capture contextual dependencies between
words in a sequence, allowing the model to weigh the importance of
different words when generating responses. This attention mechanism
helps transformers effectively model long-range dependencies and
improves their ability to understand and generate coherent text. A <a
href="https://amatriain.net/blog/transformer-models-an-introduction-and-catalog-2d1e9039f376/">list
of different transformer types can be found here</a> and a wonderful <a
href="http://jalammar.github.io/illustrated-transformer/">visual
explanation of transformers can be found here</a>.</p>
<p>Large language models, such as GPT-3.5, are deep learning models
built using transformer architectures specifically designed for language
understanding and generation tasks. These models have been trained on
massive amounts of text data, learning to predict the next word or
sequence of words given a context. By leveraging the power of
transformers and deep learning techniques, large language models can
generate human-like text, answer questions, perform language
translation, and assist with a wide range of natural language processing
tasks.</p>
<p>The success of large language models is largely attributed to the
transformer architecture’s ability to capture long-range dependencies
and learn contextual representations effectively. The deep learning
techniques used in training these models allow them to understand
complex patterns and relationships in language data, making them capable
of generating coherent and contextually relevant text.</p>
<p>Something else to note is that Deep Learning is about using the
correct architecture for a data type such that the architecture can
perform automated feature engineering. Transformers are a Deep Learning
architecture for natural language and use raw text as input and output.
So its worth noting that Transformer-based systems require no manual
feature engineering for training.</p>
<p>Deep learning forms the foundation of large language models, and
transformers provide the architecture that empowers these models with
the ability to understand and generate natural language text. Together,
they have revolutionized the field of NLP and enabled the development of
sophisticated language understanding and generation systems.</p>
<p>With the connection to deep learning and transformers established,
let’s move into taking a look at the architecture of a popular large
language model, GPT.</p>
<h2 id="the-gpt-architecture">The GPT Architecture</h2>
<p><a href="https://arxiv.org/abs/2005.14165">GPT-3 is a language model
that creates near-human level quality text content</a>. It comes in
eight different sizes, ranging from 125 million to 175 billion
parameters. The largest GPT-3 model is ten times bigger than the
previous record holder, T5-11B. The smallest GPT-3 model is
approximately the same size as BERT-Base and RoBERTa-Base.</p>
<p>All GPT-3 models follow the same attention-based architecture as
their predecessor, GPT-2. The smallest GPT-3 model has 12 attention
layers, each with 12 sets of 64-dimensional heads. In contrast, the
largest GPT-3 model has 96 attention layers, each with 96 sets of
128-dimensional heads.</p>
<p>GPT-3 achieved a substantial increase in capacity compared to GPT-2,
expanding it by three orders of magnitude. This was accomplished through
the addition of more layers, wider layers, and utilizing more training
data.</p>
<p>However, it’s important to note the immense computational
requirements of training the largest GPT-3 model. The 175 billion
parameter model necessitated 3.14E23 floating point operations per
second (FLOPS) during training. Even with the most efficient hardware,
such as the V100 GPU with a theoretical peak performance of 28 TFLOPS,
it would take 355 GPU-years and cost approximately $4.6 million for a
single training run. Similarly, using a single RTX 8000 GPU with an
assumed performance of 15 TFLOPS, the training process would take
approximately 665 years. These numbers provide perspective on the
significant computational resources needed for training the largest
GPT-3 model.</p>
<h3 id="chatgpt">ChatGPT</h3>
<p>ChatGPT is based on the GPT-3.5 architecture, which is part of the
GPT (Generative Pre-trained Transformer) series developed by OpenAI.
ChatGPT is designed to generate human-like text responses and engage in
conversations on a wide range of topics. It has been trained on a
diverse corpus of text data to acquire knowledge and language patterns,
enabling it to understand and generate coherent and contextually
relevant responses.</p>
<p><a href="https://huggingface.co/blog/rlhf">Reinforcement Learning
with Human Feedback (RLHF)</a>, a method that uses human demonstrations
and preference comparisons to guide the model toward desired behavior,
was used to optimize ChatGPT for dialogue. ChatGPT can be used for
various purposes, including answering questions, providing explanations,
assisting with creative writing, and engaging in interactive
dialogues.</p>
<h1
id="understanding-llm-abilities-and-how-to-measure-them">Understanding
LLM Abilities and How to Measure Them</h1>
<p>Any new technology that wows us is always fun to play with, but if we
hope to build any applications of value, we need to put a fine edge on
the 1-2 things the technology does well. When deep learning roared onto
the tech scene, similarly many pundits and The Twitterati ascribed to it
magical powers. The market had to come back to its senses and break down
what we could realistically expect from deep learning (image object
detection, generative models, etc).</p>
<p>In this section I want to lay out the abilities and limitations of
LLMs and then forecast where I think they’ll be of most value in
enterprise applications. For a broader view on the topic of artificial
intelligence, I’ve also provided an <a
href="dl_book_appendix_a_ai.html">appendix from our O’Reilly book on
deep learning</a>. With that, let’s jump into the abilities of large
language models, focusing on GPT-3.</p>
<h2 id="gpt-3-abilities-and-evolution">GPT-3 Abilities and
Evolution</h2>
<p>I think its worth stating out of the gate some of the core abilities
we see large language models performing commonly:</p>
<ul>
<li>reason about instructions and context in the input (the
“prompt”)</li>
<li>create plans of actions, and then execute each step of the plan with
further calls back to the LLM model</li>
<li>integrate with external tools (search engines, wikipedia, python
interpreters, etc) to try out commands and examine the input in a later
LLM chained call</li>
</ul>
<p>Further, we can also state that large language models are not running
code for themselves (yet?) or creating their own computing
environments.</p>
<p>However, one of the more compelling things large language models have
shown is the ability to learn a task from only a few examples shown in
the prompt itself, as described in the paper (“Can Foundation Models
Wrangle Your Data?”)[https://arxiv.org/abs/2205.09911]:</p>
<blockquote>
<p>Emergent Behaviors Interestingly, the biggest GPT-3 variant (175B
parameters) has the capacity to solve natural language tasks with only a
few examples (called few-shot prompting), and in some cases, just a task
description (e.g. “Translate French to English”). Unlike traditional
finetuning, no model parameters are updated to fit the task. Few-shot
prompting has proven to be effective on tasks widely different from the
FMs pretraining objective. Some examples include code generation [84],
Trivia QA [18, 48] and common sense reasoning tasks [18]. Smaller models
(less than 10B parameters) typically require some form of task-specific
finetuning to perform well.</p>
</blockquote>
<p>There has been much <a
href="https://www.quantamagazine.org/the-unpredictable-abilities-emerging-from-large-ai-models-20230316/">writing</a>
on the topic of “emergent abilities” in large language models, <a
href="https://openreview.net/forum?id=yzkSU5zdwD">for and against the
idea</a>, but researcher Jason Wei does a great job <a
href="https://www.jasonwei.net/blog/emergence">listing out some of the
specific emergence abilities on his blog</a>.</p>
<p>Beyond listing abiltiies, Yao Fu goes further and <a
href="https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1">focses
his analysis on the 3 important abilities that the initial GPT-3
exhibit</a>:</p>
<ul>
<li><strong>Language generation</strong>: to follow a prompt and then
generate a completion of the given prompt.</li>
<li><strong>In-context learning</strong>: to follow a few examples of a
given task and then generate the solution for a new test case.</li>
<li><strong>World knowledge</strong>: including factual knowledge and
commonsense.</li>
</ul>
<p>For those inclined in the details, Fu’s article is wonderfully
detailed and contains considerable insight into the evolution of the
GPT-series of LLMs.</p>
<blockquote>
<p>It is interesting to note that, although being a language model, the
original GPT-3 paper barely talks about “language modeling” — the
authors devoted their writing efforts to their visions of in-context
learning, which is the real focus of GPT-3.</p>
</blockquote>
<p>Fu goes on to describe the origin of the abilites of GPT-3:</p>
<blockquote>
<p>Generally, the above three abilities should come from large-scale
pretraining — to pretrain the 175B parameters model on 300B tokens</p>
</blockquote>
<p>Further breaking down the source of the training data:</p>
<ul>
<li>60% 2016 - 2019 Common Crawl</li>
<li>22% WebText2</li>
<li>16% Books</li>
<li>3% Wikipedia</li>
</ul>
<p>Fu goes on to further hypothesize where specific abilites in GPT-3
come from:</p>
<ul>
<li>The <strong>language generation</strong> ability comes from the
language modeling <strong>training objective</strong>.</li>
<li>The <strong>world knowledge</strong> comes from the 300B token
<strong>training corpora</strong> (or where else it could be).</li>
<li>The <strong>175B model size</strong> is for <strong>storing
knowledge</strong>, which is further evidenced by Liang et al. (2022),
who conclude that the performance on tasks requiring knowledge
correlates with model size.</li>
<li>The source of the <strong>in-context learning</strong> ability, as
well as its generalization behavior, <strong>is still elusive</strong>.
Intuitively, this ability may come from the fact that data points of the
same task are ordered sequentially in the same batch during pretraining.
Yet there is little study on why language model pretraining induces
in-context learning, and why in-context learning behaves so differently
than fine-tuning.</li>
</ul>
<hr />
<p>For reference, A 750 word document will be about 1000 tokens. If we
say the average book has 80,000 words in it, and ~2 million tokens is
roughly the equivalent to 1.5 million words, we can calculate the total
books GPT-3 was trained on to be <strong>around 2.8 million
books</strong> based on a 300 billion token training corpora.</p>
<p>For comparison, the average person might read around 700 books in
their lifetime.</p>
<hr />
<p>The entire series is wonderful for insight into how large language
models such as GPT-3 get certain types of “abilities” such as “code
generation” and “in-context learning”.</p>
<p>Key point of Section: “In-context learning is a big deal, and doesnt
require retraining the model”</p>
<p>To put the above in perspective, let’s review the code ideas of
knowledge and reasoning:</p>
<ul>
<li>Knowledge provides the foundation and raw material for reasoning. It
serves as a basis for making informed decisions, solving problems, and
understanding the world. Knowledge provides context and background
information that can be used in the reasoning process.</li>
<li>Reasoning employs logical and cognitive processes to analyze and
manipulate knowledge. It helps in organizing, connecting, and utilizing
knowledge to derive new insights, solve problems, make judgments, and
make predictions.</li>
</ul>
<p>Knowledge is a prerequisite for effective reasoning. Reasoning
heavily relies on the availability and accuracy of relevant knowledge.
Lack of knowledge can limit the quality and accuracy of reasoning.
However, Reasoning can operate even in the absence of complete
knowledge. It can make use of partial or incomplete information to draw
conclusions or make decisions. Reasoning can also be employed to fill
gaps in knowledge and acquire new knowledge.</p>
<p>Knowledge and reasoning are interrelated cognitive processes.
Knowledge provides the information and foundation for reasoning, while
reasoning employs logical and cognitive processes to manipulate
knowledge and arrive at conclusions. Knowledge represents accumulated
information, while reasoning is a dynamic process of drawing inferences
and making decisions based on available information.</p>
<p>If we take those ideas, and then consider that Yao Fu mentions:</p>
<blockquote>
<p>The two important but different abilities of GPT-3.5 are
<strong>knowledge</strong> and <strong>reasoning</strong>.</p>
</blockquote>
<p>He further concludes that:</p>
<blockquote>
<p>Generally, it would be ideal if we could <strong>offload the
knowledge part to the outside retrieval system and let the language
model only focus on reasoning.</strong></p>
</blockquote>
<p>allowing for the advantages of using more up-to-date knowledge to
answer questions using an outside retrieval system. It’s also worth
noting that a lot of the GPT-3 175B parameter model was used for storing
knowledge, we could potentially use much smaller models coupled with an
external knowledge system (e.g., data warehouse) and have models that
are much smaller but still with effective reasoning capabilities.</p>
<p>The added benefit of outsourcing knowledge for LLM applications is
that the knowledge within LLMs are unreliable and cannot be verified.
However, knowledge from databases and search engines has more capacity
and you can easily verify credibility of search results by checking the
source.</p>
<p>The simple conclusion to draw from this section is:</p>
<ul>
<li>Databases are already good at knowledge</li>
<li>We like LLMs for their reasoning abilities</li>
</ul>
<p>These early ideas begin to inform what large language model
application architectures could look like, which I explore further in
part 2 of this series. Now, let’s take a look at some of the early known
limitations of large language models.</p>
<h2 id="limitations-of-gpt-3">Limitations of GPT-3</h2>
<p>Some of the things GPT-3 and large language models in general
struggle with are:</p>
<ul>
<li>they cannot on-the-fly overwrite the model’s beliefs</li>
<li>formal reasoning</li>
<li>Biases and unfairness</li>
<li>Lack of common sense</li>
<li>Contextual misunderstandings</li>
<li>Sensitivity to input phrasing</li>
</ul>
<p>From an application prototyping standpoint, the issues “sensitivity
to input phrasing” and “outdated knowledge” come up early. The phrasing
or wording of a prompt can significantly impact the generated response.
Small changes in the input can lead to different outputs, making the
models less reliable for critical or sensitive tasks. Sometimes this
needs to be tested thoroughly before letting folks loose on a new
application. Language models have a knowledge cutoff, meaning they are
not aware of events or information that occurred after their training
data. Therefore, they may provide outdated or incorrect information
about recent events. These are just two of the early issues out team has
hit developing LLM application prototypes.</p>
<h2 id="meauring-llm-reasoning-ability">Meauring LLM Reasoning
Ability</h2>
<p>If we focus our applications on leveraging large language model’s
ability to reason, and we’re to try and offload some knowledge
requirements to an outside system to use smaller models, then it makes
sense to understand how to measure the relative reasoning ability of
different models.</p>
<p>For some great background reading on the type types of reading, check
out Google’s article on <a
href="https://ai.googleblog.com/2022/05/language-models-perform-reasoning-via.html">Types
of reasoning in LLMs</a>.</p>
<p>Further, two key LLM reasoning benchmarking resources are:</p>
<ol type="1">
<li><a href="https://github.com/FranxYao/chain-of-thought-hub">The Chain
of Though Hub</a> (background: <a
href="https://arxiv.org/abs/2305.17306">paper</a>)</li>
<li><a href="https://weightwatcher.ai/leaderboard.html">The Weight
Watcher Leaderboard</a></li>
</ol>
<p>Each ranking site uses a set of tests to measure how well each model
can do different types of reasoning tasks. Some tests (e.g., MMLU) are
used by both ranking sites.</p>
<p>For example, the Chain of Thought Hub complex reasoning tasks:</p>
<ul>
<li>math (GSM8K)</li>
<li>science (MATH, TheoremQA)</li>
<li>symbolic (BBH)</li>
<li>knowledge (MMLU, C-Eval)</li>
<li>coding (HumanEval)</li>
<li>factual (SummEdits)</li>
</ul>
<p>So based on what kind of reasoning problem you were trying to solve,
these individual benchmarks would help you understand what tradeoffs you
could make in terms of parameter size vs reasoning ability. For example,
if you had to run a model that was under 10B parameters, and the
application called for math and science heavy reasoning, these
benchmarks would help you filter and rank which models would be most
effective for your criteria.</p>
<p>So now let’s close out part 1 of this series by looking out the value
of large language models and why there is so much interest in the
space.</p>
<h1 id="why-are-large-language-models-compelling">Why Are Large Language
Models Compelling?</h1>
<p>I believe large language models are compelling because they are what
I call a “tectonic-plate shift”-class of technology; These technologies,
which introduced, shift the landscape of multiple other technologies and
industries because they change:</p>
<ol type="1">
<li>what is possible with other technologies</li>
<li>the cost of certain tasks</li>
<li>the speed at which tasks can be performed</li>
</ol>
<p>Examples of previous tectonic-plate shift technologies:</p>
<ul>
<li>databases</li>
<li>big data platforms</li>
<li>cloud platforms</li>
<li>deep learning</li>
</ul>
<p>Being able to embed applied reasoning into applications will change
how tasks are accomplished in every industry.</p>
<p>From my analysis of large language model research and early
technology, the 3 themes I see as most compelling right now in the space
are:</p>
<ol type="1">
<li>you can create a natural language interface for any application with
an API</li>
<li>you don’t have to re-train models to create specific
applications</li>
<li>knowledge work is beginning an evolution similar to the introduction
of the textile loom in the 1800s</li>
</ol>
<p>In the sections below, I lightly touch on each of these themes.</p>
<h2 id="natural-language-as-a-driver-for-any-application">Natural
Language as a Driver for Any Application</h2>
<p>In prototyping LLM applications the thing that immediately struck me
was that “ChatGPT was a nice demo, but there is a lot more here”. After
seeing the raw reasoning ability of LLMs up close, and then realizing
that frameworks such as <a
href="https://github.com/hwchase17/langchain">LangChain</a> allowed you
to “glue stuff together with LLMs” (effectively), my imagination ran
wild.</p>
<p>Pretty soon we had all sorts of APIs wired up to LLM natural language
input, and we could see how the LLM was able to reason about what sort
of parameters should be sent to an API as well. This allows you to
“speak” to an application in ways that just are not possible with
classical “key word” parsing methods. Once I saw these effects
first-hand in our prototypes, I began to think about LLMs as a
tectonic-plate-shift-class technology.</p>
<h2
id="you-dont-have-to-re-train-the-foundation-models-to-do-things">You
Don’t Have to Re-Train the Foundation Models to Do Things</h2>
<p>In class machine learning you learned quickly that you had to collect
training data for your domain-specific application and re-train a new
model to apply machine learning in your domain. It took a good decade
for enterprises to come to fully appreciate this fact.</p>
<p>And then large language models come along and introduce In-Context
Learning, and all of that gets turned on its head.</p>
<p>It’s quickly evident in experimenting with LLM applications that base
models plus a framework for prompt engineering is flexible enough to
solve many problems without ever considering the idea of re-training a
new LLM model.</p>
<p>That was my second realization that this was a
tectonic-plate-shift-class technology, as it has beeen so hard for
enterprises to collect good data and get models re-trained. LLMs could
be applied more similarly to traditional software engineering practices
— not exactly, but closer than “having to re-train a new model every
time” in traditional machine learning.</p>
<p>Once I could feel the tectonic plate shift coming, I began to
ruminate on the coming evolution of knowledge work.</p>
<h2 id="large-language-models-and-the-evolution-of-knowledge-work">Large
Language Models and the Evolution of Knowledge Work</h2>
<p>People are unsettled by rapid advances in technology.</p>
<p>We’ve seen this historically with the introduction:</p>
<ul>
<li>the 1800s textile loom (and the Luddites)</li>
<li>the steam engine</li>
<li>the introduction of computers to banking</li>
</ul>
<p>For reference, <a href="https://en.wikipedia.org/wiki/Luddite">the
Luddites</a>:</p>
<blockquote>
<p>The Luddites were members of a 19th-century movement of English
textile workers which opposed the use of certain types of cost-saving
machinery, often by destroying the machines in clandestine raids. They
protested against manufacturers who used machines in “a fraudulent and
deceitful manner” to replace the skilled labour of workers and drive
down wages by producing inferior goods. Members of the group referred to
themselves as Luddites, self-described followers of “Ned Ludd”, a
legendary weaver whose name was used as a pseudonym in threatening
letters to mill owners and government officials.</p>
</blockquote>
<p>Technology shifts have a way to reverberating uncomfortably through
business, employment, and culture. I saw it first-hand when I had
multiple physicians I know call me and start asking questions about
“this new GPT thing” (and you know something has touched a nerve when
the employment class that is used to playing god is concerned).</p>
<p>However, I reminded these physicians that certain luminaries have
forecasted (in the past decade) that ‘Radiologists will be out of
business before long.’ (because of deep learning).</p>
<p>Truckers, lawyers, and textile workers have all gotten similar
treatment with past technology cycles. Yet we have more truck loads,
lawsuits, and clothes being produced than ever.</p>
<p>Workers aren’t going away with new technology, but work does change
and sometimes whole industries even evolve.</p>
<p>For example: I do more with MidJourney in terms of graphic design
output than I did previously and no jobs were lost (previously, I just
would have less graphics work done). The work product improves and the
rate at which I can produce new artwork for articles increases and
that’s generally how technology advances have driven change in the
workforce.</p>
<p>Another examples is the effect computers had on banks; Banks have
existed for centuries, and their operations have evolved over time. In
the past, before the arrival of the computer age, banks relied primarily
on manual processes for record-keeping and transactions. This included
using ledgers to record deposits, withdrawals, and other financial
transactions by hand. Banks also used paper checks and cash for most
transactions. These manual processes were time-consuming and prone to
errors, but they were the norm for many years. As technology advanced,
banks began to adopt computers and automation to streamline their
operations and improve efficiency. Before computers arrived, many banks
were only open 4 days a week because they needed downtime to do
record-keeping reconciliation work, etc. With the introduction of
computers, some pundits forecasted that bank workers could take the 5th
workday off because computers would handle the reconciliation.</p>
<p>However, that’s not what happened. Banks quickly realized, under
competitive pressure, that they now had the option to be open 5 days per
week, and they took advantage of that opportunity.</p>
<p>The <a href="https://en.wikipedia.org/wiki/Red_Queen_hypothesis">Red
Queen never lets up</a>, it seems.</p>
<h1 id="summary">Summary</h1>
<p>In this article I introduced the idea of large language model, their
abilities, and ways to measure these abilities. I also hypothesized that
enterprise applications would leverage the reasoning ability of LLMs and
use existing databases and data warehouses for knowledge retrieval,
allowing us to use smaller and more efficient language models.</p>
<p>In part 2 of this series, we’ll look at some design patterns for
building enterprise large language model applications.</p>
<p>If you have further questions about large language models, or want to
talk directly about how Patterson Consulting can help your enterprise
build large language model applications, email me at
josh@pattersonsultingtn.com.</p>
<p>Thanks for reading.</p>
<h1 id="references">References</h1>
<p>Fu, Yao; Peng, Hao and Khot, Tushar. (Dec 2022). How does GPT Obtain
its Ability? Tracing Emergent Abilities of Language Models to their
Sources. Yao Fu’s Notion.
https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1</p>
<p>Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L.,
Gomez, A. N., Kaiser, L., &amp; Polosukhin, I. (2017). Attention is All
you Need. Neural Information Processing Systems, 30, 5998–6008.
https://arxiv.org/pdf/1706.03762v5</p>
</body>
</html>
