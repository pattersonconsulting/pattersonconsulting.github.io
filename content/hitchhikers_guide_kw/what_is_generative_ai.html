<!DOCTYPE html>
<html lang="en" data-bs-theme="light">
  <head>
    <meta charset="utf-8">

    <!-- Viewport -->
    <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1, maximum-scale=1, viewport-fit=cover">
    
    <!-- SEO meta tags -->
    <title>What is Generative AI? | The Hitchhiker's Guide to Building Knowledge Work Systems (Series)</title>
    <meta name="description" content="Companies don't buy software. Companies buy productivity.">
    <meta name="keywords" content="ebook, knowledge work, technology, efficiency, productivity, economics, line of business, investment, Artificial intelligence, data platform">
    <meta name="author" content="Josh Patterson">



    <!-- Facebook and Twitter integration -->
    <meta property="og:title" content="What is Generative AI? | The Hitchhiker's Guide to Building Knowledge Work Systems (Series)"/>
    <meta property="og:image" content="https://pattersonconsultingtn.com/assets/img/evo_kw_header_0.jpg"/>
    <meta property="og:url" content="https://pattersonconsultingtn.com/content/hitchhikers_guide_kw/what_is_generative_ai.html"/>
    <meta property="og:site_name" content="Patterson Consulting"/>
    <meta property="og:description" content="Companies don't buy software. Companies buy productivity."/>




    <meta name="twitter:title" content="What is Generative AI? | The Hitchhiker's Guide to Building Knowledge Work Systems (Series)" />
    <meta name="twitter:image" content="https://pattersonconsultingtn.com/assets/img/evo_kw_header_0.jpg" />
    <meta name="twitter:url" content="https://pattersonconsultingtn.com/content/hitchhikers_guide_kw/what_is_generative_ai.html" />
    <meta name="twitter:card" content="summary_large_image" />






    <!-- Webmanifest + Favicon / App icons -->
    <link rel="manifest" href="/alpha_manifest.json">
    <link rel="icon" type="image/png" href="../../assets/app-icons/icon-32x32.png" sizes="32x32">
    <link rel="apple-touch-icon" href="../../assets/app-icons/icon-180x180.png">
        
    <!-- Theme switcher (color modes) -->
    <script src="../../assets/js/theme-switcher.js"></script>

    <!-- Import Google font (Inter) -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&amp;display=swap" rel="stylesheet" id="google-font">

    <!-- Vendor styles -->
    <link rel="stylesheet" media="screen" href="../../assets/vendor/swiper/swiper-bundle.min.css">
    <link rel="stylesheet" media="screen" href="../../assets/vendor/lightgallery/css/lightgallery-bundle.min.css">

    <link rel="stylesheet" media="screen" href="../../assets/vendor/aos/dist/aos.css">

    <!-- Font icons -->
    <link rel="stylesheet" href="../../assets/icons/around-icons.min.css">

    <!-- Theme styles + Bootstrap -->
    <link rel="stylesheet" media="screen" href="../../assets/css/theme.pct.v2.css">

    <!-- Page loading styles -->
    <style>
      .page-loading {
        position: fixed;
        top: 0;
        right: 0;
        bottom: 0;
        left: 0;
        width: 100%;
        height: 100%;
        -webkit-transition: all .4s .2s ease-in-out;
        transition: all .4s .2s ease-in-out;
        background-color: #fff;
        opacity: 0;
        visibility: hidden;
        z-index: 9999;
      }
      [data-bs-theme="dark"] .page-loading {
        background-color: #121519;
      }
      .page-loading.active {
        opacity: 1;
        visibility: visible;
      }
      .page-loading-inner {
        position: absolute;
        top: 50%;
        left: 0;
        width: 100%;
        text-align: center;
        -webkit-transform: translateY(-50%);
        transform: translateY(-50%);
        -webkit-transition: opacity .2s ease-in-out;
        transition: opacity .2s ease-in-out;
        opacity: 0;
      }
      .page-loading.active > .page-loading-inner {
        opacity: 1;
      }
      .page-loading-inner > span {
        display: block;
        font-family: "Inter", sans-serif;
        font-size: 1rem;
        font-weight: normal;
        color: #6f788b;
      }
      [data-bs-theme="dark"] .page-loading-inner > span {
        color: #fff;
        opacity: .6;
      }
      .page-spinner {
        display: inline-block;
        width: 2.75rem;
        height: 2.75rem;
        margin-bottom: .75rem;
        vertical-align: text-bottom;
        background-color: #d7dde2; 
        border-radius: 50%;
        opacity: 0;
        -webkit-animation: spinner .75s linear infinite;
        animation: spinner .75s linear infinite;
      }
      [data-bs-theme="dark"] .page-spinner {
        background-color: rgba(255,255,255,.25);
      }
      @-webkit-keyframes spinner {
        0% {
          -webkit-transform: scale(0);
          transform: scale(0);
        }
        50% {
          opacity: 1;
          -webkit-transform: none;
          transform: none;
        }
      }
      @keyframes spinner {
        0% {
          -webkit-transform: scale(0);
          transform: scale(0);
        }
        50% {
          opacity: 1;
          -webkit-transform: none;
          transform: none;
        }
      }

      .todo_edit { 
        color: #ff0000;
       }

      .todo_consider { 
        color: #dddddd;
       }


      .working_outline { 
        color: #aaaaaa;
       }

       .todo_segue {
        color: #0000dd;
       }


       .todo_blue {
        color: #0000ff;
       }

       .narrative {
        color: #fc9003;
        font-weight: bold;
        font-style: italic;
       }

       .core_thesis {
        color: #777777;
        font-weight: bold;
        font-style: italic;
        margin-bottom: 50px;
        margin-left: 50px;
       }
       .narrative_scaffolding {

        color: #cccccc;
        
        font-style: italic;

       }


      .pre {
          display: block;
          unicode-bidi: embed;
          
          white-space: pre;
      }     

    </style>

    <!-- Page loading scripts -->
    <script>
      (function () {
        window.onload = function () {
          const preloader = document.querySelector('.page-loading')
          preloader.classList.remove('active')
          setTimeout(function () {
            preloader.remove()
          }, 1500)

          const theme = 'light'
          document.documentElement.setAttribute('data-bs-theme', theme)
          

        }
      })()
    </script>

    <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-N6H6PTM9');</script>
    <!-- End Google Tag Manager -->


  </head>


  <!-- Body -->
  <body>


    <!-- Page loading spinner -->
    <div class="page-loading active">
      <div class="page-loading-inner">
        <div class="page-spinner"></div>
        <span>Loading...</span>
      </div>
    </div>


    <!-- Page wrapper -->
    <main class="page-wrapper">

      <header data-bs-theme="light">
        <!-- Navbar. Remove 'fixed-top' class to make the navigation bar scrollable with the page -->
        <div class="navbar navbar-expand-lg fixed-top bg-light">
          <div class="container">

            <!-- Navbar brand (Logo) -->
            <a class="navbar-brand pe-sm-3" href="../../index.html">
              <span class="text-primary flex-shrink-0 me-2">
                <svg width="35" height="32" viewBox="0 0 36 33" xmlns="http://www.w3.org/2000/svg">
                  <!--
                  <path fill="currentColor" d="M35.6,29c-1.1,3.4-5.4,4.4-7.9,1.9c-2.3-2.2-6.1-3.7-9.4-3.7c-3.1,0-7.5,1.8-10,4.1c-2.2,2-5.8,1.5-7.3-1.1c-1-1.8-1.2-4.1,0-6.2l0.6-1.1l0,0c0.6-0.7,4.4-5.2,12.5-5.7c0.5,1.8,2,3.1,3.9,3.1c2.2,0,4.1-1.9,4.1-4.2s-1.8-4.2-4.1-4.2c-2,0-3.6,1.4-4,3.3H7.7c-0.8,0-1.3-0.9-0.9-1.6l5.6-9.8c2.5-4.5,8.8-4.5,11.3,0L35.1,24C36,25.7,36.1,27.5,35.6,29z"></path>
                -->




<g transform="matrix(0.004459, 0, 0, -0.00433, -8154.369629, -2022.807495)" fill="#000000" stroke="none" style="transform-origin: 8189.37px 2055.78px;">
  <path d="M340 9410 l0 -260 1348 0 c807 0 1370 -4 1403 -9 30 -6 101 -15 159
-21 177 -19 447 -88 605 -155 242 -103 389 -186 553 -310 124 -94 287 -257
390 -390 26 -34 100 -148 140 -215 214 -362 327 -901 282 -1345 -11 -115 -47
-341 -58 -362 -5 -10 -14 -45 -21 -78 -7 -33 -16 -64 -20 -70 -4 -5 -13 -30
-20 -55 -7 -25 -19 -58 -26 -75 -70 -160 -92 -205 -132 -277 -45 -80 -161
-257 -189 -288 -8 -8 -33 -37 -56 -65 -60 -71 -200 -208 -277 -270 -88 -70
-241 -175 -258 -175 -7 0 -13 -3 -13 -8 0 -11 -304 -162 -326 -162 -3 0 -20
-7 -37 -14 -45 -21 -210 -74 -254 -82 -21 -4 -45 -10 -55 -15 -9 -5 -72 -18
-140 -30 -67 -12 -145 -26 -173 -31 -29 -6 -359 -12 -782 -15 l-733 -4 0
-1175 0 -1174 3270 0 3270 0 0 3695 0 3695 -3925 0 -3925 0 0 -260z" style="fill: rgb(255, 149, 0);"></path>
  <path d="M1650 6884 l0 -1096 648 4 647 4 120 28 c66 16 125 32 130 36 6 4 28
13 50 20 53 17 129 56 179 92 23 16 52 36 66 46 86 60 201 201 261 322 84 168
109 281 116 525 7 251 -18 402 -97 580 -56 126 -184 280 -295 355 -27 18 -62
42 -77 52 -15 10 -29 18 -32 18 -3 0 -30 11 -60 25 -30 14 -61 25 -68 25 -7 1
-31 8 -53 16 -101 37 -228 44 -892 44 l-643 0 0 -1096z" style="fill: rgb(255, 149, 0);"></path>
</g>



                </svg>
              </span>
              Patterson Consulting
            </a>


            <a class="btn btn-primary btn-sm fs-sm order-lg-3 d-none d-sm-inline-flex" href="../../contact_us.html" target="_blank" rel="noopener">
              <i class="fs-xl me-2 ms-n1"></i>
              Contact Us
            </a>

            <!-- Mobile menu toggler (Hamburger) -->
            <button class="navbar-toggler ms-sm-3" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-label="Toggle navigation">
              <span class="navbar-toggler-icon"></span>
            </button>

            <!-- Navbar collapse (Main navigation) -->
            <nav class="collapse navbar-collapse" id="navbarNav">
              <ul class="navbar-nav navbar-nav-scroll me-auto" style="--ar-scroll-height: 520px;">


                <li class="nav-item dropdown">
                  <a class="nav-link dropdown-toggle" href="#" data-bs-toggle="dropdown" aria-expanded="false">Industries</a>
                  <ul class="dropdown-menu">
                    <li><a class="dropdown-item" href="../../insurance_industry.html">Insurance</a></li>
                  </ul>
                </li>


                <li class="nav-item dropdown">
                  <a class="nav-link dropdown-toggle" href="#" data-bs-toggle="dropdown" data-bs-auto-close="outside" aria-expanded="false">Engineering Services</a>
                  <ul class="dropdown-menu">
                    <li><a class="dropdown-item" href="../../platform_engineering.html">Platform Engineering</a></li>
                    <li><a class="dropdown-item" href="../../data_engineering.html">Data Engineering</a></li>
                    <li><a class="dropdown-item" href="../../generative_ai.html">GenAI Services</a></li>
                    <!--
                    <li><a class="dropdown-item" href="../../data_strategy.html">Data Strategy</a></li>
                  -->
                    
                    
                  </ul>

                </li>

                <li class="nav-item dropdown">
                  <a class="nav-link dropdown-toggle" href="#" data-bs-toggle="dropdown" data-bs-auto-close="outside" aria-expanded="false">Resources</a>
                  <ul class="dropdown-menu">
                    <li><a class="dropdown-item" href="../../blog/blog_index.html">Blog</a></li>
                    <li><a class="dropdown-item" href="../../publications.html">Team Publications</a></li>
                    <li><a class="dropdown-item" href="../../index.html#case_studies">Case Studies</a></li>
                    <li><a class="dropdown-item" href="https://www.youtube.com/channel/UCmaki2Xq1AeFL8XbWGIWyQg">Videos</a></li>
                  </ul>

                </li>

                <li class="nav-item">
                  <a class="nav-link" href="../../about.html">About</a>
                </li>
              </ul>
            </nav>

          </div>
        </div>
      </header>


      <!-- Page header -->
      <section class="container py-5 mt-5 mb-md-2 mb-lg-3 mb-xl-4">

        <!-- Breadcrumb -->
        <nav aria-label="breadcrumb">
          
          <ol class="pt-lg-3 pb-lg-4 pb-2 breadcrumb">
            <li class="breadcrumb-item"><a href="">eBook</a></li>
            <li class="breadcrumb-item"><a href="../hitchhikers_guide_kw_toc.html">Hitchhiker's Guide to Knowledge Work Systems</a></li>
            <li class="breadcrumb-item active" aria-current="page">What is Generative AI?</li>
          </ol>
          
        </nav>

        <!-- Post title + post meta -->
        <h1 class="display-4 text-left pb-2 pb-lg-3">What is Generative AI?</h1>


            <div class="d-flex flex-wrap align-items-center justify-content-between border-bottom mb-4">
              <div class="d-flex align-items-center mb-4 me-4">
                <span class="fs-sm me-2">By:</span>
                <a class="nav-link position-relative fw-semibold p-0" href="#author" data-scroll data-scroll-offset="80">
                  Josh Patterson
                  <span class="d-block position-absolute start-0 bottom-0 w-100" style="background-color: currentColor; height: 1px;"></span>
                </a>
              </div>

            </div>

      </section>


      <!-- Post cover image (parallax) -->
      <section class="jarallax" data-jarallax data-speed=".65">
        <!--
        <div class="jarallax-img bg-position-center-y" style="background-image: url(../../assets/img/kw_information_transformation_header2.jpg);"></div>
        -->
        <div class="jarallax-img bg-position-center-y" style="background-image: url(../../assets/img/what_is_gen_ai_header_0.jpg);"></div>

        <div class="d-none d-xxl-block" style="height: 660px;"></div>
        <div class="d-none d-xl-block d-xxl-none" style="height: 650px;"></div>
        <div class="d-none d-lg-block d-xl-none" style="height: 500px;"></div>
        <div class="d-none d-md-block d-lg-none" style="height: 400px;"></div>
        <div class="d-md-none" style="height: 300px;"></div>
      </section>


      <!-- Post content -->
      <section class="container pt-5 mt-md-2 mt-lg-3 mt-xl-4">
        <div class="row justify-content-center pt-xxl-2">
          <div class="col-lg-9 col-xl-8">
            
<!--
            <p class="fs-lg">




Generative AI represents the latest evolution in the <a href="./technology_transforms_the_information_economy.html" target="_blank">long trajectory of knowledge work transformation</a>, following the same <a href="./structural_transformation.html" target="_blank">structural pattern</a> seen across centuries of technological advancement—from mechanical looms to mainframes, and now to large language models. These innovations do not fundamentally alter the purpose of knowledge work—to transform information into advantage—but rather shift the tools and pace required to remain competitive. 
          </p>

          <p class="fs-lg">
As with prior technological shifts, the organizations that succeed are those that effectively harness new capabilities to <a href="./how_technology_investment_enables_growth.html" target="_blank">improve decision-making, operational efficiency, and informational leverage, while others fall behind</a>. The stakes remain the same; only the means have changed. Our tools have evolved with us as labor has shifted across different industries. 

</p>

-->
<!--
          <p class="fs-lg narrative_scaffolding pre">

            [ Easy intro, similar to evo-kw article ]


Large language models, such as GPT-3.5, are advanced artificial intelligence systems designed to understand and generate human-like text. These models are trained on vast amounts of data to learn the patterns, structures, and semantics of language. They can then generate coherent and contextually relevant responses to various prompts.

Training a large language model involves utilizing a massive dataset, which often includes a wide range of texts from books, articles, websites, and other written sources. This diverse corpus helps the model learn the nuances of human language and develop a broad understanding of various topics.

Once trained, large language models can be used for a wide range of applications. They can:

* generate human-like text
* answer questions
* assist with language translation
* write code
* summarize articles
* create conversational agents

and much more. They achieve this by leveraging the knowledge and patterns they have learned during training.

          </p>
          
-->
<!--
<p class="fs-lg todo_edit">

Generative AI refers to a class of advanced artificial intelligence systems—such as large language models (LLMs) like GPT-3.5—that are designed to generate human-like text and respond contextually to a wide range of inputs. Trained on extensive datasets comprising books, articles, and websites, these models learn the patterns and semantics of natural language, enabling them to perform tasks such as answering questions, writing summaries, generating code, and supporting conversational interfaces. Their broad capabilities position generative AI as a transformative tool for enhancing decision-making, automation, and operational efficiency in data-driven industries like insurance.

</p>


          <p class="fs-lg todo_edit">
Generative AI is a sub-group of deep learning models called "transformers" that can take different types of input (e.g.,"multi-modal") and generate different types of complex output such as text, images, audio, and video.

          </p>

          <p class="fs-lg todo_edit">
Generative AI, or GenAI, refers to artificial intelligence systems capable of producing text, images, videos, or other forms of data in response to specific prompts. These systems rely on generative models that learn the patterns and structures of their training data, enabling them to create new content with similar characteristics. This capability is particularly evident in large language models (LLMs), which have seen significant advancements due to improvements in transformer-based deep neural networks. These models can generate coherent and contextually relevant outputs, making them powerful tools for various applications.
          </p>
-->

          <p class="fs-lg">

Generative AI refers to a class of advanced machine learning systems capable of producing human-like text, images, audio, and video in response to prompts. Built on transformer-based deep learning architectures, these models—such as large language models (LLMs) like GPT-3.5—are trained on vast and diverse datasets to learn the structure and semantics of language and other media. Once trained, they can generate contextually accurate and coherent outputs across a wide range of tasks, including text summarization, question answering, translation, and code generation. Their versatility and ability to synthesize information make them especially valuable for enhancing decision-making, automating knowledge work, and modernizing workflows across industries.

</p>


          <p class="fs-lg todo_edit">

            While generative AI covers text-generation, image generation, and audio generation, for the purpose of this article I am going to focus on how large language models are changing cognitive labor in the business world.

          </p>

          <h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">The Neural Network That Learned to Reason</h2>

<!--
          <p class="fs-lg narrative_scaffolding pre">


Deep learning is a subfield of machine learning that focuses on training artificial neural networks with multiple layers to learn and extract complex patterns and representations from data. Deep learning algorithms, such as convolutional neural networks (CNNs) and recurrent neural networks (RNNs), have revolutionized various fields, including computer vision, speech recognition, and natural language processing.

Before transformers, recurrent neural networks were commonly used as generative language models but they didn’t have nearly as many abilities as today’s large language models.

Transformers are a specific type of deep learning architecture that has significantly advanced NLP tasks. They were introduced in the seminal paper ["Attention is All You Need" by Vaswani et al. in 2017](https://arxiv.org/abs/1706.03762). Transformers employ a self-attention mechanism to capture contextual dependencies between words in a sequence, allowing the model to weigh the importance of different words when generating responses. This attention mechanism helps transformers effectively model long range dependencies and improves their ability to understand and generate coherent text. A [list of different transformer types can be found here](https://amatriain.net/blog/transformer-models-an-introduction-and-catalog-2d1e9039f376/) and a wonderful [visual explanation of transformers can be found here](http://jalammar.github.io/illustrated-transformer/).

Large language models, such as GPT-3.5, are deep learning models built using transformer architectures specifically designed for language understanding and generation tasks. These models have been trained on massive amounts of text data, learning to predict the next word or sequence of words given a context. By leveraging the power of transformers and deep learning techniques, large language models can generate human-like text, answer questions, perform language translation, and assist with a wide range of natural language processing tasks.

</p>
-->
<!--
          <p class="fs-lg narrative_scaffolding pre">



## The GPT Architecture

[GPT-3 is a language model that creates near-human level quality text content](https://arxiv.org/abs/2005.14165). It comes in eight different sizes, ranging from 125 million to 175 billion parameters. The largest GPT-3 model is ten times bigger than the previous record holder, T5- 11B. The smallest GPT-3 model is approximately the same size as BERT-Base and RoBERTa-Base.

All GPT-3 models follow the same attention-based architecture as their predecessor, GPT-2. The smallest GPT-3 model has 12 attention layers, each with 12 sets of 64-dimensional heads. In contrast, the largest GPT-3 model has 96 attention layers, each with 96 sets of 128-dimensional heads.

GPT-3 achieved a substantial increase in capacity compared to GPT-2, expanding it by three orders of magnitude. This was accomplished through the addition of more layers, wider layers, and utilizing more training data.

However, it’s important to note the immense computational requirements of training the largest GPT-3 model. The 175 billion parameter model necessitated 3.14E23 floating point operations per second (FLOPS) during training. Even with the most efficient hardware, such as the V100 GPU with a theoretical peak performance of 28 TFLOPS, it would take 355 GPU-years and cost approximately $4.6 million for a single training run. Similarly, using a single RTX 8000 GPU with an assumed performance of 15 TFLOPS, the training process would take approximately 665 years. These numbers provide perspective on the significant computational resources needed for training the largest GPT-3 model.

</p>
-->

<!--
          <p class="fs-lg narrative_scaffolding pre">



## GPT-3 Abilities and Evolution

It's worth listing some of the core abilities we see large language models commonly performing:

* Reasoning about instructions and context in the input (the “prompt”)
* Creating plans of actions, and then execute each step of the plan with further calls back to the LLM model
* Integrating with external tools (search engines, Wikipedia, Python interpreters, etc.) to try out commands and examine the input in a later LLM chained call

Large language models are not running code for themselves (yet?) or creating their own computing environments.

However, one of the more compelling things large language models have shown is the ability to learn a task from only a few examples shown in the prompt itself, as described in the paper (“Can Foundation Models Wrangle Your Data?”)[https://arxiv.org/abs/2205.09911]:

> Emergent Behaviors Interestingly, the biggest GPT-3 variant (175B parameters) has the capacity to solve natural language tasks with only a few examples (called few-shot prompting), and in some cases, just a task description (e.g. “Translate French to English”). Unlike traditional finetuning, no model parameters are updated to fit the task. Few-shot prompting has proven to be effective on tasks widely different from the FMs pretraining objective. Some examples include code generation [84], Trivia QA [18, 48] and common sense reasoning tasks [18]. Smaller models (less than 10B parameters) typically require some form of task-specific finetuning to perform well. 

There has been much [writing](https://www.quantamagazine.org/the-unpredictable-abilities-emerging-from-large-ai-models-20230316/) on the topic of "emergent abilities" in large language models ([for and against the idea](https://openreview.net/forum?id=yzkSU5zdwD) ), but researcher [Jason Wei does a great job listing out some of the specific emergent abilities on his blog]](https://www.jasonwei.net/blog/emergence).

Beyond listing abilities, Yao Fu goes further and [focuses his analysis on the 3 important abilities that the initial GPT-3 exhibit](https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1):
 
- **Language generation**: to follow a prompt and then generate a completion of the given prompt. 
- **In-context learning**: to follow a few examples of a given task and then generate the solution for a new test case.
- **World knowledge**: including factual knowledge and commonsense.

For those inclined in the details, Fu’s article is wonderfully detailed and contains considerable insight into the evolution of the GPT-series of LLMs.

>  It is interesting to note that, although being a language model, the original GPT-3 paper barely talks about “language modeling” — the authors devoted their writing efforts to their visions of in-context learning, which is the real focus of GPT-3.

Fu goes on to describe the origin of the abilites of GPT-3:

> Generally, the above three abilities should come from large-scale pretraining — to pretrain the 175B parameters model on 300B tokens 

Further breaking down the source of the training data:

* 60% 2016 - 2019 Common Crawl
* 22% WebText2
* 16% Books
* 3% Wikipedia

Fu goes on to further hypothesize where specific abilites in GPT-3 come from:

- The **language generation** ability comes from the language modeling **training objective**.
- The **world knowledge** comes from the 300B token **training corpora** (or where else it could be).
- The **175B model size** is for **storing knowledge**, which is further evidenced by Liang et al. (2022), who conclude that the performance on tasks requiring knowledge correlates with model size.
- The source of the **in-context learning** ability, as well as its generalization behavior, **is still elusive**. Intuitively, this ability may come from the fact that data points of the same task are ordered sequentially in the same batch during pretraining. Yet there is little study on why language model pretraining induces in-context learning, and why in-context learning behaves so differently than fine-tuning.

</p>
-->

          </div>
        </div>


        <div class="row justify-content-center pt-xxl-2" style="border: 0px solid #990000;">
          <div class="col-lg-7 col-xl-6">
            
            <p class="fs-lg">

Large language models (LLMs) like GPT-3 are the product of a long evolution in artificial intelligence, rooted in the broader field of deep learning. Deep learning, a subset of machine learning, builds on artificial neural networks with many layers—designed to learn increasingly abstract patterns in data. Early breakthroughs in computer vision and speech recognition demonstrated their power, but it wasn’t until the introduction of the transformer architecture in 2017 that deep learning began to reshape natural language processing at scale. Transformers replaced earlier models like recurrent neural networks, enabling systems to better capture the relationships between words, regardless of their distance in a sentence.
</p>


          </div>

          <div class="col-lg-3 col-xl-2">

            <!-- Caption on the left -->
            <figure class="figure">
              <img src="../../images/book_cover.png" class="img-thumbnail rounded-0" alt="...">
              <figcaption class="figure-caption">O'Reilly's Deep Learning: A Practitioner's Approach (2018)</figcaption>
            </figure>
          </div>
        </div>

        <div class="row justify-content-center pt-xxl-2">
          <div class="col-lg-9 col-xl-8">


<p class="fs-lg">
Transformers use a self-attention mechanism to determine which parts of the input matter most for understanding meaning. This architecture became the foundation for models such as GPT-3, which are capable of reading, interpreting, and generating human-like language. GPT-3’s architecture scales this design to extremes: its largest version includes 175 billion parameters, layered into 96 attention blocks. Such scale makes the model both powerful and costly—training it took hundreds of years of GPU time and millions of dollars in compute resources. But the payoff is clear: GPT-3 can generate language, interpret questions, and perform tasks it was never explicitly trained to do.

</p>
<p class="fs-lg">

Among the most notable capabilities of these models is <i>in-context learning</i>—the ability to pick up a new task from just a few examples provided in the prompt, without retraining. This is a departure from previous approaches, which required reconfiguring the model for each new task. GPT-3 also shows signs of reasoning, planning, and tool use when chained with external systems like Python interpreters or search engines. These behaviors were not explicitly programmed but emerged from the scale of training and data exposure—what some researchers describe as “emergent abilities.”

</p>
<p class="fs-lg">

The source of these capabilities lies in the vast amount of data the model was trained on—300 billion words from websites, books, and Wikipedia—and the size of the model itself. Language generation flows from the training objective of predicting the next word. World knowledge comes from the scale and diversity of the data. But the true origin of in-context learning—why the model can generalize from examples rather than updates to its weights—remains one of the open questions in the field.

</p>
<p class="fs-lg">

For technology leaders in insurance, the message is clear: LLMs are not just larger models—they represent a fundamental shift in how machines can engage with information. Unlike older systems that needed to be trained or coded for every task, LLMs adapt through language. They are reasoning engines built on the backbone of neural networks, now capable of parsing context, proposing strategies, and even helping teams work faster. As these systems become more integrated into enterprise tools, they will begin shaping how decisions are made, not just how data is processed.

</p>









            <div class="card bg-primary bg-opacity-10 border-0 overflow-hidden pt-3 pt-xl-4 px-lg-3 px-xl-4 mt-5 mb-5">
              <div class="card-body position-relative z-2 pb-0">
                <h3 class="h4 card-title text-primary">How Much Text are Large Langauges Models Trained On?</h3>

                <p class="pb-sm3 pb-md-4 mb-2">

                  For reference, A 750 word document is about 1000 tokens. If we say the average book has 80,000 words in it, and 2 million tokens is roughly the equivalent to 1.5 million words, we can calculate the total books GPT-3 was trained on to be <b>around 2.8 million books</b> based on a 300 billion token training corpora.

                </p>

                <p class="pb-sm3 pb-md-4 mb-2">

For comparison, the average person might read around 700 books in their lifetime.

                </p>


              </div>
            </div>


          <p class="fs-lg todo_edit">
The early 2020s witnessed a surge in generative AI systems, driven by the capabilities of LLMs. Notable examples include chatbots like ChatGPT and Copilot, which can engage in sophisticated conversations, and text-to-image generators such as Stable Diffusion and DALL-E, which create visual content from textual descriptions. Text-to-video AI generators like Sora further expand the possibilities of generative AI. Major tech companies, including OpenAI, Microsoft, and Google, alongside numerous smaller firms, are at the forefront of developing these innovative models, illustrating the broad and transformative impact of generative AI across industries.
          </p>


          <p class="fs-lg">
The evolution of generative AI took a significant leap in 2014 with the introduction of variational autoencoders and generative adversarial networks (GANs). These innovations enabled deep neural networks to learn generative models for complex data, like images, rather than just discriminative models that classify data. This breakthrough allowed these models to generate entire images from scratch, not merely assigning class labels, marking a pivotal moment in the development of generative AI and expanding its potential applications dramatically.
          </p>

          <p class="fs-lg">

The evolution of generative AI accelerated in 2017 with the introduction of the Transformer network, surpassing older Long-Short Term Memory (LSTM) models. This innovation led to the creation of the first generative pre-trained transformer, GPT-1, in 2018. The breakthrough continued with GPT-2 in 2019, which showcased the ability to generalize across various tasks in an unsupervised manner, establishing a new standard for foundation models in AI. This progression has significantly expanded the capabilities and applications of generative AI, making it more versatile and powerful.
          </p>

          <p class="fs-lg todo_edit">
In 2021, the landscape of generative AI advanced remarkably with the release of DALL-E, a transformer-based model capable of creating high-quality art from natural language prompts. This innovation was soon followed by Midjourney and Stable Diffusion, further demonstrating the potential of generative networks to produce visually stunning and contextually accurate images. These models not only showcased the practical applications of AI in creative fields but also highlighted the rapid progression and expanding capabilities of generative AI technologies.
          </p>

          <h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">Not Just the Same Old Machine Learning</h2>
<!--
          <p class="fs-lg">

Generative artificial intelligence, or generative AI, is making waves in technology, allowing machines to create new data rather than just making predictions based on existing information. While this concept isn't new, recent advancements have led to more powerful and complex models like OpenAI's ChatGPT, which can generate text that resembles human writing. These models, built on algorithms like Markov chains and more recent innovations such as generative adversarial networks (GANs) and transformer architectures, have opened up a wide range of applications, from synthetic image generation to designing novel protein structures.
          </p>

          <p class="fs-lg">
Researchers are leveraging generative AI for various tasks, such as training computer vision models with synthetic image data or designing new materials with novel protein structures. However, while these models offer immense potential, they also come with challenges and potential risks. Worker displacement in call centers, biases inherited from training data, and issues like plagiarism and copyright infringement are some concerns. Yet, there's also optimism about the creative possibilities and economic impacts of generative AI, with the potential to empower artists and revolutionize various disciplines by democratizing creative content production and aiding in the development of more generally intelligent AI agents.
          </p>
-->
          <p class="fs-lg">

<!--


Artificial Intelligence as a general field can be described as ...

> One of the most salient written lines about the beginnings of Artificial Intelligence was by author Pamela McCorduck when she wrote that AI began with "an ancient wish to forge the gods"

Machine Learning is defined as ... (relate date science)

> Machine learning ... refers to the algorithms used during data mining for acquiring the structural descriptions from the raw data.

> In everyday parlance, when we say learning, we mean something like “gaining knowledge by studying, experience, or being taught.” Sharpening our focus a bit, we can think of machine learning as using algorithms for acquiring structural descriptions from data examples. A computer learns something about the structures that represent the information in the raw data.


how is generative ai different than traditional machine learning?

with machine learning a model is typcially specifically trained on a subset of a total population of a dataset that is relevant only to your organization

however, with large language models and image generation models, the "models are built for reasoning, dataset is large corpus of text, distribution of the data doesnt change, so llm model is portable"

Generative AI models like ChatGPT are typically much larger than traditional AI models, involving billions of parameters. This vast scale allows them to capture a wide range of knowledge and generate more nuanced and contextually appropriate responses.
 
* traditional AI models approximated the distribution of data for a specific dataset, but large language models are built for reasoning and they model the distributionn of concepts in language
* thereforce, large language models can be used on many tasks that need to reason over raw text input (e.g., "prompts")
-->



<a href="./what_is_artificial_intelligence.html" target="_blank">Artificial Intelligence</a> has long captured our imagination—what author Pamela McCorduck once called “an ancient wish to forge the gods.” Traditional machine learning methods, foundational to data science, rely on algorithms that extract patterns and structure from specific organizational datasets. These models are narrow in scope, trained to perform well within a constrained domain where the data distribution is familiar and relatively static.
          </p>

          <p class="fs-lg">

Generative AI models, particularly large language models like GPT3 (and its line), represent a significant departure. Trained on massive corpora of text, they are built not just to detect structure but to reason across varied and unfamiliar contexts. Unlike traditional models, which are tailored to a specific dataset, generative models are broadly applicable, portable, and capable of handling a wide array of tasks through natural language input. This shift from pattern recognition to conceptual reasoning makes generative AI a strategic asset for enterprises ready to rethink how knowledge work is done.

          </p>












          <h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">Why Large Language Models are Useful</h2>

          <p class="fs-lg">
Generative AI can produce text that is remarkably human-like in its fluency and coherence. This capability stems from the sophisticated patterns the models learn during their extensive training on diverse text data. Text generation is particularly interesting to F1000 enterprise customers as it provides a raw reasoning engine to make nuanced and complex analysis over data embedded as text in the input. The sub-domain of text generation is commonly referred to as "large language models" (LLMs) and takes a string known as a prompt as input. It then outputs another string to answer the question or request posed in language and data of the input string.

Text generation output can range from simple question/answer to code generation, article writing, and even poem creation in distinct styles.


          </p>

          <p class="fs-lg todo_edit">

<!--
Generative AI represents a paradigm shift that is poised to transform product strategy and user experiences across industries. While there's a rush to integrate AI features into existing products, it's crucial to avoid the pitfall of feature bloat. Generative AI's true potential lies not just in enhancing current interfaces like chatbots but in reimagining value propositions and user experiences altogether. This means thinking beyond simple AI enhancements to fundamentally redesign how software serves users, making AI an integral yet seamless part of the overall user journey.

The rapid adoption of generative AI is strikingly different from previous technological shifts like cloud computing and big data. Unlike the gradual uptake by smaller, agile companies, AI's integration is being driven by large companies' executives who mandate its use across their organizations. This has led to a widespread and fast-paced experimentation phase across businesses of all sizes. 



Large language models are compelling because they are what I call a “tectonic-plate shift”class of technology; These technologies, which introduced, shift the landscape of multiple other technologies and industries because they change:

1. what is possible with other technologies
2. the cost of certain tasks
3. the speed at which tasks can be performed


Being able to embed applied reasoning into applications will change how tasks are accomplished in every industry.

-->

          </p>

          <p class="fs-lg todo_edit">


Large language models (LLMs) represent a foundational shift in computing, not just an upgrade. Their real value lies in embedding reasoning directly into software, enabling systems to handle complexity, make decisions, and adapt quickly. Unlike past innovations like cloud or big data—which evolved gradually—LLMs are being deployed rapidly and broadly, often driven from the top of large organizations. This speed reflects their potential to fundamentally reshape how digital tools support work.
          </p>

          <p class="fs-lg todo_edit">

Rather than simply adding features, LLMs open the door to rethinking entire user experiences. They lower the cost of complex tasks, increase execution speed, and expand what's technically possible. The result is a new generation of software that’s more intuitive, responsive, and capable of handling judgment-based tasks once reserved for specialists. Used well, they don’t just enhance workflows—they redefine them.


          </p>


          <p class="fs-lg">
Video, Image, and Audio generation is useful for creative applications in media. Examples of these applications are image synthesis via a Adobe Photoshop tool or other online applications such as Midjourney.

          </p>


            <h2 class="h2 mb-lg-4 pt-3 pt-md-4 pt-xl-5">Types of Generative AI Applications</h2>


          <p class="fs-lg">

Examples of generative AI applications include:

</p>

<ol>

<li>ICD code translation from raw doctors text notes</li>
<li> Meteorologist specialist that can answer questions about current and past hurricanes, forecasting how they might impact a reinsurance portfolio</li>
<li> A medical sales assistant that pulls together prospect lists based on physician services specialty and physical location</li>
<li> visual analytics UX driven by natural language</li>
<li> complex scenario analysis based on natural language description</li>
<li> business management assistant that analysis current business metrics and recommends where to focus operational improvement</li>

</ol>



          <p class="fs-lg">

 I generalize these applications of generative AI into 3 types:

</p>

<ul>
  <li> conversational AI</li>
  <li> workflow automation</li>
  <li> decision intelligence tools</li>
</ul>

<h2 class="h3 mb-lg-4 pt-3 pt-md-4 pt-xl-5">Conversational User Interfaces</h2>

<!--

Text-based conversational user interfaces have significantly transformed the workplace by automating routine tasks and enhancing customer service. Customer service bots handle simple inquiries, freeing up human agents for more complex issues, while digital workers automate repetitive and semi-technical tasks. This automation not only increases efficiency but also allows employees to focus on tasks that require human intelligence and creativity. As a result, businesses can operate more smoothly and employees can engage in more meaningful and productive work.


Generative AI, exemplified by large language models, is revolutionizing how we interact with technology by allowing natural language interfaces to extend beyond data management into virtually all areas of organizational work. Similar to how DBT and Snowflake democratized data manipulation with SQL, generative AI empowers more people to engage in complex tasks quickly and efficiently through conversational interfaces. This broadens accessibility, enabling diverse teams to leverage AI for mapping the world—whether it’s optimizing logistics, enhancing customer service, or automating routine tasks—thereby accelerating innovation and productivity across industries.


AI chatbots like Bank of America's Erica are revolutionizing customer engagement by providing efficient, intelligent interfaces that cater to modern consumers' needs. With over 1.5 billion engagements since its launch, Erica showcases the power of personalized interactions and immediate feedback. The exponential growth of Erica's user base underscores the increasing reliance on chatbots as indispensable tools for enhancing digital interactions.

Moreover, Erica's success offers a blueprint for various industries, demonstrating the scalability and versatility of AI chatbots. From banking to telecommunications, these bots assist users with personalized insights, tracking services, and facilitating seamless connections to human support when needed. As AI chatbots continue to evolve and adapt, they prove to be proactive assets essential for businesses aiming to stay customer-centric and relevant in today's digital landscape.


Messaging applications have experienced exponential growth, transforming into the primary communication channels globally, surpassing traditional social media platforms. With over 3 billion active users in 2024, messaging apps like WhatsApp, WeChat, and Facebook Messenger dominate digital communication. WhatsApp leads with 2 billion users, followed by WeChat and Messenger, highlighting their critical role in daily interactions. The surge in user engagement is further evidenced by a significant preference for messaging—60% of consumers favor it over email or phone calls. This shift is bolstered by the rapid adoption of business functionalities within these platforms, such as WhatsApp Business, which has seen a tenfold increase in its user base since 2019. The integration of messaging apps into commerce and their acceptance for business communications underscore a robust trend towards these platforms as indispensable tools for both personal and professional interactions.

Texting has ascended to the foremost mode of communication, especially favored by Millennials, due to its compelling blend of efficiency, cost-effectiveness, and broad accessibility. With over 3 billion individuals predicted to use messaging apps in 2022, texting's ubiquity is largely driven by its ability to facilitate quick exchanges—90% of texts are opened within three minutes—allowing users to manage multiple conversations simultaneously. Moreover, modern messaging apps enhance this experience by supporting rich media and social sharing features, which amplify their appeal across all age groups, not just younger generations. This multifunctionality and the meaningful interactions it supports, akin to traditional phone calls but with greater convenience, underscore why texting remains the top digital activity worldwide.

Over the next decade, conversational AIs (CAIs) are poised to become an integral part of everyday technology interactions, driven by the ubiquity of personal computing devices and advancements in AI. As AI's capability to understand and remember user interactions becomes more refined, interacting with machines through both text and voice will become as natural and intuitive as human conversation. This will not only enhance the effectiveness of customer service and personalized marketing but also foster a new dimension of user engagement where digital assistants can remember preferences and context over time, much like a human counterpart. The result will be a seamless, more personalized user experience across various platforms, significantly impacting how brands interact with consumers and vice versa, making CAIs critical in the technological landscape.

-->

<p class="fs-lg">

Generative AI-powered conversational interfaces are reshaping how organizations interact with both customers and internal systems. Text-based chatbots now automate routine service tasks, streamline semi-technical operations, and reduce the load on human agents—allowing teams to focus on higher-value work. Platforms like Bank of America's Erica, with over 1.5 billion interactions, demonstrate the scale and effectiveness of personalized AI-driven engagement. These interfaces not only enhance responsiveness but also provide meaningful, real-time feedback, improving both operational efficiency and customer satisfaction.

</p>
<p class="fs-lg todo_edit">
At the same time, the rise of messaging apps—with over 3 billion global users—signals a decisive shift in communication preferences. Consumers favor messaging for its speed, accessibility, and ability to deliver rich, multi-modal interactions. With business messaging adoption accelerating, generative AI integrated into these platforms becomes a natural extension of digital service. Over the next decade, conversational AIs will evolve into persistent, memory-rich digital assistants that personalize experiences across voice and text. For insurers, this means scalable, 24/7 engagement capabilities and a future-ready approach to customer interaction.
</p>

<h2 class="h3 mb-lg-4 pt-3 pt-md-4 pt-xl-5">Workflow Automation</h2>

<p class="fs-lg">
<!--
Adding Semantic Glue to Make Workflows Smarter

examples
* claims processing
* call center automation

Integration with legacy systems may also be a big use case for LLMs

* further

Shawn Wang's "smol developer" project represents an innovative leap in AI-driven code generation. Instead of merely generating code snippets upon request, it can create entire codebases from a product specification, iteratively improving them based on user feedback. This approach, which involves a collaborative feedback loop between the user and the AI, could revolutionize how we develop software by focusing on refining the product through continuous iteration and enhancement.

This concept extends beyond code generation to other domains, like data analytics. The "smol analyst" idea proposes using a similar iterative approach for creating dashboards and reports. Users describe their desired outcomes, and the AI generates an initial draft, which is then refined based on user feedback. This method encourages a back-and-forth process, helping users ask better questions and achieve more accurate results. By treating the AI as an eager but inexperienced employee, this approach could significantly enhance the utility of LLMs in business intelligence.

However, challenges remain, particularly in ensuring the reliability of the AI's outputs. While the iterative feedback loop works well for generating functional software, data analytics require transparency and validation of computational processes. One potential solution is to integrate multiple specialized models, each handling different aspects of the task, and using human oversight to verify the AI's work. This multi-model approach could help mitigate the "black box" issue, making AI-generated analytical work more trustworthy and useful.


* segue - edit

Generative AI significantly enhances workflow automation by integrating cognitive decision-making and dynamic adaptability into traditional robotic process automation (RPA). While RPA excels at automating repetitive, rule-based tasks, generative AI extends these capabilities to handle complex judgments and unstructured data analysis. This fusion creates a more intelligent and flexible automation system that can manage both routine processes and intricate tasks, improving overall efficiency and effectiveness. By offering contextually relevant information and making informed decisions, generative AI enables businesses to tackle complex scenarios, such as loan approvals or patient diagnoses, with greater precision and personalization.

Moreover, generative AI presents a substantial opportunity for integrating legacy systems into modern automation workflows. By leveraging AI's advanced data analysis and decision-making capabilities, companies can seamlessly incorporate outdated systems into their automated processes, ensuring a smoother transition and maximizing existing investments. Additionally, generative AI automation enhances design and manufacturing by reducing late-stage design changes and accelerating test data interpretation. This proactive approach minimizes production delays and improves product quality, ultimately speeding up time-to-market and fostering innovation. In essence, generative AI transforms workflow automation into a more robust, adaptable, and intelligent framework, driving efficiency and sophistication across various industries.

-->



Generative AI is redefining workflow automation by adding cognitive decision-making and adaptability to traditional robotic process automation (RPA). While RPA handles structured, repetitive tasks, generative AI expands the scope to include unstructured data and complex judgments. This fusion allows organizations to automate not just routine operations, but also tasks requiring contextual understanding—such as processing customer requests, analyzing claims data, or interpreting technical diagnostics—making automation more flexible, accurate, and scalable.

</p>
<p class="fs-lg todo_edit">
A key advantage lies in integrating legacy systems into modern workflows. Generative AI can interpret and bridge data from older platforms, preserving existing investments while enabling smarter, end-to-end automation. Additionally, iterative feedback loops, combined with a multi-model architecture and human oversight, help mitigate reliability concerns by increasing transparency in AI-driven processes. The result is a more intelligent automation layer—one that accelerates execution, reduces downstream errors, and supports continuous improvement across diverse operational domains.



          </p>


<h2 class="h3 mb-lg-4 pt-3 pt-md-4 pt-xl-5">Decision Intelligence</h2>




<p class="fs-lg">



<!--

* quickly play out business scenarios that previously needed multiple specialists to break down and analyze

> Rapid Scenario Planning

> With an LLM, strategists can quickly generate focused scenarios for exploration. This allows them to pressure test strategies and contingencies in a fraction of the usual time.

Large language models (LLMs) have found exciting applications in economic simulation, where they model market dynamics, business operations, and financial decision-making processes. By leveraging strategic reasoning, LLMs can predict and optimize outcomes in complex economic scenarios, such as market competition and resource allocation. Research by Horton, Chen, Xie, and Li demonstrates how LLM-empowered agents can simulate hiring scenarios, predict stock movements, and make rational economic decisions. Frameworks like CompeteAI and AucArena illustrate LLMs' capabilities in business competition and auctions, respectively, highlighting their adaptability and strategic thinking in economic environments. This potential reshapes macroeconomic modeling, showcasing LLMs as powerful tools for simulating realistic economic behaviors.

* segue - edit


The shift towards data-driven decision-making, as exemplified by platforms like Yelp and Google, highlights a profound transformation in how we navigate everyday choices. No longer reliant on intuition and anecdote, we now seamlessly integrate data analysis into our decision-making processes, whether it's selecting a restaurant or planning a night out. This universal adoption of data-driven approaches underscores the natural integration of data into our daily lives, with services like Yelp subtly guiding our choices without the need for explicit data literacy.

In contrast, within organizations, the utilization of data often remains fragmented and disconnected from decision-making processes. While there's a pervasive emphasis on fostering data literacy and promoting the use of analytical tools, these efforts often fall short of replicating the seamless integration of data seen in consumer applications. Corporate dashboards and BI tools, detached from operational workflows, fail to provide the intuitive and integrated experiences necessary for effective decision-making.

To bridge this gap, the future of operational analytics lies in creating integrated experiences that seamlessly embed data insights into existing workflows. Rather than treating data analysis as a separate activity, operational tools should integrate data analysis capabilities directly into the decision-making process. This requires a shift towards building focused, disciplined, and user-centric data applications that prioritize solving specific problems and seamlessly integrate data insights into operational workflows, mirroring the intuitive and natural integration of data seen in consumer applications like Yelp.
-->



Generative AI, particularly large language models, enables organizations to rapidly simulate complex business scenarios that once required cross-functional teams and extended analysis. These models support swift exploration of strategic options, allowing decision-makers to test contingencies and forecast outcomes with greater agility. By modeling operational dynamics and economic behaviors, LLMs introduce a new level of depth and speed to business strategy, supporting faster, more informed decisions.

          </p>

          <p class="fs-lg todo_edit">


This evolution parallels how consumers now rely on subtle, data-driven systems in everyday life. Yet within organizations, data often remains siloed and separated from real-time decision-making. To close this gap, the focus must shift toward embedding analytics directly into workflows—creating user-centric, problem-focused tools that make insight generation as intuitive as consumer experiences. True decision intelligence comes not from more dashboards, but from designing systems that integrate intelligence into the moment of action.


</p>





          <h2 class="h3 mb-lg-4 pt-3 pt-md-4 pt-xl-5">The Mechanization of Cognitive Labor</h2>


          
          <p class="fs-lg ">
Generative AI represents a turning point in the evolution of knowledge work, much like the mechanical loom reshaped hand weaving. Rather than replacing people, it mechanizes cognitive tasks—transforming how information is processed, decisions are made, and value is created. This shift mirrors earlier waves of transformation, where new tools didn’t eliminate labor but restructured it. In each case—from the invention of writing to the printing press and now AI—the core outcome has been the same: tools extend human capability, allowing organizations to scale coordination, accelerate insight, and focus skilled labor on higher-order problems.


          </p>

          <p class="fs-lg ">


This is not replacement, but realignment—freeing teams to focus on what matters most while the machinery of reasoning runs in the background.

The competitive edge lies not in cutting labor but in amplifying talent. The organizations that thrive will be those that use AI to enhance the judgment, speed, and output of their best people. Just as tools have always extended human reach, this new class of tools extends our ability to understand, decide, and act—faster and at greater scale. The stakes remain unchanged; only the means have evolved.

          </p>


          </div>
        </div>
      </section>



      <!-- Post content -->
      <section class="container pt-5 mt-md-2 mt-lg-3 mt-xl-4">


            <!-- Tags -->
            <div class="d-flex flex-wrap pb-5 pt-3 pt-md-4 pt-xl-5 mt-xl-n2 pl-3">
              <h3 class="h3 py-1 mb-0 me-4">Next in Series</h3>
            </div>



                  <div class="card overflow-hidden mb-4">
                    <div class="row g-0">
                      <div class="col-sm-4 bg-repeat-0 bg-size-cover" style="background-image: url(../../assets/img/what_is_ai_header2.jpg); min-height: 14rem;"></div>
                      <div class="col-sm-8">
                        <div class="card-body">
                          <h4 class="card-title">What is Artificial Intelligence?</h4>
                          <p class="card-text">Taking a look at what is real and how to define AI.</p>
                          
                          <!--
                          <a class="btn btn-primary" href="#">Go somewhere</a>
                        -->
                <a class="btn btn-lg btn-link px-0" href="./what_is_artificial_intelligence.html">
                  Read next article in series
                  <i class="ai-arrow-right ms-2"></i>
                </a>

                        </div>
                      </div>
                    </div>
                  </div>

      </section>




    </main>

    

  <footer class="footer py-5 bg-dark" data-bs-theme="dark">
      <div class="container pt-md-2 pt-lg-3 pt-xl-4">
        <div class="row pb-5 pt-sm-2 mb-lg-2">
          <div class="col-md-4 col-lg-3 pb-2 pb-md-0 mb-4 mb-md-0">


            <a class="navbar-brand pe-sm-3" href="/index.html">
              <span class="text-primary flex-shrink-0 me-2">
                <svg width="35" height="32" viewBox="0 0 36 33" xmlns="http://www.w3.org/2000/svg">

                  <g transform="matrix(0.004459, 0, 0, -0.00433, -8154.369629, -2022.807495)" fill="#000000" stroke="none" style="transform-origin: 8189.37px 2055.78px;">
                    <path d="M340 9410 l0 -260 1348 0 c807 0 1370 -4 1403 -9 30 -6 101 -15 159
                  -21 177 -19 447 -88 605 -155 242 -103 389 -186 553 -310 124 -94 287 -257
                  390 -390 26 -34 100 -148 140 -215 214 -362 327 -901 282 -1345 -11 -115 -47
                  -341 -58 -362 -5 -10 -14 -45 -21 -78 -7 -33 -16 -64 -20 -70 -4 -5 -13 -30
                  -20 -55 -7 -25 -19 -58 -26 -75 -70 -160 -92 -205 -132 -277 -45 -80 -161
                  -257 -189 -288 -8 -8 -33 -37 -56 -65 -60 -71 -200 -208 -277 -270 -88 -70
                  -241 -175 -258 -175 -7 0 -13 -3 -13 -8 0 -11 -304 -162 -326 -162 -3 0 -20
                  -7 -37 -14 -45 -21 -210 -74 -254 -82 -21 -4 -45 -10 -55 -15 -9 -5 -72 -18
                  -140 -30 -67 -12 -145 -26 -173 -31 -29 -6 -359 -12 -782 -15 l-733 -4 0
                  -1175 0 -1174 3270 0 3270 0 0 3695 0 3695 -3925 0 -3925 0 0 -260z" style="fill: rgb(255, 149, 0);"></path>
                    <path d="M1650 6884 l0 -1096 648 4 647 4 120 28 c66 16 125 32 130 36 6 4 28
                  13 50 20 53 17 129 56 179 92 23 16 52 36 66 46 86 60 201 201 261 322 84 168
                  109 281 116 525 7 251 -18 402 -97 580 -56 126 -184 280 -295 355 -27 18 -62
                  42 -77 52 -15 10 -29 18 -32 18 -3 0 -30 11 -60 25 -30 14 -61 25 -68 25 -7 1
                  -31 8 -53 16 -101 37 -228 44 -892 44 l-643 0 0 -1096z" style="fill: rgb(255, 149, 0);"></path>
                  </g>

                </svg>
              </span>
              <span class="text-light">
              Patterson Consulting
              </span>
            </a>    

            <p class="fs-sm pb-2 pb-md-3 mb-3 text-light">Delivering data pipelines, analytics, and large language model applications.</p>
            <div class="d-flex gap-3">
              <!--
              <a class="btn btn-icon btn-sm btn-secondary btn-facebook rounded-circle" href="#" aria-label="Facebook">
                <i class="ai-facebook"></i>
              </a>
            -->
              <!--
              <a class="btn btn-icon btn-sm btn-secondary btn-instagram rounded-circle" href="#" aria-label="Instagram">
                <i class="ai-instagram"></i>
              </a>
            -->
              <a class="btn btn-icon btn-sm btn-secondary btn-linkedin rounded-circle" href="https://www.linkedin.com/company/patterson-consulting-tn/" aria-label="LinkedIn">
                <i class="ai-linkedin"></i>
              </a>
            </div>
          </div>
          <div class="col-md-8 col-lg-7 col-xl-6 offset-lg-2 offset-xl-3">
            <div class="row row-cols-1 row-cols-sm-3">
              <div class="col mb-4 mb-md-0">
              </div>
              <div class="col mb-4 mb-md-0">

              </div>
              <div class="col mb-4 mb-md-0">
                <h4 class="h6 fw-bold pb-lg-1">Company</h4>
                <ul class="nav flex-column">
                  <li><a class="nav-link fw-normal py-1 px-0" href="/contact_us.html">Contact Us</a></li>
                  <li><a class="nav-link fw-normal py-1 px-0" href="/blog/blog_index.html">Blog</a></li>
                  <li><a class="nav-link fw-normal py-1 px-0" href="/index.html#case_studies">Case Studies</a></li>
                  <li><a class="nav-link fw-normal py-1 px-0" href="/publications.html">eBooks</a></li>
                  <li><a class="nav-link fw-normal py-1 px-0" href="https://www.youtube.com/channel/UCmaki2Xq1AeFL8XbWGIWyQg">Videos</a></li>
                  <li><a class="nav-link fw-normal py-1 px-0" href="/about.html">About</a></li>
                </ul>
              </div>
            </div>
          </div>
        </div>
        <p class="nav fs-sm mb-0">
          <span class="text-body-secondary">© All rights reserved. Made by</span>
          <a class="nav-link fw-normal p-0 ms-1" href="https://www.pattersonconsultingtn.com/" target="_blank" rel="noopener">Patterson Consulting</a>
        </p>
      </div>
    </footer>    


    <!-- Back to top button -->
    <a class="btn-scroll-top" href="#top" data-scroll aria-label="Scroll back to top">
      <svg viewBox="0 0 40 40" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
        <circle cx="20" cy="20" r="19" fill="none" stroke="currentColor" stroke-width="1.5" stroke-miterlimit="10"></circle>
      </svg>
      <i class="ai-arrow-up"></i>
    </a>


    <!-- Vendor scripts: JS libraries and plugins -->
  <!--
    <script src="../../assets/vendor/jarallax/dist/jarallax.min.js"></script>
-->

    <script src="../../assets/vendor/swiper/swiper-bundle.min.js"></script>

    <!-- Bootstrap + Theme scripts -->
    <script src="../../assets/js/theme.min.js"></script>
  </body>
</html>
